{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "approximate-morris",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'export' ���O�����Υ~���R�O�B�i���檺�{���Χ妸�ɡC\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mighty-helping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smaller-isolation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "narrow-laser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "neural-absolute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "maritime-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudaSetDevice(0)\n",
    "#dataset transcript要在dataset資好夾調\n",
    "#cuda 在basesolver init調\n",
    "#dataset要在data.py設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "graduate-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "# # os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "\n",
    "# torch.cuda.set_device(0)\n",
    "# print(torch.cuda.current_device())\n",
    "#! python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Author: kun\n",
    "# @Time: 2019-10-29 20:29\n",
    "\n",
    "import yaml\n",
    "# import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "class Para(object):\n",
    "    a=1\n",
    "\n",
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda:0')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
    "    \n",
    "#force_cudnn_initialization()\n",
    "def main():\n",
    "    # For reproducibility, comment these may speed up training\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Arguments\n",
    "#     parser = argparse.ArgumentParser(description='Training E2E asr.')\n",
    "#     parser.add_argument('--config', type=str, help='Path to experiment config.')\n",
    "#     parser.add_argument('--name', default=None, type=str, help='Name for logging.')\n",
    "#     parser.add_argument('--logdir', default='log/', type=str,\n",
    "#                         help='Logging path.', required=False)\n",
    "#     parser.add_argument('--ckpdir', default='ckpt/', type=str,\n",
    "#                         help='Checkpoint path.', required=False)\n",
    "#     parser.add_argument('--outdir', default='result/', type=str,\n",
    "#                         help='Decode output path.', required=False)\n",
    "#     parser.add_argument('--load', default=None, type=str,\n",
    "#                         help='Load pre-trained model (for training only)', required=False)\n",
    "#     parser.add_argument('--seed', default=0, type=int,\n",
    "#                         help='Random seed for reproducable results.', required=False)\n",
    "#     parser.add_argument('--cudnn-ctc', action='store_true',\n",
    "#                         help='Switches CTC backend from torch to cudnn')\n",
    "#     parser.add_argument('--njobs', default=32, type=int,\n",
    "#                         help='Number of threads for dataloader/decoding.', required=False)\n",
    "#     parser.add_argument('--cpu', action='store_true', help='Disable GPU training.')\n",
    "#     parser.add_argument('--no-pin', action='store_true',\n",
    "#                         help='Disable pin-memory for dataloader')\n",
    "#     parser.add_argument('--test', action='store_true', help='Test the model.')\n",
    "#     parser.add_argument('--no-msg', action='store_true', help='Hide all messages.')\n",
    "#     parser.add_argument('--lm', action='store_true',\n",
    "#                         help='Option for training RNNLM.')\n",
    "#     # Following features in development.\n",
    "#     parser.add_argument('--amp', action='store_true', help='Option to enable AMP.')\n",
    "#     parser.add_argument('--reserve-gpu', default=0, type=float,\n",
    "#                         help='Option to reserve GPU ram for training.')\n",
    "#     parser.add_argument('--jit', action='store_true',\n",
    "#                         help='Option for enabling jit in pytorch. (feature in development)')\n",
    "#     ###\n",
    "#     paras = parser.parse_args()\n",
    "    paras = Para()\n",
    "#     paras.config = './config/aishell_asr_example_lstm4atthead1-test.yaml'\n",
    "#     paras.name = None\n",
    "#     paras.logdir = 'log/'\n",
    "#     paras.ckpdir = 'ckpt/'\n",
    "#     paras.outdir = 'result/'\n",
    "#     paras.load = None\n",
    "#     paras.seed = 0\n",
    "#     paras.cudnn_ctc = False\n",
    "#     paras.cpu = False\n",
    "#     paras.no_pin = False\n",
    "#     paras.test = True\n",
    "#     paras.no_msg = False\n",
    "#     paras.lm = False\n",
    "#     paras.amp = False\n",
    "#     paras.reserve_gpu = 0\n",
    "#     paras.jit = False\n",
    "    setattr(paras, 'config', './config/cv11Lu_asr_lstm4atthead_allvocab-whisperclass.yaml')\n",
    "    setattr(paras, 'name', None)\n",
    "    setattr(paras, 'logdir', 'log/')\n",
    "    setattr(paras, 'ckpdir', 'LAS_ckpt/')\n",
    "    setattr(paras, 'outdir', 'result/')\n",
    "    setattr(paras, 'load', None)\n",
    "    setattr(paras, 'seed', 0)\n",
    "    setattr(paras, 'cudnn_ctc', False)\n",
    "    setattr(paras, 'njobs',0)\n",
    "    setattr(paras, 'cpu', False)\n",
    "    setattr(paras, 'no_pin', False)\n",
    "    setattr(paras, 'test', False)\n",
    "    setattr(paras, 'no_msg', False)\n",
    "    setattr(paras, 'lm', False)\n",
    "    setattr(paras, 'amp', False)\n",
    "    setattr(paras, 'reserve_gpu', 9)\n",
    "    setattr(paras, 'jit', False)\n",
    "    setattr(paras, 'gpu', not paras.cpu)\n",
    "    setattr(paras, 'pin_memory', not paras.no_pin)\n",
    "    setattr(paras, 'verbose', not paras.no_msg)\n",
    "    setattr(paras, 'finetune', False)\n",
    "    setattr(paras, 'binaryClass', True)\n",
    "#     force_cudnn_initialization()\n",
    "    print(torch.multiprocessing.get_start_method())\n",
    "#     torch.multiprocessing.set_start_method('spawn',force=True)\n",
    "    config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "    np.random.seed(paras.seed)\n",
    "    torch.manual_seed(paras.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(paras.seed)\n",
    "\n",
    "    # Hack to preserve GPU ram just incase OOM later on server\n",
    "    if paras.gpu and paras.reserve_gpu > 0:\n",
    "        buff = torch.randn(int(paras.reserve_gpu * 1e9 // 4)).cuda()\n",
    "        del buff\n",
    "\n",
    "    if paras.lm:\n",
    "        # Train RNNLM\n",
    "        from train_lm import Solver\n",
    "\n",
    "        mode = 'train'\n",
    "    else:\n",
    "        if paras.test:\n",
    "            # Test ASR\n",
    "            assert paras.load is None, 'Load option is mutually exclusive to --test'\n",
    "            from test_asr import Solver\n",
    "\n",
    "            mode = 'test'\n",
    "        elif paras.finetune:\n",
    "            assert paras.load is not None\n",
    "            from finetune_asr import Solver\n",
    "            mode = 'train'\n",
    "        elif paras.binaryClass:\n",
    "            # from train_whisperclass import Solver\n",
    "            from Whisper_Biclass_train import Solver\n",
    "            mode = 'train'\n",
    "        else:\n",
    "            # Train ASR\n",
    "            from train_asr import Solver\n",
    "\n",
    "            mode = 'train'\n",
    "\n",
    "    print(\"\\nUsing {} mode\\n\".format(mode))\n",
    "\n",
    "    for idx in range(0,5):\n",
    "        paras.config = f'./config/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-{idx+1}.yaml'#latest7k_4lstm.pth\n",
    "        # setattr(paras, 'load', f'./LAS_ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-{idx+1}_sd0/whisper-v2-15k-a-d.pth')\n",
    "        #要用vag01要改load_ckpt\n",
    "        config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "        solver = Solver(config, paras, mode)\n",
    "\n",
    "\n",
    "        solver.load_data()\n",
    "#         solver.print_model()\n",
    "        solver.set_model()\n",
    "        solver.exec()\n",
    "        del solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "traditional-cabinet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spawn\n",
      "\n",
      "Using train mode\n",
      "\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-1_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-17']\n",
      "Mozillacv11Dataset CTT5-1-17 found wav data: 21\n",
      "text len: 21\n",
      "remove None, then wav data: 21, text len: 21\n",
      "[VAGDataset] path: data_process, split: ['CTT5-5-17', 'CTT5-2-17', 'CTT5-3-17', 'CTT5-4-17']\n",
      "Mozillacv11Dataset CTT5-5-17 found wav data: 25\n",
      "Mozillacv11Dataset CTT5-2-17 found wav data: 38\n",
      "Mozillacv11Dataset CTT5-3-17 found wav data: 21\n",
      "Mozillacv11Dataset CTT5-4-17 found wav data: 25\n",
      "text len: 109\n",
      "remove None, then wav data: 109, text len: 109\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naomi\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\wav2vec2\\feature_extraction_wav2vec2.py:92: RuntimeWarning: Mean of empty slice.\n",
      "  normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:length].var() + 1e-7)\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\naomi\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\wav2vec2\\feature_extraction_wav2vec2.py:92: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:length].var() + 1e-7)\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss tensor(75.4340, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(74.6837, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(74.2329, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.9117, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.7987, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.6904, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.5984, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.5089, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.3530, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.3235, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.1891, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.1374, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.0495, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.9213, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.8410, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.7221, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.6978, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.5985, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.5024, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.3962, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.3168, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.2176, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.1353, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.0438, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.9525, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.8693, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.7395, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.7017, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.5713, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.5218, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.3954, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.2670, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.3284, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.2055, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.1113, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.9401, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.9013, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.8747, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.8102, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.6937, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.5640, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.5499, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.4552, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.3928, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.2125, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.2322, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.1582, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.1018, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.8799, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.9592, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.8005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.8188, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.7158, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.6053, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.5396, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.5238, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.3962, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.3724, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.2417, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.2473, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.1609, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.0978, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.0030, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.9174, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.8203, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.8553, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.7824, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.6853, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.6153, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.5582, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.4850, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.4266, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.3597, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.3069, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.2355, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.1599, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.0524, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.0657, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.9907, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.8131, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.9124, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.8500, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.7718, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.6978, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.6579, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.5574, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.5119, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.4630, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.4154, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.3215, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.2429, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.2187, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.2007, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.1290, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.0237, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.0263, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.9592, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.7869, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.9018, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.8006, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.7259, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.6675, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.6428, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.5917, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.5287, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.4629, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.3940, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.3916, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.3285, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.2728, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.2173, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.1632, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.1007, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.0745, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.9617, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.9951, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.9403, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.8674, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.8384, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.7796, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.7260, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.6723, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.6513, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.6034, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.5563, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.5013, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.4552, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.3776, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.3680, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.3179, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.2754, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.2176, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.1742, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.1449, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.0834, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.0390, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.0103, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-2_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-2-17']\n",
      "Mozillacv11Dataset CTT5-2-17 found wav data: 38\n",
      "text len: 38\n",
      "remove None, then wav data: 38, text len: 38\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-17', 'CTT5-5-17', 'CTT5-3-17', 'CTT5-4-17']\n",
      "Mozillacv11Dataset CTT5-1-17 found wav data: 21\n",
      "Mozillacv11Dataset CTT5-5-17 found wav data: 25\n",
      "Mozillacv11Dataset CTT5-3-17 found wav data: 21\n",
      "Mozillacv11Dataset CTT5-4-17 found wav data: 25\n",
      "text len: 92\n",
      "remove None, then wav data: 92, text len: 92\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.8846, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.8474, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.8504, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.8148, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.7708, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.6546, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.6989, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.6447, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.5716, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.5355, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.4651, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.3529, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.3896, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.3293, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.2548, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.1915, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.1260, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.0754, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(63.0165, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.9332, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.8932, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.8072, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.7151, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.6765, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.6558, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.5530, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.5269, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.4299, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.2966, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.3816, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.2407, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.2171, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.1018, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.1163, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.9132, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(62.0074, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.9073, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.7626, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.7901, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.7095, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.6772, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.6211, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.5181, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.5057, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.4348, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.2892, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.2850, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.1852, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.2070, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.1037, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.0820, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(61.0038, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.9943, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.9448, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.8763, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.7674, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.7792, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.6988, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.6106, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.5212, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.4745, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.5003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.4212, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.3865, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.3341, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.2507, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.1989, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.1392, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.0782, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.0598, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(60.0006, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.9488, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.9238, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.8847, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.8283, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.7644, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.7099, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.6617, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.6225, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.5640, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.5418, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.4687, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.4425, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.3913, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.3737, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.3122, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.2618, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.2001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.1456, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.1012, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.0333, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(59.0452, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.9851, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.9456, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.9110, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.7947, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.7697, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.7870, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.7159, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.7043, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.5566, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.6440, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.5829, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.5259, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.4011, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.4433, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.3817, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.3614, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.2593, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.2217, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.2515, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.2391, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.1907, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.1398, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.0554, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.1096, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.0521, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(58.0070, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.9495, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.9431, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.9032, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.8246, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.7825, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.7956, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.7586, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.7267, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.6149, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.6628, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.6393, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.5699, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.5622, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.5246, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.4864, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.4533, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.4199, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.4007, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.3506, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.3257, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.3056, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.2154, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.2373, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.1792, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.1851, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.1425, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.1040, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.0884, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.0521, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(57.0090, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.9983, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.9472, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.9340, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.9031, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.8660, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.8493, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.8202, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.7693, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.7373, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.7286, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.6808, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.6585, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.6548, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.6025, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "total_loss tensor(56.5953, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 92\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-3_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-3-17']\n",
      "Mozillacv11Dataset CTT5-3-17 found wav data: 21\n",
      "text len: 21\n",
      "remove None, then wav data: 21, text len: 21\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-17', 'CTT5-2-17', 'CTT5-5-17', 'CTT5-4-17']\n",
      "Mozillacv11Dataset CTT5-1-17 found wav data: 21\n",
      "Mozillacv11Dataset CTT5-2-17 found wav data: 38\n",
      "Mozillacv11Dataset CTT5-5-17 found wav data: 25\n",
      "Mozillacv11Dataset CTT5-4-17 found wav data: 25\n",
      "text len: 109\n",
      "remove None, then wav data: 109, text len: 109\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 109\n",
      "total_loss tensor(75.5396, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(75.1238, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(74.8382, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(74.6271, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(74.5065, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(74.3586, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(74.3148, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(74.1928, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(74.1222, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(74.0047, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.9262, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.8452, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.7417, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.6455, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.5430, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.4312, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.3591, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.2397, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.1704, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(73.0650, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.9660, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.8743, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.7659, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.6844, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.5917, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.4326, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.4130, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.3085, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.2208, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.1051, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(72.0575, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.9539, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.8447, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.7609, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.6683, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.5516, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.4510, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.4255, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.2567, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.1796, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.1705, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(71.0763, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.9317, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.8885, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.7530, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.7255, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.6188, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.5266, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.4361, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.3022, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.2792, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.2161, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.1160, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(70.0157, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.9678, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.8703, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.8010, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.6876, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.6165, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.5426, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.4204, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.3832, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.2941, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.2388, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.1544, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(69.0863, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.9801, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.9424, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.8675, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.7850, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.6929, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.6498, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.5782, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.5022, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.4334, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.3528, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.2740, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.1965, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.1316, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(68.0400, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.9620, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.9182, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.8494, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.8095, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.7078, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.6499, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.5964, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.5140, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.4741, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.4004, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.3353, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.2695, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.2120, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.1344, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.0799, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(67.0136, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.9027, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.9031, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.8171, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.7529, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.7064, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.6523, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.5758, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.5192, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.4641, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.3923, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.3410, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.2671, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.1499, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.1454, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.1318, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(66.0483, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.9570, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.9427, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.8801, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.8143, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.7135, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.7021, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.5975, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.5974, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.5427, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.4322, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.3595, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.3967, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.3123, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.2715, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.1877, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.1542, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(65.0992, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(64.9991, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(64.9913, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(64.9771, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(64.9070, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(64.8463, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(64.7901, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(64.7401, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "total_loss tensor(64.6925, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 109\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-4_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-4-17']\n",
      "Mozillacv11Dataset CTT5-4-17 found wav data: 25\n",
      "text len: 25\n",
      "remove None, then wav data: 25, text len: 25\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-17', 'CTT5-2-17', 'CTT5-3-17', 'CTT5-5-17']\n",
      "Mozillacv11Dataset CTT5-1-17 found wav data: 21\n",
      "Mozillacv11Dataset CTT5-2-17 found wav data: 38\n",
      "Mozillacv11Dataset CTT5-3-17 found wav data: 21\n",
      "Mozillacv11Dataset CTT5-5-17 found wav data: 25\n",
      "text len: 105\n",
      "remove None, then wav data: 105, text len: 105\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 105\n",
      "total_loss tensor(73.4133, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(72.8559, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(72.4647, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(72.1509, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(72.0700, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.9571, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.8698, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.7595, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.6343, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.5544, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.4126, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.3437, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.2301, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.0271, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.0600, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.7506, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.8632, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.7427, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.6252, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.4118, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.4081, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.3058, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.1826, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.0515, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.9307, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.8639, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.7649, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.6120, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.5631, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.3301, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.3460, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.2359, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.1263, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.0291, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.9609, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.8392, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.7492, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.6072, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.5230, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.4690, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.0847, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.2781, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.1304, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.0749, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.9188, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.8373, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.7586, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.6900, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.5909, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.4751, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.3587, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.3198, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.2174, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.1386, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.0264, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.9380, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.8411, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.7691, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.6945, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.6030, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.5204, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.3926, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.2898, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.2507, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.1760, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.9699, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.0191, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.9283, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.8456, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.7570, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.6426, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.5885, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.5375, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.4312, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.3467, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.2498, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.2032, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.0860, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.0623, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.9486, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.8346, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.8236, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.7277, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.6471, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.5293, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.5478, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.4452, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.3793, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.2941, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.1768, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.1385, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.1141, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.0293, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.9555, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.8856, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.8073, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.7475, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.6728, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.6030, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.4685, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.4708, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.4142, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.3515, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.2736, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.2059, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.1463, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.0737, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.9894, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.9462, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.8778, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.8239, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.7505, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.6981, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.6333, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.5676, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.5301, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.3853, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.4073, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.2864, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.3035, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.2330, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.1348, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.1174, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.0470, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.9973, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.9431, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.8887, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.8288, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.7335, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.7197, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.6561, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.6098, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.5310, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.5038, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.4403, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.3626, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.3330, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.2459, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.2243, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.1858, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.1294, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(61.0529, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-5_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-5-17']\n",
      "Mozillacv11Dataset CTT5-5-17 found wav data: 25\n",
      "text len: 25\n",
      "remove None, then wav data: 25, text len: 25\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-17', 'CTT5-2-17', 'CTT5-3-17', 'CTT5-4-17']\n",
      "Mozillacv11Dataset CTT5-1-17 found wav data: 21\n",
      "Mozillacv11Dataset CTT5-2-17 found wav data: 38\n",
      "Mozillacv11Dataset CTT5-3-17 found wav data: 21\n",
      "Mozillacv11Dataset CTT5-4-17 found wav data: 25\n",
      "text len: 105\n",
      "remove None, then wav data: 105, text len: 105\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 105\n",
      "total_loss tensor(72.5484, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(72.3325, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(72.1624, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(72.0674, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.9784, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.9100, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.8279, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.7432, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.6394, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.5488, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.4837, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.3799, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.2894, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.2004, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.1328, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(71.0250, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.8845, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.8324, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.7576, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.6493, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.3660, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.5400, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.3672, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.2002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.2557, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.1208, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(70.0160, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.9322, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.8394, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.7139, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.6405, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.5844, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.4876, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.4017, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.3154, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.1955, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.1415, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(69.0150, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.9663, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.8895, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.8146, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.7078, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.6178, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.4800, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.4416, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.3618, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.3461, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.2450, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.1615, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(68.0697, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.9801, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.8976, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.8266, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.7390, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.6495, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.6057, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.4729, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.4452, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.2559, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.3478, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.2396, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.1371, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.0538, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(67.0008, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.9281, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.8541, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.7797, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.6959, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.6446, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.5728, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.4943, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.3759, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.3555, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.2944, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.2120, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.1602, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.0322, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(66.0541, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.9629, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.8432, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.8326, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.7659, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.6956, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.6212, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.5586, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.4374, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.4154, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.4118, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.3262, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.2762, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.2176, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.1031, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.0919, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(65.0086, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.9569, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.9005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.8406, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.7942, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.6712, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.5393, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.5879, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.5966, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.5076, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.4311, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.3820, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.3079, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.2901, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.2403, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.1744, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.0972, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.0650, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(64.0044, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.8726, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.8925, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.8789, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.7836, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.6384, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.6639, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.6460, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.5800, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.5290, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.4580, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.4508, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.4008, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.3230, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.3099, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.2346, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.1567, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.1524, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.1055, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.0128, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(63.0114, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.9404, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.8993, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.8606, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.7607, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.7704, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.7163, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.6561, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.6299, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.5533, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "total_loss tensor(62.5390, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 105\n",
      "15001\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da76b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.device_count()\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "# torch.cuda.device_count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval.py --file ~/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6359ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'data_process/CTT5-2-2/2CTT.wav'\n",
    "# v1: ['我看到有一對兄妹感覺是想要偷吃餅乾然後那個哥哥踩的椅子好像快跌倒了這樣子然後還有媽媽在洗碗可是水潮都水水龍頭沒有關所以水一直漏出來這樣子OK應該這樣子吧然後窗外好像有一些東西']\n",
    "# v2: ['我看到有一對兄妹感覺是想要偷吃餅乾然後那個哥哥踩的椅子好像快跌倒了這樣子然後還有媽媽在洗碗可是水槽的水 水龍頭沒有關所以水一直漏出來這樣子窗外好像有些東西']\n",
    "# v3: ['看到有一對兄妹感覺是想要偷吃餅乾哥哥踩的椅子好像快跌倒了然後還有媽媽在洗碗可是水槽的水溫度沒有關所以水一直漏出來窗外好像有些東西']\n",
    "\n",
    "# 'data_process/CTT5-1-2/33CTT.wav'\n",
    "# v1: ['在內容內容你看到什麼就說什麼你覺得是什麼就是什麼沒有標準的答案隨便講一個兩個三個四個三個三個不講不做事的']\n",
    "# v2: ['在內容內容一個兩個三個四個三個三個不講不做事的']\n",
    "# v3: ['在內容內蒙一個兩個三個四個三個三個不講不做事的']\n",
    "\n",
    "# 'data_process/CTT5-3/57CTT.wav'\n",
    "# v1: ['有一個小孩子在拿櫃台那個櫃上的餅乾但是站在的椅子上會非常危險椅子有傾斜有跌下來的可能那一個媽媽在洗碗槽前面洗碗那洗碗槽裡水已經流下來流了滿地他自己並不知覺他繼續做他的工作']\n",
    "\n",
    "# 'data_process/CTT5-4/21CTT.wav'\n",
    "# v1: ['男孩子要拿東西板凳沒凳好倒下來這樣很危險還有媽媽在洗碗盤那水滿出來了其他的都沒']\n",
    "\n",
    "# 'data_process/CTT5-4/6CTT.wav'\n",
    "# v1: ['哥哥拿餅乾坐在電子椅子上,椅子快要倒下來了然後媽媽在洗這個餐具的時候水都已經漏出來了大概就是這樣子吧']\n",
    "\n",
    "# 'data_process/CTT5-4/7CTT.wav'\n",
    "# v1: ['看到了一個媽媽在洗碗然後水潮的水就滿出來了然後兩個小朋友在拿餅乾有一個餅乾就是椅子快掉下來就是快跌倒的樣子然後就這樣']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f4084e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath:  data_process/CTTsegment_remove/100CTT.wav\n",
      "[0. 0. 0. ... 0. 0. 0.] 16000\n",
      "torch.Size([1, 816304])\n",
      "filepath:  data_process/CTTsegment_remove/10CTT.wav\n",
      "[0. 0. 0. ... 0. 0. 0.] 16000\n",
      "torch.Size([1, 355968])\n",
      "filepath:  data_process/CTTsegment_remove/11CTT.wav\n",
      "[0. 0. 0. ... 0. 0. 0.] 16000\n",
      "torch.Size([1, 246208])\n",
      "filepath:  data_process/CTTsegment_remove/12CTT.wav\n",
      "[0. 0. 0. ... 0. 0. 0.] 16000\n",
      "torch.Size([1, 570816])\n",
      "filepath:  data_process/CTTsegment_remove/13CTT.wav\n",
      "[0. 0. 0. ... 0. 0. 0.] 16000\n",
      "torch.Size([1, 1961152])\n"
     ]
    }
   ],
   "source": [
    "# decode about 30 sec\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Wav2Vec2FeatureExtractor, Wav2Vec2Model\n",
    "import soundfile as sf\n",
    "\n",
    "# load model and processor\n",
    "device = torch.device('cuda:0')\n",
    "model_checkpoint = \"TencentGameMate/chinese-wav2vec2-large\" # distil-whisper/distil-large-v2\n",
    "processor = Wav2Vec2FeatureExtractor.from_pretrained(model_checkpoint)\n",
    "# outofCUDA\n",
    "model = Wav2Vec2Model.from_pretrained(model_checkpoint).to(device)\n",
    "# whisper = WhisperModel.from_pretrained(model_checkpoint).to(device)\n",
    "# model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"zh\", task=\"transcribe\")\n",
    "model.config.output_attentions = True\n",
    "model.config.output_hidden_states = True\n",
    "\n",
    "path = \"data_process/CTTsegment_remove\"\n",
    "transcriptionlist = pd.DataFrame()\n",
    "for f in os.listdir(path):\n",
    "    filepath = path + '/' + f\n",
    "    if os.path.isfile(filepath) and f.find(\"wav\") != -1:\n",
    "        print(\"filepath: \", filepath)\n",
    "        wav, sr = sf.read(filepath)\n",
    "        temp = \"data_process/CTTsegment_remove/temp.wav\"\n",
    "        sf.write(temp, wav, 16000)\n",
    "        wav, sr = sf.read(temp)\n",
    "        print(wav, sr)\n",
    "        # import librosa    \n",
    "        # wav, sr = librosa.load(filepath, sr=16000) # Downsample 44.1kHz to 8kHz\n",
    "        # print(sr)\n",
    "        # outofCUDA\n",
    "        # input_features = processor(wav, sampling_rate=sr, return_tensors=\"pt\").input_features.to(device)\n",
    "        \n",
    "        input_values = processor(wav, sampling_rate=sr, return_tensors=\"pt\", padding=\"longest\").input_values.to(device)  # Batch size 1\n",
    "        print(input_values.shape)\n",
    "        # retrieve logits\n",
    "        logits = model(input_values).last_hidden_state\n",
    "        \n",
    "        # # take argmax and decode\n",
    "        # predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        # transcription = processor.batch_decode(predicted_ids)\n",
    "\n",
    "        # print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath:  data_process/Lu_CTTdeletion_o_d/002_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['四層桃']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/002_2.wav\n",
      "['媽媽在洗碗筷,可能是想一些心事吧']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/002_3.wav\n",
      "['洗的有咖啡杯啊盘子啊这厨房倒是很干净他这样子这个水喷的到处都是他还穿着围裙拿个抹布在擦擦这个盘子好像在想心事的样子所以他的孩子在这里这样他都不知道水溢出来他也不知道琉璃台应该是讲小孩子吗小孩子够是不是要拿点心吃不是他弟弟就是哥哥']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/002_4.wav\n",
      "['讲小孩子吗?小孩子要够是不是要拿点心吃不是他弟弟,是哥哥']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/002_5.wav\n",
      "['夾糖 方糖的夾子算盤手風琴 廣球拍 羽毛球拍這個是圓規表 圓規尺 圓規...喔不是 這個量尺量角度的應該量度 電梯 手扶器這個就是那個要測量的那個腳架我們會叫它三腳架 倒把對 這個這也是樂器之一嘛對']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/002_6.wav\n",
      "['我會叫它三角架 棗靶對 這個這個是樂器之一嘛對應該是不太認識它應該講是豎琴輪椅這個是窗台上的花架嗯 很好這個是河馬這不就是河馬嗎我們會叫海馬蘑菇這個是那個愛斯基摩人的住的屋子什麼什麼什麼我不會說這個圓龜']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/002_7.wav\n",
      "['我還以為是吉姆人的住的屋子什麼的,我不會知道,原歸']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/003_1.wav\n",
      "['猪没差人,野狗子,老虎,想不起来,动物,几三不三动物呢,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪,猪']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/003_2.wav\n",
      "['都想不起来了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/003_3.wav\n",
      "['桃源县新竹县新竹市台中县台中市这都是台南了台南市台南县这是房子房子这是我们的房子这是什么是树啊是瓜瓜想不起来了他给这个病吧病他要给他拿下吃他这是拿了什么我看不懂他就是这个小姐问他要吗要他吃就他看不懂了小女孩男孩']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/003_4.wav\n",
      "['我看不懂他就是这个小姐问他要吗要他吃就他看不懂了小女孩男孩也是女孩啊他也没有写在哪里这是房子啊凳子他站到凳子上他给你拿那个什么蛋糕啊结果他会摔下来这个好像是个花呀什么房子插背吧嗯这是妹啊不是说窗子等于是妹啊这是个什么花树那个那个水里头那个叫什么']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/003_5.wav\n",
      "['窗子等于什么呀这是个什么花树那个水里头那个叫什么老的叫什么骆带动物的就是挂鸟带我都挂不晓得什么前辈这个我不懂这个剪刀这个就是那个什么小孩玩的什么对对听的骆驼这是一个什么这锯子这个是钢琴吧鸦琴对']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/003_6.wav\n",
      "['这是一个什么哦哦这个是钢琴吧有几对哦一家哦哇牛对种那个叫什么牛犀牛对这算是茶杯还是什么啊那个漏水的漏水这个都不晓得叫什么哦夹子饭盘这个是人家探那个时候拿那个什么嗯嗯这是打羽毛球排队这是叫那个什么吃的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/003_7.wav\n",
      "['这是什么']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/003_8.wav\n",
      "['这又是什么?这是做那个就是人走不动的腿毛病有毛病做车子嘛坐轮胎坐上去一个人陪着他走这是叫什么的?这是叫什么动物?对呀,在海里头我都想着这种玩意这是什么?这是房子嘛对呀,就住在房子里面这是花土用的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/003_9.wav\n",
      "[' Batuyun.']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/004_1.wav\n",
      "['毛了狗了鸡了鸭了就是毛了狗了鸡了鸭了什么公鸥了水鸡小鸟了嗯地上拔的虫了地上拔的还有什么水里边的鱼了天上飞的鸟了苹果香蕉枣子梅子水梨红梨葡萄还有梅子青梅梅子了嗯苹果香蕉还有什么桃老朽枝这个差不多这样红的黄的蓝的绿的青的白的差不多还有黑的嘛']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/004_10.wav\n",
      "['这东西怎么识别吗这是什么那么这个叫什么别约议了别约议了三个月的一期吗两期这个好像楼梯啊三角墙烧死这个是里面的墙相对嘛都有些奉献了都推出了这个一纸嘛书一我东西就是被内容的推出能处在里面吗这个是什么相对啊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/004_11.wav\n",
      "['可以说人住在这里边嘛这个是什么啊香槟啊花园花园里边的家属李伯家属这是什么鸟蝶翅嘛这个是相公这个是一个什么毛子嘛什么毛铁桶啊那么勾动啊努力动这别人也有别人也有就是什么别人也有']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/004_2.wav\n",
      "['差不多這樣']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/004_3.wav\n",
      "['江湖南渡燕林嘉峪台南高雄屏東還有什麼?掛列台東還沒講到高雄台內嘉峪台中南渡漳華跑了我們出江湖嘉峪了我們出江湖他這個按點燈了什麼按什麼這個拿棍棍拿個槍拿那個什麼啊?不知道拿紙巾布把那個擦擦這個孩子的家我拿這個東西放到上面這個水的大概六升這個紙網裡邊的這個']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/004_4.wav\n",
      "['這個孩子的家我拿這個東西放到上面這個這個這個這個']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/004_5.wav\n",
      "['這個什麼?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/004_6.wav\n",
      "['跟這個角度不一樣']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/004_7.wav\n",
      "['这个是什么东西']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/004_8.wav\n",
      "['这个人要的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/004_9.wav\n",
      "['这个是红红的细腻这个是这个月的三九六七七九万啊六七七这个是毛啊六六六六斗嘛这个茄子嘛茄子嘛茄子大个茄子嘛这个是茄子大个冰子嘛就这么茄子嘛这个啊斗嘛这个是这个东西的身边嘛这是什么那么这个叫什么手筋啊毛刨了别的也了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/005_1.wav\n",
      "['貓狗馬老鼠牛老虎熊貓鳥猩猩大鯨鹿老豹 蝙蝠魚喔 月上啦雞鴨鵝羊鹿雞香蕉 鳳梨櫻桃 草莓桃子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/005_2.wav\n",
      "['可以告訴我']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/005_3.wav\n",
      "['青色蘋果綠桃紅色珠黃色灰色鵝黃色藏青色寶藍普魯士藍']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/005_4.wav\n",
      "['南同縣宜蘭縣基隆市華仁縣台東縣群龍縣高雄縣高雄市台南縣台東市差不多了媽媽在洗盤子水都流下來了小孩子在偷拿美心西餅的餅乾他站在陣營上陣營快倒了女兒跟兒子在偷吃餅乾']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/005_5.wav\n",
      "['OK,她站在陣營上,那陣營快倒了,就是這個女兒跟兒子在偷吃點餐,已經快倒了。因為那個水一直流,她媽媽沒注意看,那麼窗戶外面是一個庭院,庭院有花草啊,然後呢,琉璃上面有一個飛水的盤子,所以已經快到媽媽的腳上了,她沒注意看。OK,還有什麼呢?沒有啦,大概差不多了。']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/005_6.wav\n",
      "['這是廚房他們在偷吃餅乾啦他們在偷這個那你這個呢?這個可能是想吃的豆子還是說小小的,小聲一點這是窗簾窗戶抹布在擦這是流理台的樹一棵樹上面的花五花牛鉛筆香菸棧剪刀清潔器漏頭黑標']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/005_7.wav\n",
      "['一棵樹上面的花 花牛 仙人掌 剪刀 清真器 鹿頭 飛鵰 巨頭 青蝇 長衣架 金字塔 一朵花 犀牛 鹿頭 夾子 上牌 手風琴 球盤一個圓形的尺啦一個應該是也不能叫圓規就是一把圓形的這個我就清楚了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/005_8.wav\n",
      "['這個應該是一個花圃架吧']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/005_9.wav\n",
      "['花籃,鋁包,這個是去年冰冰完,這個圓規']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/006_1.wav\n",
      "['動物老虎啊動物很多牛啊馬啊兔子啊羊牛啊狗兔子雞也是鴻鴨也是鴻鵝鳥羊啊都可以講嗎羊啊你也可以講嗎吃的水果是吧鳳梨水果很多鴻羊桃西瓜南蛤一下下想都想不出來想不出來西瓜']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/006_10.wav\n",
      "['弹琴用的吗?我不知道我知道这张弹琴这一推移这好像我们比较不认识轮椅就花架这个是什么?这个也是动物吗?对我不晓得呀我知道我看错这个是我们农村的那个那个什么我不会讲蘑菇的样子这个是什么我都不知道这个地方的人我不晓得呀结果那个我们在这取笑人什么讲我也不会讲花针用的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/006_11.wav\n",
      "['结果那个我们在学校里社工讲话我也不会讲话都用了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/006_2.wav\n",
      "['洋桃西瓜南...一下子想都想不出來想不出來西瓜洋桃水耳木瓜洋桃講過了是吧紅的綠的綠色紅色黃色粉紅色黑的我講過沒有黑金黃色想不出來我也沒重複的金黃色金黃色哦台北啊你再講一次']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/006_3.wav\n",
      "['嗯想不出来我有没有重复的金黄色金黄色哦台北啊你再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再再']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/006_4.wav\n",
      "['但是不行哦 这个怕船怎么钻对它那个水龙头就是水就会满出来的那这个呢就很危险哦它椅子没有放好啊没有摔跤那你要我讲什么我不知道哎哦看到有东西它的哪个它躺嘛它不想它的脚要我讲我看它就很危险现在椅子已经歪了嘛好像很还好没有摔跤吧嗯我不知道要说什么哎我觉得这个水没有关好嘛哦最近已经']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/006_5.wav\n",
      "['没有睡觉吗我不知道要说什么我觉得这个水没有关好已经爆出来了水龙头没有关它在擦盘子我觉得没有什么我不晓得你要我说什么水龙头啊就柜子就这样子我还是不知道窗帘这个窗子这里我看不出来有什么东西这是路吗是路吗我没有感觉好像是厨房是不是']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/006_6.wav\n",
      "['这是鹿吗?是鹿吗?好像是厨房是不是?好像在喊叫是不是?我不晓得我觉得它在喊叫的样子是不是?好像在危险是不是?这个就是碗盘是吗?这个如果说是我讲的话就是我们厨房里面的那个洗碗槽啊什么的盘子它在擦盘子毛巾嘛是吧?这是树这是光影哦?这个是什么我不晓得']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/006_7.wav\n",
      "['就是什么我不知道']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/006_8.wav\n",
      "['我们那时候想挂衣服才能挂衣架这我看不懂国外的建筑物屋顶啊这是什么这是花哎呦我这个是什么牛啊我就不知道是什么牛猪犀牛骆驼那个钳子是不是算盘就是那个violin是不是这是风琴就打球的那个什么球拍这个我们这些学校已经画图用的那个什么我都不知道这梁啊我不晓得这叫什么']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/006_9.wav\n",
      "['我们在学校已经画图用的那个叫什么我都不知道这梁啊我不晓得叫什么就是梯那个上下的那个楼梯就是人家拍照用的那个对一架这样子我不知道叫什么我知道叫什么三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三三']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_1.wav\n",
      "['動物都會嘛牛啊象啊猴子啊豬也算動物雞啊也是動物雞啊是不是算動物象也是動物狗啦貓啦牛']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_10.wav\n",
      "['這是那個']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_11.wav\n",
      "['那個就是金銅是不是有門的?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_12.wav\n",
      "['這個']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_13.wav\n",
      "['畫圖的圓規是兩尺這個是電梯這個是在測量三角架這個是掃把這個是橋葉器是不是我不會講樹群']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_14.wav\n",
      "['這叫什麼東西啊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_15.wav\n",
      "['這是叫什麼東西啊?我常常他們這個...海藻不是海象,不是喔這個洋菇這個這個這個釣堡啦蒙古堡這個冰壺這個煙龜']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_2.wav\n",
      "['猴啦,猫啦,牛,有讲过的,水果,梨子,桃子,茄子,奶茄,莲莲,西瓜,凤梨,水果,很多水果嘛,']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_3.wav\n",
      "['西瓜、鳳梨、水果']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_4.wav\n",
      "['那個像那個那個叫什麼名字']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_5.wav\n",
      "['鄉是隨便講鄉村鄉村台北鄉是台北鄉那個八里鄉什麼三芝鄉廈門鄉什麼很多了還有什麼鄉事事很多了我們講一聽這個最外文的關鍵這個最外文']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_6.wav\n",
      "['嗯這個是要拿東西啊這個這個叫什麼放在椅子上啊拿這個好像是拿那個那個水果什麼的然後呢然後那個那個椅子倒下來這個是小姐嘿那個樣子是開水龍頭']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_7.wav\n",
      "['開水龍頭']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_8.wav\n",
      "['沒有啦,差不多啦就這樣吼這個叫他這個小姐嘛叫這個小妹叫這個他的哥哥然後這個叫他好吼好好像是拿水管給他吹這個這個是那個煮飯那個水瓶洗碗的這個台這個水很亂流下來啦這個水太多啦']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/007_9.wav\n",
      "['水洗碗的這個台這個水碗它會流下來這個水太多了嗯,流下來這個是它的盆子這是廚房那個在裡面放沙子我們叫什麼櫃台廚房櫃台廚房室這個是那個裡面家裡的那個可能是鼻子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/008_1.wav\n",
      "['鸡毛狗牙牛羊猪靠着帽子还想说吗?想不到了哎呀那那那那那想不起来了闹书猫咪想不起来了哎呀牛羊苹果洋葡萄栗子三美香就够了香蕉套子裙子想不起来了尽量想了桃李杏想不起来了桃李杏还有什么红红蓝白黑']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/008_2.wav\n",
      "['想不起来了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/008_3.wav\n",
      "['想不起来了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/008_4.wav\n",
      "['想不起来了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/008_5.wav\n",
      "['这边有漏纸啊漏纸啊他妈妈的吸盘子啊飞溜出来了没什么讲不出说来他这个这个这个处里面装什么东西啊就这么多了没什么话讲了这是一棵树啊这是个挖柳啊这是铅笔啊这是仙人杖啊剪刀这个医生用的那个那个叫做什么听证的听证器啊这个骆驼这个是什么打针的飞镖这是个橘子这是个扣铅衣甲这是个什么东西这个衫啊针子它这个花']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/008_6.wav\n",
      "['这是个枸杞这是什么东西这是山这是花这是豆子拼装的时候用的叫核豆吧楼豆夹子扇盘竖甲手风琴大网球这是叫机闪吃吗?蓝圆形的机闪吃啊这个是楼梯三个甲扫这是个手风琴']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/008_7.wav\n",
      "['这些是三个架,扫,这是个手风琴,钢琴,这是个什么,手琴,这个是什么,这是个窗户,这个是架子,立架,花架,这个是天马,水里面的小狗,这个是个城堡,沙漠里面的,沙漠里面的,不知道,远归啊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/008_8.wav\n",
      "['沙漠里面的地形什么不知道远归远方']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/009_1.wav\n",
      "['老虎、狮子、豹子、豺狼老虎、狮子、豹子、豺狼鸡、牛、犀牛、牛、豺狼兔子、马、牛、羊马、牛、羊、狗鸡、鸭鸭、鸭、鸭、鸭鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭、鸭']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/009_10.wav\n",
      "['曹也曹长得很栗草如茵啊她的心情很愉快她的儿女儿子爬在踩着凳子爬上去拿这个饼干拿柜子里面的饼干姐姐妹妹伸着手向她仰']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/009_11.wav\n",
      "['这个饼干 拿柜子里面的饼干 姐姐妹妹伸着手向他要 瓜铃 春饼 仙人掌 这是清真寺 环月 我没见过好像是巨子一样 口香 口琴 三角锥 金字塔这是什么花 这么多花 这个呢 这个溪流']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/009_12.wav\n",
      "['花瓣 溪流 绿粉 漏斗 栗子 蒜板 手风琴 网球牌 半圆龟']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/009_13.wav\n",
      "['這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/009_14.wav\n",
      "['哦有什么洞啊这是那个蘑菇啊防空洞啊不是不是防空洞地窖啊不冰窖啊这个才是那个原规很好下面没有了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/009_2.wav\n",
      "['好']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/009_3.wav\n",
      "['对']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/009_4.wav\n",
      "['台北市台北縣桃園市桃園縣新竹市新竹縣新西縣市台南市台南縣嘉義市嘉義縣高雄市高雄縣屏東市屏東縣然後還要鄉鎮北投鎮市林鎮縣市北投鎮市林北投區市林區不算鎮嗎縣市板橋市']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/009_5.wav\n",
      "['陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西陕西']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/009_6.wav\n",
      "['那么她的孩子就在爬在爬高去拿这个饼干用心洗饼拿饼干姐姐弟弟在爬姐姐在哥哥哥哥在爬妹妹在伸手向她要椅子已经歪斜着快跌倒这是厨房了可以讲她开妈妈在厨房里面洗这个碗盘被子看着外面的这个风']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/009_7.wav\n",
      "['他在里面洗碗盘被子看着外面的景色很悠闲地站在这儿洗那么他的两个孩子他的儿子跟女儿儿子爬在椅子上去拿这个饼干妹妹生的时候他也就弟弟妹妹他的厨房']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/009_8.wav\n",
      "['妹妹生的时候像她也她妈的就弟弟妹妹她的厨房布置的很好啊还有窗户有窗户对外可以看一边做饭一边可以看到外面的风景同时厨房里面的这个油烟也可以很容易散出去这边她我就说她这个厨房呢布置的很好啊这边']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/009_9.wav\n",
      "['很容易散出去']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/010_1.wav\n",
      "['就是所有的动物就这样']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/010_2.wav\n",
      "['草莓、楊桃、葡萄、榴槤、蓮霧、橘子、香蕉台灣的水果都有了吧很厲害台灣的水果都有可以嗎?還是還要再?通常的紅橙黃綠藍靛紫是一個顏色其他都是混合色嘛粉紅色啦粉紅色啦粉紫色啦什麼茯綠色啦什麼天藍色啦電藍色啦這個鵝黃色啦']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/010_3.wav\n",
      "['紅色啦、粉紫色啦什麼湖綠色啦什麼天藍色啦、電藍色啦這個鵝黃色啦、米黃色啦牛奶色啦、翠綠色啦還有銀白色啦、金色啦那顏色很多啦那這個要背起來很多咧台北市從基隆市開始好基隆、台北基隆市、台北市台北縣、桃園縣金竹縣、金竹市']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/010_4.wav\n",
      "['基隆市、台北市、台北縣、桃園縣、金竹縣、金竹市苗栗縣、南投縣、彰化縣、雲林縣嘉義縣、嘉義市、台南市、台南縣高雄縣、高雄市、屏東縣、台東縣、花蓮縣、宜蘭縣']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/010_5.wav\n",
      "['台東縣、花蓮縣、宜蘭縣']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/010_6.wav\n",
      "['剛拿的時候就已經開始要摔倒了這個媽媽在洗碗槽洗衣服可是洗碗槽可能水堵住了所以水都漏出來了窗戶外面的墊子草皮看起來還不錯外面的天氣也還不錯從水槽裡漏出來的水已經把這個媽媽的鞋子濃濕了這個媽媽在擦盤子她的窗簾開了一半餅乾上面的櫃子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/010_7.wav\n",
      "['你家的座椅呢']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/010_8.wav\n",
      "['还有咖啡在厨房这是一棵树蝌蚪仙人掌剪刀听诊器骆驼双风筒飞镖板具口琴衣架金字塔花细牛骆驼夹子算盘手风琴球拍分角器羊龟分节叫分头龟了这个是垫腹机三角架扫把吐气']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/010_9.wav\n",
      "['分角器,羊龜,分节叫分肚龟了这个是垫腹机三角架,扫把,这个,吐气,灰花架,这个,海马,香菇,艾斯基姆的冰屋这个是羊龟']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/011_1.wav\n",
      "['动物狗猫猪羊鸡犬豉马牛羊苹果香蕉梨桃红梨橘子芒果枫黑的白的红的蓝的黄的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/011_2.wav\n",
      "['黑的白的紅的藍的黃的紫的綠的金的金色的深綠的淺紅的深黃的藍的紫的紫的有了粉的黑的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/011_3.wav\n",
      "['算了算了台北市台中市台南市高雄市他站在椅子上拿東西這水龍頭放著水在洗東西雨窗後洗碗他站在椅子上拿東西這是什麼鏡子水龍頭這是廚房這是臥房']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/011_4.wav\n",
      "['这个是什么 镜子水龙头 这个是厨房这是卧房这个是什么 主妇 妹妹她让他拿蛋糕椅子 椅子要叠交了窗帘 窗户 睡觉这个是个人 水龙头 放水鸡碗 碗盘用手擦碗擦盘子 枕布 橱柜 树蜗牛 笔 仙人掌 剪刀']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/011_5.wav\n",
      "['他叫手']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/011_6.wav\n",
      "['它叫什么风琴啊网球啊网拍的尺 三角尺圆规尺用这个尺圆规尺这个是踢电梯三角三角尺三角规规尺我看这个去了这个照相机的架子三角架扫把这个叫这叫什么琴啊竖琴竖琴轮椅挂架这叫什么']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/011_7.wav\n",
      "['这叫什么琴呢树琴,树琴,轮椅,花架这叫什么叫什么龙啊,什么龙不知道叫什么龙的海龙啊香菇这个是厨道,做的地不是烧火的地方油煲叫那个叫什么煲啊,这个圆规']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/011_8.wav\n",
      "['吳陽輝']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/012_1.wav\n",
      "['水果呢?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/012_2.wav\n",
      "['西瓜冬瓜水果呢台灣芒果講過了還有還有一種還是很多種']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/012_3.wav\n",
      "['這個小孩在開廚子拿蛋糕吃這個小妹妹來接應他他媽媽在洗盤子水淹出來了盤子還沒有洗好窗戶外面有很多草']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/012_4.wav\n",
      "['他媽媽在洗盤子水淹出來了盤子還沒有洗好窗戶外面有很多草花草窗簾有打開窗簾還有那個窗戶廚具椅子椅子 椅子點心櫃廚房的櫃子往旁旁往男孩子他爬在椅子上面去拿東西結果差一點倒下來椅子倒了那個抹布擦布這個是']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/012_5.wav\n",
      "['他爬到椅子上面去拿东西结果差一点倒下来椅子倒了那个抹布 擦布这个是洗碗台 书蜗牛 鲜笔这个是热带之物仙人掌 剪刀 耳机 听筒 骆驼 标枪 标针 锯子 口琴 挂钩就是衣挂 金字塔 好像是菊花水牛 这个叫什么 叫水牛啊有鼻子的 犀牛 骆驼']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/012_6.wav\n",
      "['好像是菊花水牛这个叫什么叫水牛啊有鼻子的犀牛漏斗 茄子蒜盘风琴手风琴网球拍两脚气电梯三脚架照相机啊扫把竖琴是吧四脚竖琴龙椅老年龙椅这个花架这个想不起来海马香菇山菇这个是什么灶烧火的那个烧火烧炉子的那个']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/012_7.wav\n",
      "['这个想不起来,海马、香菇、山菇这个是什么灶,烧火的那个烧火烧炉子的那个灶,炉灶就是烧油,这就是油,两脚气这个是,嗯,呦,圆龟,圆龟']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_1.wav\n",
      "['鸡呀狗,猫,这我们家里都有的,花形一家都有的还有呢?羊,牛,这我家里都是有的再一个,猫很好这都是我家里有的再来再想想不起来咯,想得太多了,有的时候怕复杂了好了就在这算了鸡,牛,这都是我以前小时候在乡下家里有的呀,这些东西']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_10.wav\n",
      "['曬一次的 因為太陽曬什麼濕的東西他在做什麼他在做一個小凳子他在吃的這個東西叫他拿給他這是屎啊 一口屎啊這個我就不知道了這個鼻這個我就不曉得了這個一個夾子這個掃的 啥東西的啥']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_11.wav\n",
      "['這是一個夾子這是一個刷刷東西的刷這是一個牛這是一個牛牛是這些羊那個大是那個叫什麼這是一個駱駝這是一個鉛筆這是一個飛機']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_12.wav\n",
      "['這個呢?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_13.wav\n",
      "['這個花嘛這個是牛啊另外一種動物叫什麼雞這是一個杯子這是拿東西的拿月的東西這個呢這個算盤這個什麼東西這個網球打球的那個東西']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_14.wav\n",
      "['这些东西我哪里会记得这样的啊这也不知道啊楼梯这个是刀这个是照相机啊我不知道这个是刷子刷子啊这个上面的嗯?那什么也不知道哎呀一个乐器乐器啊吹笛啊这些东西我都不知道']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_15.wav\n",
      "['這個上面的,嗯?叫什麼?也不知道,哎呀,這個月氣,月氣吹掉這些東西我都不知道這個是椅子啊,坐在上面的別人坐的椅子,對我沒有事情,我好玩也坐啊坐著好玩啊這個椅子叫做,藍胎啊是什麼東西我就不知道什麼東西哦,種花的花,花車子,花棒棒我也不曉得是什麼東西,不知道這個呢?這個是那個叫什麼?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_16.wav\n",
      "['花圈子 花棒棒我也不曉得那是什麽東西不知道這個呢這個是那個叫什麽在地下種的那個叫什麽哎呀這個東西拆好久了紙瓦這個叫紙瓦這個也不知道冰淇淋啊這個是那個那個叫什麽人呢劃頭的人那種工藝工作的人做的這個東西還要做要這個尖尖要這個頭']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_17.wav\n",
      "['画头的人那种是工艺工作的人做的这个东西要这个尖尖要这个头头头的这样的画头']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_2.wav\n",
      "['牛,这都是我以前小时候做香菜酱油的呀,这些东西哎呦,水果我家里也有不少哎,我就记不得了米,吃是吃,吃了就想不出名字来的,有的是啊橘子,桃,香蕉']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_3.wav\n",
      "['橘子桃香蕉我家裡都記不起來我們家裡整吃的東西都整好多因為家裡大嘛 群體用人多嘛就給你弄東西這樣子拿來好吃就行了 叫名字紅的 黃的 藍的 綠的藍的 黑的 也是太多了啦搞不清楚']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_4.wav\n",
      "['中的 绿的 蓝的 黑的 也是太多了搞不清楚嘛叫粉红色的 绿色的 棕色的 红色的 黄的 记不得了看着都知道家里都有这些东西家里大嘛 人又多嘛找这些人没有事情就给你蹬着洗着的现在好多年都没有了还有这种']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_5.wav\n",
      "['我早就跟這些人沒有事情就跟你登早寫稿的現在好多年都沒搞還有這種好國母那你先台灣有南港有香港還是台灣也是有好多地方我先說台北基隆一下子就想不出來了我們夫妻家裡都有好多身份的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_6.wav\n",
      "['哎,基隆,一下子就想不出来了我们夫妻家里都有好多先生了,都有嘛哎呀,这个主要就是奔来一下的台湾,基隆,台北,台南这个是手啊这是拿第一个什么盘子这个球,打球,这个灯纸这个是一个手,哎,想不起来了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_7.wav\n",
      "['打球,这个灯纸,这个是一个书讲不起来了这个是用一个盘子盘子东西小孩子玩的东西,摆东西还有看见什么了还有这个一个大的盘子啊这个是装大东西的这样设计东西的这个碗杯子,这个灯纸这个是个小朋友头发']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_8.wav\n",
      "['这个碗,杯子,灯,这个是个小朋友,头发,家里的小鸟,这是一个门,这个小鸟,这个地方我就不知道什么地方,这个人好像就是你啊,长得那么漂亮,这个男孩子我不知道,这个也不知道,这个我没看到,这个好像也是你啊,这个也好像是你啊,']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/013_9.wav\n",
      "['这个男孩我不知道这个也不知道我没看过这个我觉得好像也是女的这个也好像是女的三个都是女的秋红火烧了蒸馒头她给你做凳子然后呢凳子放在那个晒晒一晒的因为太阳晒什么湿的东西在做什么在做一个小凳子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/015_1.wav\n",
      "['越多越好对讲到数了还有还有还有']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/015_10.wav\n",
      "['相机的脚架,神索的三脚架这是扫把,这是竖琴这是轮椅这是花园里面的花墙这个叫什么呢,这个不会海马蘑菇这是防空洞']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/015_11.wav\n",
      "['这个不会海马蘑菇这是防空洞北方北方人居住的地方北方人住这玩意儿这是圆规']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/015_2.wav\n",
      "['橘子、梨、苹果、香蕉、芒果还有芭乐差不多水果橘子、香蕉考试颜色红黄蓝白黑粉红黑有没有有啊有啊多得很讲不出来了你这是测验这个好点帮我动动脑']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/015_3.wav\n",
      "['那就讲不出来了你这是测验症啊帮我动动脑我脑袋已经老了不行了台湾好台湾台北市高雄市台南市基隆市台中市县市县市台北县台中县高雄县高雄县基隆不是县吧基隆是县吗不是县']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/015_4.wav\n",
      "['高雄縣,基隆不是縣吧?基隆是縣嗎?不是縣台中縣花蓮縣台中縣這個Lady在洗碗手裡面拿著盤子這個小孩在偷點心吃等這個椅子這個凳子快要翻了這個小女孩在指責他']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/015_5.wav\n",
      "['這個椅子這個凳子快要翻了這個小女孩在指責他這是洗碗的這個盆子水已經滿了都流出來了這是窗簾這裡面窗戶外面有樹木這也是窗戶外面的景色這是一個這是一個櫥櫃手裡拿的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/015_6.wav\n",
      "['这个景色这是一个这是一个橱柜手里拿的这个是一个盘子一个盘子跟一个毛巾这个对这是一个窗户对外面有树这里是两个瓷器一个瓷器碗这是应该是在这个一个家庭的厨房里面这个是儿子这个是女儿这个儿子在偷糖吃']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/015_7.wav\n",
      "['一个家庭的厨房里面这个是儿子这个是女儿这个儿子在偷糖吃这个地方是洗碗机这个厨房也是算厨房这是一个大一棵大树这是一个蜗牛啊这是一个铅笔这是一个这叫什么玩意儿']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/015_8.wav\n",
      "['这是一个这叫什么玩意儿?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/015_9.wav\n",
      "['镊子这是什么?竹蒜这是一个这是一排书架这个是手风琴网球拍这是一个圆规半规这个这个叫圆规半规画图用的两规两尺这是楼梯这是脚架相机的脚架伸缩的叫什么三脚架这是扫把这是竖琴这是']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/016_1.wav\n",
      "['我那个很活的很活的粗的那个有粗在哪里啊我记得有点粗啊这是个风魁啊对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/016_10.wav\n",
      "['窗帘上的客人给了一杯糖果这个主局主局门关着这上面还有盘子碗在这边有树窗外有路有月子有树对面还有一个王子手上拿毛巾擦板擦盘子的毛巾他在哪边干这应该是他的看不出是哥哥弟弟']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/016_11.wav\n",
      "['那个唱盘子的马晶嘛他在哪边干呢这应该是他的看不出是哥哥弟弟了他的孩子我觉得这个是兄妹两个弟妹弟姐两个因为年龄差不多有点水着水着所以没关系这应该是什么书我看这看不出什么书来蚵牛柴饼仙人掌剪刀听东西骆驼双峰骆驼微镖钢锯']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/016_12.wav\n",
      "['对 财币 新人掌 剪刀 听筒 听器 骆驼双风骆驼 飞镖 工具这个有出生一个人一家那一个金字塔这个就什么花生一个那个贝州菊 犀牛 骆斗这个家家子 是吧这你们没用吧 我们用过手风筋 网球拍 宇宙拍那个一般六周月车 观月车电灯楼梯 现在这是我们常常用的设计家']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/016_13.wav\n",
      "['宇宙拍那个186度月车 关月车电动楼梯 这是我们传统用的摄影机架这个机型叫 书型啊 能演什么音乐的这个应该画家 这个海蛮这个叫君子这个应该叫姚还是文伯 这个一个姚这个月归 非常好']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/016_14.wav\n",
      "['自己一個有這個有龜這也非常好']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/016_2.wav\n",
      "['那要什么?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/016_3.wav\n",
      "['水果']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/016_4.wav\n",
      "['西瓜,西瓜,还有莲藕,榴莲,梨,水果吃的水果那些我西瓜收购了没见哈密瓜,荔枝桂圆,都水果荔枝桂圆,长水状的底下的有番茄,红萝卜我们也吃,当水果吃西山的也是,红莱']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/016_5.wav\n",
      "['紅蘿蔔我們也吃,當水果吃西山的也是']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/016_6.wav\n",
      "['红中国红 桃红 粉红 玫瑰红 蓝色是红的黄的是 浅黄 淡黄 深黄 咖啡黄就这几个颜色来的 淡子 深子 绿子 浅子 什么其他没什么颜色都有 都差不多了 温和色的 淡色的 女生 红黄蓝 温和色的什么鞋子象征啊 台北市 台北县 象征是吧']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/016_7.wav\n",
      "['很好']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/016_8.wav\n",
      "['中华二水月林新宁台南这个就是钢山清水大江周营高雄红山台东台东再上来是花莲楼东一来那个那个那个南投那个那个水管出来了没关那个小孩冰箱要倒一直倒下来了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/016_9.wav\n",
      "['没关那个女生的小孩去拿冰干要要要到一直倒下来了那个他这个小孩小孩想吃也要想吃冰糖他想他想吃吗他就没接到没接到没拿到没有他要去接吗到家里来啊还唱着唱唱着外面月子这个是创立部创立部开的创作开的给了一杯汤子这个主局主局门关着']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/018_1.wav\n",
      "['猪牛羊马狮子老虎狗乌龟鱼虾蟹狼鹿马骡子狗猫蝙蝠鸟桃子栗子杏子苹果枣子香蕉栗子蒜桔']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/018_2.wav\n",
      "['蒜頭是一種青菜']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/018_3.wav\n",
      "['说不出来']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/018_4.wav\n",
      "['台南縣市澎湖馬公金伊朗這個是站在凳子上來取這個架子的東西嘛這凳子踏的不正確有摔跤的可能那這個是他洗碗盤的時候水太多了溢出來了他這個是在取的吃的東西啊這個男生找個女生嘛他這個是水龍頭沒有關']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/018_5.wav\n",
      "['溢出来了他这个是在去吃的东西这个男生交给女生他这个是水龙头没有关所以都溢到地上来了溢到地上来了地上来搞事了这个好像是交给一个男生一个女生兄弟姐妹会或者哥哥弟弟这是家庭住户嘛这在家里面这厨房嘛这个是好像男生拿一个吃的东西交给这个女生在他这个在这个凳子上中心部门还有这个接下来的可能']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/018_6.wav\n",
      "['嗯']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/018_7.wav\n",
      "['这是头饰的那个镖这个巨子这是什么金字塔这是什么']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/018_8.wav\n",
      "['这是清术琴这是那个什么乱仪对这个花架这是海马这是那个军这个是S级暴人的铸甲冰冻物这是院鬼']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/019_1.wav\n",
      "['在洗碗洗碗洗完他忘記了把這個紙類水留下來留了一地這個小孩子要拿蛋糕然後椅子坐可是不小心椅子翻掉了這個姐姐在旁邊哇哇叫叫他小心小心小心好了沒有了紙類水開了沒有關掉留了一地這個小孩子就不小心摔下來這個姐姐哇哇叫叫他小心']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/019_2.wav\n",
      "['沒有關掉留了一地子這個小孩子就不小心摔下來這個姐姐哇哇叫他小心椅子彎掉了是嗎小孩子要去拿蛋糕嘛他們姐妹兩個去拿蛋糕可是不小心椅子翻過來了姐姐叫他小心小心菇類那種有毛毛的那種菇類嘛它不叫做菇類嗎?叫做菇類嘛']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/019_3.wav\n",
      "['毛毛的那种菇类嘛它不叫做菇菇吗?这都是肺腱嘛口琴,布顶啊蒙古包也不像手风琴,打羽毛球的嘛牛排,黏的好像是楼梯的那个地方手风琴啊,不是了这没有看过就是病人坐在上面那个黑黑的嘛那叫什么,我也搞不清']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/019_4.wav\n",
      "['上面那個黑的嘛那叫什麼 可以 我也搞不清楚']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/019_5.wav\n",
      "['狼猴鸡鸭老鼠猪鸡这几讲过了牛老虎老鹰狗狗讲过了牛猪羊讲不出来韩国就是柳丁西瓜洋桃香蕉苹果榴莲番茄凤梨讲不出来']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/019_6.wav\n",
      "['我们叫天天吃什么吃香蕉苹果榴莲番茄凤梨讲不起来了凤梨讲不起来了还有姑姑在想新话的黄黑黄黑绿蛋黄可以吗可以白色黑色青色紫色']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/019_7.wav\n",
      "['黑色、青色、紫色黃色、綠色、黑色、棕色、紅色紅色講過了阿館怎麼順序講呢?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/019_8.wav\n",
      "['新竹桃源我又不出去的桃源新竹嘉義我出來了台北縣台北市沒了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_1.wav\n",
      "['小朋友用凳子攀高去拿点心结果的时候不小心凳子歪了以后差点摔跤了这个是一个家庭主妇在厨房洗碟子结果的时候水溢出来了窗外还有很好的景致']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_10.wav\n",
      "['狗啊还有这个野生动物的象啊骆驼啊狮啊豹啊这个狐狸啊这个水中有的鳄鱼啊这个可以的 够多越多越好香蕉凤梨橘子笨肝柳丁']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_11.wav\n",
      "['香蕉、鳳梨、橘子、棒干、柳丁、榴槤、蘋果還有奇異果、枇杷、芒果、荔枝、龍眼很多']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_12.wav\n",
      "['芝麻芒果荔枝龍眼很多還有很多水果甘蔗也是水果紅薑藍子橙綠白黑黃銅甲鵝五顏六色差不多講了十種']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_13.wav\n",
      "['河,所謂五顏六色,差不多講了四種店,是一種,講不出來了還有啊,黑色講了,好開心啊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_14.wav\n",
      "['桃源縣新竹縣遼寧縣台中市彰化縣雲林嘉義台南縣高雄市屏東縣花蓮縣']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_15.wav\n",
      "['台南縣、高雄市、高雄縣、屏東縣、花蓮縣、台東縣、宜蘭縣、這個...澎湖縣、這個...金明縣還有這個...這個...這個...好,你講鄉鎮是吧鄉鎮,這個是...就像我們講的這個白頭啊、四林啊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_16.wav\n",
      "[\" So what? Who's hurting now?\"]\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_2.wav\n",
      "['窗外啊還有很好的景致花草這個好像這個是媽媽這個是兒子這個是女兒大概是這樣的關係都是在一個廚房空間裡面一個就是啊他這裡還有兩個小碟子小...小...就是這個是碟子了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_3.wav\n",
      "['就是啊,他这里还有两个小碟子小,小,就是这个是碟子了这个是好像那个装辣椒装酱油的那个东西还有这个琉璃台还有橱柜柜子还有这个小朋友啊已经拿到个水果了他凳子歪掉现在是啥就是他在拿这个']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_4.wav\n",
      "['拿了个水果了,它是笨拙的现在是啥?就是它在拿这个点心喜饼对,拿喜饼这个它的意思就是说你上去给我拿个饼给我吃它吃了给它吃,大概就这样的意思这还有窗帘把它打开一点很好这个图片这个是一个很美丽的一个树']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_5.wav\n",
      "['把它打开一点很好这个图片这个是一个很美丽的一个树花柿 蝸牛铅笔那个杂木里面的那个叫什么杂木里面才会长的那种针杖剪刀 真听器听真器骆驼那个飞镖这个公鸡']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_6.wav\n",
      "['听器 听真器骆驼飞镖这个公鸡板鸡这个好像是口琴鱼架这个非洲的金字塔一朵花犀牛漏斗这个就是平常我们吃咖啡加方糖的夹子方糖这个呢算盘手风琴这个是有毛球']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_7.wav\n",
      "['这个是有毛球扑还是网球扑对对对两脚气垫腹体背体三脚架大概是摄影的三个扫揪竖琴轮椅就是我们病人行动方面的轮椅这个是滑架因为它搬了很多东西']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_8.wav\n",
      "['就是我们病人行动部方面的人椅这个是滑架因为它搬了很多对这个呢海马叫箍吧对箍这个是窑这个是圆规没有了不管是天鹅飞铁这些都可以最时髦的现在的单顶鹤黑面猪老鹰这个斑猪猴子马鞘白头翁']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/020_9.wav\n",
      "['我大概是講這個會肥掉了講地下會跑的就是我們家學的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_1.wav\n",
      "['這些人物他在做什麼事情對不對那還有一個比較很不應該的事情就是說他一直在擦那個盤子然後就地上滴下來很多的很多的這個這個這個就是在在在他那個他那個我不太會講可以吧那就是他在他在他在這個這個流理台的這個地方']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_10.wav\n",
      "['喔那個...']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_11.wav\n",
      "['坐到輪椅上面這個是好像在某些地方這是叫花架這是什麼馬海馬這個是菌類這就是那個哪裡就是那個對在住的在住喔']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_12.wav\n",
      "['那裡就是那個對在住的喔在住喔對在冰那個是遠歸怎麼講我現在還沒有弄清楚好我再說一次說我找到的動物對只要越多隻動物小狗駱駝魚還有它一定是怎麼講']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_13.wav\n",
      "['它一定是...怎麼講反正就是把所有的動植物啊什麼的統統可以擺進去嘛還是怎麼樣太多了照把這些東西都可以嗎想這些東西可以嗎想得到的水果楊桃桂圓還有想得到的水果']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_14.wav\n",
      "['好來開始']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_15.wav\n",
      "['建制鄉鎮台北市']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_2.wav\n",
      "['不太會講可以吧?她是女性就好啊她在這個流理台的這個地方那這個女孩子不曉得她頭腦在想什麼她一直那個水就出來了那這邊是有一個男孩子他是在那裡去拿東西給她看起來是她的妹妹還是怎樣']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_3.wav\n",
      "['一個男孩子,他是在那裡去拿東西給她看起來是她的妹妹還是怎樣那她現在她這個可能是她的媽媽嘛那她就要把她擦乾淨不曉得為什麼她都通通露出來了那還有一個蠻危險的一個']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_4.wav\n",
      "['都通通露出來了那還有一個蠻危險的一個狀況在那邊這就是在家裡面的一個應該講說他是在家裡面做一些事情但是可能心裡有沒有很']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_5.wav\n",
      "['做一些事情但是可能心裡有沒有很專心的去...小孩子的這個...這個是小孩子跑上去拿吃的東西嘛對不對大概是這樣子但是他的媽媽或者他姐姐']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_6.wav\n",
      "['吃的東西嘛,對不對?大概是這樣子但是他的媽媽或者他姐姐他就不曉得為什麼他頭腦就沒有...不曉得他想到哪裡去了這就是一棵樹啊那個叫什麼?就好像是蝸牛那樣子嘛']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_7.wav\n",
      "['那個叫什麼?就好像是蝸牛那樣子嘛很好很好這個是鋼筆千人掌嘛剪刀青銅這是那個駱駝這是飛鏢這是鋸子這個是那個琴口琴那個就是叫什麼?架子嘛衣服架子這個好像是那個叫什麼?這應該是一個什麼?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_8.wav\n",
      "['這應該是一個什麼東西我就是忘了金字塔這是花嘛雞牛等於是漏斗嘛這是風琴啦手風琴這是打羽毛球拍子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/021_9.wav\n",
      "['走空琴']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/023_1.wav\n",
      "['老鹰乌鸦喜鹊鹦鹉猫头鹰麻鹊鸽子那就是鸟鸟类类对不对凤凰都可以讲凤凰这个火鸡嗯... 兔皮还有是孔雀我先讲孔雀就讲凤凰孔雀对还有大铜铜鸟这个最大的还有鸠鸟鸟类差不多了鸵鸟也算鸟类鸵鸟火鸡兔皮我讲过了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/023_10.wav\n",
      "['这个叫墳墓啊,这房间主叫康啊,雪屋,SGS的雪屋,圆规']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/023_2.wav\n",
      "['好,两类差不多了,脱料就剩两类了,脱料,火鸡,脱皮,我讲过了,还有水果,凤梨,桃子,西瓜,这个,杨梅,草莓,李子,桃子,李,水梨,芭拉,芒果,榴莲,椰子,柚子,葡萄,葡萄柚,橘子,柳丁,这个,奇异果,木瓜,']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/023_3.wav\n",
      "['红黄蓝不和紫 绿 青 绿 和橘色 蓝色有没有蓝色粉红色 粉红色紫蓝紫色 橘黄色 白颜色白颜色很严重的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/023_4.wav\n",
      "['基隆市 基隆县 台北县台北市 台中市 新竹县台中县 南投县 嘉义县台南 台南县 高雄县 宜蓝县花莲市 花莲县 台中市 台南县完了以后别的乡镇要讲了都可以讲那很多了好 讲台北好了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/023_5.wav\n",
      "['别的乡镇要讲了都可以讲那很多了好 讲台湾的好了这个台湾说太久了第一个小孩子要拿蛋糕不小心椅子要倒下来了拿蛋糕给他妹妹']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/023_6.wav\n",
      "['这个小孩子要拿蛋糕不小心那个椅子要倒下来了这个拿蛋糕给他妹妹他妹妹没有蛋糕拿给他这个妈妈在想事情这个水啊吸完的时候水已经满了他都没有注意他都没有注意没有就是外面也没有就是水就泼出来了下面有一个母亲一个儿子一个女儿在厨房就是拿那个气垫蛋糕']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/023_7.wav\n",
      "['上面有一个母亲一个儿子一个女儿在厨房就是拿那个锡点蛋糕把门打开了他拿饼干嘛拿给他拿一块给他再拿第二块的时候就花一只就掉下来了对对这树蜗牛这叫铅笔叫尖刀剪刀叫听筒叫骆驼双峰楼叫这射箭靶射靶的那个这个叫做靶那个射靶的嘛飞镖']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/023_8.wav\n",
      "['这叫做摩托双风楼这叫做射箭靶射靶的那个这个叫做靶那个射靶的飞镖巨子口琴音架这是IG的金字塔菊花细牛漏斗这个钳子这是买西点蛋糕的时候的上弹手风琴网球盒网球盒这个是圆规它不是圆规哦这是半角规半圆规这是电覆机这是摄影架子照相架']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/023_9.wav\n",
      "['半圆龟这是电弧机这是摄影架子照相架摄影架 照相架 摄影架底架 上架 上把这个叫做wiring这个手机是什么琴啊?竖琴 竖琴人影这是花架 花马这是草菇 海马这个叫坟墓房间组屋']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/024_1.wav\n",
      "['這個拿餅乾嘛這個水漏出來了他拿這個來擦他拿這個要修理的不是啊不是修理拿這個布要擦水手拿這個布要擦水就行了嘛就這樣還有沒有啊這個水滿出來他拿這個布來擦水這個要關這個這個不可能是關這個這下面有什麼漏的已經被他下面被那個不可能就擦水關']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/024_10.wav\n",
      "['差不多我就眼下养这么多海带、鸟、猫、狗差不多就长到这些不管怎么顺序都可以']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/024_11.wav\n",
      "['我不常起这些东西想起来橘子香药想起这些不管怎么顺序都可以白的红的蓝的绿的咖啡的灰的黄的金色的红色蓝色咖啡色我想到这些灰色想起来先是台北市台中市高雄市']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/024_12.wav\n",
      "['我想到这些 灰色 请您进去讲一下 台北市 台中市 高雄市 台南市 屏东 新店 淡水 高雄 北通我想到这些 我想一下 阿迪山 也是 台中 台南 嘉义 屏东 业柳 新店 雪里红那算素菜 好 谢谢']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/024_13.wav\n",
      "['那些素菜']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/024_2.wav\n",
      "['不可能是關這個,這下面有什麼漏了一點,下面被那個不可能,就查水弄頭關死就這樣,這是個竹孤,這是小孩子,一男一女這是廚房,這有餅乾,叫小朋友上去拿餅乾給女孩這個就是水弄頭,水滿出來,這是廚房這個水台水滿出來了,他賣鹽吃水弄頭,他要來查這個水']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/024_3.wav\n",
      "['这个厨房这个水台呀水满出来了他没领着水龙头他要来查这个水拿着抹布来查这个水就这样他就是想来查这个水拿个抹布来查这个水嘛这是一棵树啊这是个蜗牛天底这个好像长一个什么一棵不是这什么树来的就是长出了一棵树不清楚这是什么树叫什么天生长这个天生长剪刀这个医生看']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/024_4.wav\n",
      "['就是长出了一棵树不清楚这是什么树叫什么仙人掌这个仙人掌剪刀这个医生看病那个东西听啊听针那个东西听分器啊骆驼这个小孩玩那个飙飙啊这个锯子这个是什么我不晓得没看过乐器啊没看过手缝琴啊二口琴啊二口琴啊这是挂衣服那个挂钩衣架这个是个什么这个就是照着']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/024_5.wav\n",
      "['这是挂衣服那个挂钩衣架这个是个什么这个就是罩着这厨房罩着那个东西不是啊建筑物的那棚子是吧到野外去那个游的那个棚子这不是棚子吗帐篷啊鸡什么鸡精这一颗花一颗花这个就是一个牛牛犀牛这是一个漏斗啊这个就是啊夹子那个夹子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/024_6.wav\n",
      "['牛牛 犄牛这是一个漏斗这个就是夹子那个夹子 夹子算盘这是折粉琴这是碗拍 网球拍这个那个瓷这有名字叫做那个刻板上画出那个瓷都俩横啊不叫都俩横 都俩横这个是楼梯这个那个做画图用的那个叫什么名字不晓得测量做那个做像那个架子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/024_7.wav\n",
      "['这个做画书用的那个叫什么名字不晓得测量做那个照相架子照相架子照相架子什么我不晓得那个名字会用这个这个是那个扫把这个那个这是那个琴是不是是不是琴嘛这个琴嘛对那它那个琴呢这个什么器械器素琴这个这个是花架子这个这个这个什么是海马']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/024_8.wav\n",
      "['这个是花架子这个是什么?是海马墨湖墨冬菇这个是神木是不是神木?不是哦,不是木蒙古包是不是?少看那个东西啊可能专家人啊不晓得这个是那个化粗用的什么纸这个我没用过不晓得,就化粗用的轮规这个是我想到怎么讲的嘛狗']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/024_9.wav\n",
      "['我沒用過不曉得就放話服用的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_1.wav\n",
      "['从哪里做起都可以他在做西点做完之后还拿给这个小孩吃这还说什么就这样讲讲那他这个拿东西的人会叠交可是这个小孩还是在这摇东西吃我看他在查清洁查这个盘子还有什么事还好了吗都结束了吗他就是来拿东西他就是要吃的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_10.wav\n",
      "['就是上樓的那個東西我也不曉得叫什麼他說坐手什麼一種工具嘛就是放人上去的時候踩在上面坐著那我不知道我也我不知道這個燒地的那個燒著這個大門口大門的那種開關那種東西那我不知道不知道因為我從來沒有']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_11.wav\n",
      "['這是一種開關那我不知道因為我從來沒有用過沒有關係這是做椅子嗎這是方壇坐立椅子叫什麼名字我不知道這是窗簾嗎這個就是隔窗子的東西我不曉得叫什麼名字這個我用到的喔我不知道叫什麼名字好沒有關係這是一種蟲嗎叫什麼名字我不知道']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_12.wav\n",
      "['我不知道叫什麼名字這是一種蟲嗎?叫什麼名字我不知道海馬是嗎?海馬是嗎?這個駿子好像牆壁不動一樣我也搞不清楚叫什麼名字是人的啊?這個我不知道學生好像會用的那個工具鉛筆啊什麼毛筆什麼東西因為我不畫圖所以不知道']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_13.wav\n",
      "['有要做什麼?因為我不畫圖所以...毛狗豬牛羊很好魚也算動物對啊還有什麼東西啊?多得很了越多越好想不起來我真是想不起來豬牛馬有牛羊鼠這多得很對啊對啊很好很好太多了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_14.wav\n",
      "['我媽有牛羊鼠子,多得很,太多了牛羊豬魚鯉魚,我還想不到呢,越掛越想不到橘子,柿子,太多了,想不起來']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_15.wav\n",
      "['这个柿子哎呀太多了想不起来这样我一个都想不起来了一天到晚吃的都忘掉了我真的就想了一下想不起来苹果啊橘子啊这个苹果橘子平常吃的什么我吃的东西都忘掉了越想越想不出来苹果牛奶橘子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_16.wav\n",
      "['平常吃的什么我吃的东西都忘掉了越想越想不出来苹果牛奶橘子这个只要是这就跟我说红绿蓝白青紫还有些什么颜色我都想不起来红绿蓝白青紫黑黄蓝绿黑讲了没有黄蓝黑']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_17.wav\n",
      "['黄蓝黑讲的没有黄蓝黑白一下想不起来就是这些颜色吗有啊白黑黄黑那这就不好越多越好我恐怕想不起来这个都想不动了天使箱子我们住的地方是什么地方这样我反而想不动了住的在哪里台湾']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_18.wav\n",
      "['我們住的地方是什麼地方真是想不起來以這樣我反而想不到了住的在哪裡台灣台灣裡面的台灣真是想不起來越是過的越是想不起來四好地名都想不出來了中壢很好台北很好台南還有哪些現在我自己住的都忘掉了台北台南高雄還有哪些的地方']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_19.wav\n",
      "['现在我自己住的都忘了台北台南高雄还有哪些的地方']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_2.wav\n",
      "['嗯 还有什么事啊 还好了吗都结束了吗 他就是来拿东西嘛他就是要吃的 他在洗东西他在查东西 其他的这个东西掉掉了他要整理 好像就掉下地了人就是人嘛 他的祖宗嘛 家人家庭 屋房就是在酒有这个水 倒水']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_3.wav\n",
      "['這是在酒有這個水倒水這個在查東西查乾淨這個是要吃的這個在拿東西的時候快要跌跤了是他在做些什麼事我剛才不是講過嗎他在拿東西吃嗎對他在要東西吃嗎是他直接快跌跤了這是主婦在查東西查清潔因為他有水流下去了這個是樹嘛']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_4.wav\n",
      "['這是主婦在查東西 查清潔因為他有水流下去了這個是樹嘛這是蝸牛這是一個那個那個什麼樹啊我不曉得叫什麼名字我不知道他叫什麼名字好沒有關係好來他這個呢? 尖刀青銅這是駱駝這個是一個好像是針一樣的一個玩具我不知道怎麼演玩具劇我不知道我不知道因為我沒看到過這種玩具']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_5.wav\n",
      "['好像是个针一样的 这玩具我不知道是什么玩具 不知道因为我没看到过这种玩具这是个什么东西我也看不出来恐怕是那个那个摩擦的那个那个是什么这个地方 鋸子对这种我都会不认识考试对啊 我不晓得是什么口型的这挂衣服挂钩 挂钩挂这个衣服的 这叫什么名字我也不晓得叫什么名字']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_6.wav\n",
      "['衣服挂钩挂钩挂着衣服的这叫什么名字我也不晓得叫什么名字这个是房子娃娃是什么东西这个我看不出来我不知道我对这个国外高尚的建筑不知道不知道这个名字花嘛牛叫做牛这种牛叫什么牛我还想不起这个名字了这个是茶杯吧我不晓得这个什么东西这不像喝茶的样子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_7.wav\n",
      "['我還想不起來這個名字呢']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_8.wav\n",
      "['我不曉得叫什麼名字這個東西我不知道我很少在廚房做事我都在外面吃飯這個叫什麼我不知道三盤這是個什麼東西啊這好像是那個那個那個那個叫什麼就是等於那個那個樂器啊對樂器那我不知道這種樂器叫做手手啊手工琴啊很好很好來什麼啊球盤這個是那個學校用的學生用的那種對']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/025_9.wav\n",
      "['手工琴啊很好很好來什麼啊球盤這個是那個學校用的學生用的那種叫什麼名字我一下想不起來了就叫這個現在用過了就忘了好來這塊是樂器嗎好像什麼樂器我不知道我不知道就是那個等於是說等於是說上樓的那個東西我也不曉得叫什麼他都做了你現在跑啊你怎麼不知道我說出來不知道']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_1.wav\n",
      "['人啊狗啊牛啊马啊鸡啊羊啊鹅啊这个动物类的话想那么多光是动物啊人类啊狗啊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_10.wav\n",
      "['在洗手洗东西啊那个儿子的话想着凳子搁头了往上爬看着那个什么想吃东西到手把东西妹妹的话在下边手撑着我问她要但是她那个凳子都歪了快要摔跤了很危险的这个事情应该赶紧调查最后我看了这个东西看着的话她妈妈在洗手']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_11.wav\n",
      "['很危险的这个是应该赶紧调查最后我看到这个东西看到的话他妈妈在宿在厨房吃东西在厨房不是在厨房了这算什么是啊窗子扣起了看着那个窗子看着那个下边那个水溜出来了看着水溜出来了看着孩子上去抢东西抓东西吃那边有个瘦吃的我来咬看到那个凳子的话我一拉咬摔跤了拿来']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_12.wav\n",
      "['抢东西抓东西吃那边有个瘦吃人我才咬看到那个凳子的话喂了要睡觉了那呢这个是在江县一个厨房的柜子是一个柜子在窗子边起窗子还有窗帘这个窗帘它刚打开一点这时候在厨房里边呢在那个凳子上面凳子喂了咱们凳子上面拿东西吃']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_13.wav\n",
      "['在厨房里边呢,有个凳子,站在凳子上面,凳子歪了,咱们凳子上面拿东西吃,那个凳子,那个妹妹手伸在我那儿咬,这个算什么书,国牛,远天地,这,那叫什么,我搞不清楚了,这个,这个,我迟早迟早我名字就记不到了,我讲,这是沙漠里边长这个东西,']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_14.wav\n",
      "['这个我知道我名字是记不到了这是沙漠里面长这个东西的这叫这算什么天仗剑刀这这个一声咏听耳机一声咏听这个听懂了对对很好骆驼这个是小孩都问了飞镖啊鞠子扣心这一甲这这是这爱记的分母啊这是它这草花']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_15.wav\n",
      "['扣亲这是一家这是外籍的父母这是他草花 新柚 老豆这是那个夹子夹的什么东西蒜盘这是封亲那个什么手抓的亲手抓的这个封亲不算封亲了受亲了不是的受什么这个受亲了这网球盘这养龟不算养龟这算什么经常的话']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_16.wav\n",
      "['这个手寸的这网球拍啊这仰规不算仰规这算什么经常的话什么亮啊那那那它用的话给你画什么东西像些什么东西什么吃什么这个这是不这楼梯吗三角角这是毛刷这算什么毛刷的这算什么扫的这叫什么手寸的是吧']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_17.wav\n",
      "['这算什么冒杀的算什么扫的这叫什么石寝的是吧这个病人做的这样叫什么这个韧衣这算什么花甲这是睡里面长的睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡睡的这都是什么这']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_18.wav\n",
      "['草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓,草莓']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_2.wav\n",
      "['光是动物人类狗牛羊猪鸡羊柿子橘子苹果香蕉蜂蜜西瓜南瓜西瓜酸']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_3.wav\n",
      "['西瓜南瓜西瓜酸西瓜香瓜栗子栗子枣青梅子草莓苹果']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_4.wav\n",
      "['草莓啊蘋果啊芭樂顏色什麼順序啊不管顏色紅的黃的藍的白的灰的對金黃色啊天藍色啊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_5.wav\n",
      "['红的呀,黄的呀,蓝的呀,白的呀,颜色呀,黑的呀,黄的呀,']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_6.wav\n",
      "['黃的呀,藍的呀,白的呀,顏色,青的呀,黑的呀,黃的呀,天藍色呀,橘紅色呀,鄉鎮呀,鄉市呀,我說知道的,台灣省裡邊的,高雄呀,基隆呀,台中呀,屏東呀,']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_7.wav\n",
      "['基隆啊台中啊屏東啊花蓮啊台中啊台北啊台北市啊台北縣啊桃園啊桃園縣啊新竹縣啊嘉義啦嘉義縣啊高雄縣啊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_8.wav\n",
      "['我看了这个']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/026_9.wav\n",
      "['跟他们联系啊他的妈妈都没法知道啊我看了这个状况啊我看了这个这么称呼都可以说这个他算是一个这个这口算是一家人一样的妈妈呢在厨房呢在做事情比如说在洗盘子啊有这个事业的在洗手洗东西啊那个儿子的话想着蹬这个头了往上爬']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/027_1.wav\n",
      "['小孩子趴稿拿点心吃还有一个好像妇女在洗碗饭所以水没控制好流出来是这样啊他们可能是一个妈妈一个儿子一个女儿相思书房看到点心呢碗呢盘呢水龙头啊椅子柜子这上面一个是在小孩子趴稿拿东西一个在洗碗饭一棵大树蜗牛啊鲜冰']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/027_2.wav\n",
      "['一个是在小孩子爬高拿东西一个在洗碗碗一棵大树蜗牛铅笔这是仙人掌一支的剪刀医生的听病器医生听针的那个这个我不懂听神器骆驼这是那个镖针呢镖针这个叫什么飞剑啊不是飞镖这是羊绣口琴衣架这是金字塔一朵花鸡牛骆驼夹子算盘手风琴']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/027_3.wav\n",
      "['这是羊肌 口蹄 衣架这是金字塔 一朵花 鸡牛 肉豆 虾子 蒜盘 手风琴 五角派 两脚气这是电梯 三脚架 扫把 树枝 病人坐的椅子 淋浴这个是窗户 栏杆 花架 裁麻这个呢 羊骨 这是那个蒙古包 冰库 冰窝 冰库 烟鬼 羊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/027_4.wav\n",
      "['冰窟']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/027_5.wav\n",
      "['鸡 海象 企鹅 五尾熊 凤凰 鸳鸯狗 猫 鸡 羊 兔子 甜椒 凤梨 苹果 洋草 草莓 酸酸的 释迦 凤梨 西瓜 奇異果']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/027_6.wav\n",
      "['嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/027_7.wav\n",
      "['嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/027_8.wav\n",
      "['屏州市南投江华台中市台中县嘉义市嘉义县台南市台南县高雄市高雄县台东县屏东县华联县南投斗六吴卫新宁岗山']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/027_9.wav\n",
      "['我會細語感散']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/029_1.wav\n",
      "['猫狗是算吗?猫狗牛羊马骆驼袋鼠老虎狮子绵羊马牛马牛老虎骆驼绵羊豹子猴子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/029_10.wav\n",
      "['这个是仙人掌 剪刀这个是听筝器 笔这个也是个笔这不是笔啊这个后面是个羽毛这个镖啊 它的名字飞镖 很好 很好锯子 口琴 鱼架这个金字塔 一朵小花 犄牛 骆驼 蝎子下方呢 算板 这个手风琴这个有响网球帕子有响打唱 打文歌的乐队']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/029_11.wav\n",
      "['這個手風琴這個有像網球發的有像打文字的那個這是圓規不是那個圓尺它叫什麼我不知道它叫做它的名字叫什麼梁梁梁尺啊好可以來這個是你的墊扶梯是三角架是照相的這是掃把這個是大提琴手風琴這什麼豎琴']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/029_12.wav\n",
      "['這個是大提琴啊手風琴啊這是什麼?樹琴木琴輪椅我不會音樂這是種花的家我不知道這個名字就是讓花爬上去的嗎?我不知道這個名字叫做花家啊這是個中藥中藥叫個什麼呢?花馬不是叫什麼呢?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/029_13.wav\n",
      "['中藥叫個什麼呢?火馬不是叫什麼呢?海馬不是駿子這個是燒東西的窯這個是圓龜好可以了很好哦']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/029_2.wav\n",
      "['包子、猴子、狗熊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/029_3.wav\n",
      "['橘子、柳丁、鳳梨、木瓜、西瓜、火龍果、奇異果、芭樂、番茄、香蕉、葡萄、莓木、蘋果、紅橙黃綠、藍靛紫']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/029_4.wav\n",
      "['蘋果紅橙黃綠藍靛紫黑色紫色黃色綠色灰色白色那我要講重的呢重複講的呢有沒有關係沒有關係淡藍咖啡淺灰']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/029_5.wav\n",
      "['沒有關係沒有關係']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/029_6.wav\n",
      "['路不太清楚']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/029_7.wav\n",
      "['清書哪些線哪些書是淡水寺這個封元禎行諸事講了沒有?可以了已經很好了看著講媽媽帶著兩小孩一個哥哥一個妹妹在廚房裡媽媽在洗盤子這個水濃濃的水啊在洗盤子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/029_8.wav\n",
      "['媽媽在洗盤子水龍頭的水在洗盤子這裡有個窗戶哥哥站著凳子上去勾美心吸點刺結果凳子站歪了妹妹就告訴哥哥哥哥你要摔跤了媽媽一緊張的來看哥哥結果水龍頭水都滿出來了他都不知道呢可以了嗎?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/029_9.wav\n",
      "['哇']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/030_1.wav\n",
      "['羊牛狗貓牛豬羊香蕉香蕉蘋果紅蘿蔔白蘿蔔白蘿蔔白蘿蔔白蔥鮮蔗雞肉鮮蔗雞肉洗碗倒樓樓上拿東西倒樓上拿東西水池裡面洗碗倒樓上拿餅乾倒水池裡面洗碗小孩女孩媽媽媽媽在']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/030_2.wav\n",
      "['還有看到']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/030_3.wav\n",
      "['好']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/030_4.wav\n",
      "['這是鮭魚肉豆這是家傳吧這是紅筋這是鮭魚這是煎雞這是手筋這是鮭魚這是人魚這是什麼東西這是冰不知道冰庫不知道']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/030_5.wav\n",
      "[' No.']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/032_1.wav\n",
      "['有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪有哪']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/032_2.wav\n",
      "['嗯?不是天馬?對']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/034_1.wav\n",
      "['好 从哪一个说起妈妈在洗盘子但是呢水一直开着所以水就从这个水槽里面水流出来了流到满地上都是然后小朋友一个儿子嘛儿子是到了那个柜子上面去拿一个美心的吸点结果没有站好所以站在椅子上就快要摔下来的样子那个他的女儿站在旁边就告诉他']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/034_2.wav\n",
      "['站在椅子上就快要摔下來的樣子他的女兒站在旁邊就告訴他說你拿一個給我吧是這樣子是在廚房裡這樣子好還有上面有櫃子下面也有櫃子還有窗戶窗戶外面的風景有樹還有窗簾還有這個水龍頭水在流出來還有櫃子上面有兩個碗一個盤子還有這位媽媽']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/034_3.wav\n",
      "['还有柜子上面有两个碗一个盘子还有这位妈妈是正在擦盘子用抹布在擦水是继续流下来已经满出来了满到地上地板上很干净就这样这是一棵树花牛铅笔这个是仙人掌剪刀听筒骆驼射标那个标叫标签吗不是不是灰标叫灰标']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/034_4.wav\n",
      "['刀 听筒 骆驼 射标那个标叫标 标签吗不是不是 灰标 叫灰标锯子 口琴 衣架金字塔 花 犀牛 漏斗 夹子 夹长的夹子算盘 手风琴 网拍那个打网球的拍子 球拍吗这个分度器 电梯 三脚架 罩把竖琴 轮椅 花架 河马 海马香菇 这个是一个烧 烧什么的一个']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/034_5.wav\n",
      "['鱼鱼 花甲 河马 海马香菇 烧砖的那个 窑双脚龟 圆龟马 狗 牛 老虎 狮子 骆驼蜥蜴 什么的 也可以蛇 什么的 鸡 鸭 鹅 鸽子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/034_6.wav\n",
      "['雞鴨鵝鴿子還有什麼動物犀牛野狗野貓香蕉草莓橘子柳丁楊桃自家西瓜香瓜鳳梨百香果紅龍果沒有了想不起來了還有啊龍眼荔枝顏色紅藍黃黑灰紫綠色']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/034_7.wav\n",
      "['紅藍黃黑灰紫綠色深綠墨綠天藍色深藍淺藍黑色應該講過了吧應該這個顏色差不多還有金色銀色還有嗎橘色是吧應該差不多了還有因為我做印刷的所以應該這些顏色應該都差不多了咖啡色土黃色都可以']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/034_8.wav\n",
      "['印刷的所以這些顏色應該都差不多了喔 混的喔咖啡色 土黃色都可以台北縣 台北市桃園 新竹台中市 台中縣雲林 南投嘉義 台南台南縣市 高雄縣市屏東 台東花蓮 宜蘭然後說小一點的範圍像北投 士林 新店 圓山中和 永和']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/034_9.wav\n",
      "['小一點的範圍像北投、士林、新店、圓山、中和、永和日月潭、阿里山很多啊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_1.wav\n",
      "['動物']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_10.wav\n",
      "['花圃']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_11.wav\n",
      "['先生長嘛剪刀青銅駱駝這是...這應該是以前用的是不是以前用的那個筆寫字用的?這個不是筆喔那是投標這是投過去的標這什麼名字啊?小朋友玩的那個標這標鋸子口琴衣架金字塔花犀牛這是一個漏斗這是一個夾這個鐵夾夾東西的夾這個']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_12.wav\n",
      "['花西牛這是一個漏斗這是一個夾這個鐵夾夾東西的夾這個夾糖的啦那叫什麼我不知道它叫什麼這個普通我們鐵夾的夾鐵夾夾糖蒜盤拉風琴手風琴對到底是網球發還是買手發可以這是圓規這是杜亮紅的那個對不是喔這不是圓規啦這叫兩角器啊對']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_13.wav\n",
      "['這不是圓規啦這叫兩腳氣啊電梯這是圓規啦三腳照相機的那個底下架子照相架底下照相架三腳架照吧這是普通叫不是手風琴啦就是那種豎琴']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_14.wav\n",
      "['不是手风琴啊,这是那种竖琴这是摇椅,摇轮椅这是花圃上的那个,这叫什么呢?它已经在外面了花圃的那个定的那个架子,那叫什么?我还不太了解这个是,不是啪啪铛,这个可以种东西']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_15.wav\n",
      "['这个我还不太了解这个是不是爬爬藤这个是可以种东西就是爬可以爬在上面嘛对不对可是这个我们花圃啊不是花圃啦这个我们也因为这个我待会不太熟比较早看然后这个呢这是那个什么牛啦马叫什么不是河马是什么马海马海马海马这是羊膏']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_16.wav\n",
      "['海马']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_17.wav\n",
      "['我不太知道它叫什麼我只曉得它是晚上睡覺的地方你叫什麼?冰屋這叫冰屋這是三角這是那個化緣龜啦']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_2.wav\n",
      "['還有犀牛、熊動物太多了河馬普通的就是這些還有狗啦也算對,有奶的也算鳳梨、西瓜、草莓、藍莓西瓜、香蕉、葡萄香蕉講過了蕃茄、橘子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_3.wav\n",
      "['香蕉講過了蕃茄橘子柳丁芭樂奇異果甘蔗也算了有的水果我們不怎麼還有那個叫什麼還有橘色咖啡色奶油色黑色']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_4.wav\n",
      "['有橘色、咖啡色、奶油色、黑色、中和的色']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_5.wav\n",
      "['默色算不算?算默色灰色有這麼多?對台北、台中、台南、高雄、屏東、花蓮花蓮還有宜蘭宜蘭、台中、高雄、屏東我講的都是幾個大的小的就是花蓮高山豬不算高山豬那個有嗎?都可以加']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_6.wav\n",
      "['小的小的我就花蓮高山竹不算高山竹那個高山竹那邊還有一個縣市鄉鎮鄉鎮我就比較少宜蘭嘛那個嘉義嘉義高山竹高山竹我在想說那個也是一個縣市嘛那邊對不對你想那個也算一個吧我這樣想小朋友像他妹妹嘛他叫哥哥拿餅乾']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_7.wav\n",
      "['对不对?你想那个也算一个吧我这样想小朋友像他妹妹嘛他叫哥哥拿饼干有个椅子有点歪了他妈妈在这里洗碗结果水龙头没有关漏水漏出来了其他就是外面的风景玻璃外面的风景这还要讲吗?这样子啊有洗好的盘子摆旁边有花草窗子花布']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_8.wav\n",
      "['洗好的盘子摆旁边有花草 窗子 花布这就是一个厨房间嘛对 很好越强行越强行我刚刚讲的都差不多了可是这个水水管漏的话还要从里面还要渗透出来这边滴下去这边还有里面水管里面还要漏出来']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/035_9.wav\n",
      "['這邊滴下去這邊還有裡面水管裡面還有漏出來椅子不穩了還摔跤看不出來什麼不像你摸啊沒有東西窗簾啊窗簾有有有有有外面有棵樹對面有一個有個房子屋頂這邊有個花圃樹沒有講這叫樹啊花牛']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/037_1.wav\n",
      "['大象、马、狗、鸡、鸭、鱼、狮子、老虎、蝉蝇、猴子、花豹还有什么?鸡,你讲过了吗?山羊、骆驼、野猪、狗啊,花狗、黄狗都可以香蕉、凤梨、枇杷、葡萄']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/037_10.wav\n",
      "['水流的幸福大']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/037_11.wav\n",
      "['那個水蒙在放,一心想流得嘩嘩的已經流去了他還是漫不經心的,還是讓老金想到別的地方去了手裡摸到一個房子他就是這個這個事情找了那個兩個姐弟啊,那個姐弟一心想去拿那個美心西點的蛋糕拿下來但是那個凳子,一個三個腳的凳子這個凳子馬上就要倒下來了,那個怎麼辦?這個妹妹就想到,她手裡還拿一個凳子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/037_12.wav\n",
      "['這個凳子馬上就要倒下來了那怎麼辦?這個妹妹就想說她手裡還有一個蛋糕可是眼線的都拿不到了那個東西都要架下來']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/037_13.wav\n",
      "['口琴']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/037_14.wav\n",
      "['冰库 冰是叫什么用冰做的住家的地方房子 这个叫什么 圆规']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/037_2.wav\n",
      "['香蕉、鳳梨、枇杷、葡萄、楊桃、蓮霧、西瓜、香蕉、梨子、柱子、柳橙、楊梅、百梨、二十四季梨']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/037_3.wav\n",
      "['板犁二十四季犁还有什么的香蕉有讲过板犁就是我们的板犁这个是我们家人讲的摸四边加一个板子板犁就是我们现在外边用的火爆出来炒在沙子里面炒出来的那个叫板犁那我再介绍绿色白色深蓝色浅蓝色']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/037_4.wav\n",
      "['我可以教法律嗎?好啊,那我得見書']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/037_5.wav\n",
      "['差不多了吧']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/037_6.wav\n",
      "['苗栗縣台中縣豐原市彰化縣南投縣霧峰市嘉義縣吳鳳鄉台南市新營市高雄縣']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/037_7.wav\n",
      "['這個太太心裡想著什麼地方去了她在擦盤子的時候沒想到那個水龍頭一直在放水水都倒去了那她的小孩她為了要去拿那個蛋糕可是那個凳子又快倒了馬上就要掉下來了她的妹妹在']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/037_8.wav\n",
      "['他去拿那個蛋糕可是那個凳子又快倒了馬上就要掉下來了他的妹妹在...妹妹就扶他眼見到就意味馬上就發生嚴重的事情了OK,還有啊?還有...是啊,他馬上就把神龍說你趕快關下來不關就家裡要長大誰他那個弟弟很危險馬上就要倒下來倒下來眼見到就那個蛋糕也吃不到了那是蛋糕嗎?蛤?七點嗎?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/037_9.wav\n",
      "['然后又底地很危险马上就要倒下了倒下了眼睛就那个蛋糕也吃不到了那是蛋糕吗?西点嘛美心西点眼睛的这个点心也吃不成了OK 厨房有窗帘啊这个凳子快倒了有盘子啊都讲到了嗯 早餐这个水流的这么大他这个太太眼睛心不在焉她是外面是一个在院子里面']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_1.wav\n",
      "['對 母親都仔細看了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_10.wav\n",
      "['那種企鵝也算吧?算啊,算耶企鵝猴子貓咪狗有講過了啊動物螃蟹算不算?算螃蟹蝦子這些呢?算啦魚、水果西瓜、鳳梨香瓜、木瓜番茄哈密瓜冬瓜']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_11.wav\n",
      "['香瓜、木瓜、番茄、哈尼瓜、冬瓜、南瓜、水瓜、鳳梨、草莓、香瓜有了吧?有了草莓,還有水瓜、冬瓜、南瓜、草莓,不知道還有什麼喔!還有芭樂,還有鳳梨']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_12.wav\n",
      "['不知道还有什么哦还有芭乐还有还有凤梨差不多了南瓜你给我讲这几个讲那儿红白黄绿蓝定制橘咖啡还有浅浅浅的绿还有这种这种蓝讲过了紫也讲过了差不多了白色有讲过吗']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_13.wav\n",
      "['蓝讲过了,紫也讲过了,差不多了白色有讲过吗?橘色,白色也讲过了咖啡色,像牛皮纸就咖啡色了粉红色,橘色,黄色,白色,蓝色,绿色差不多了吧,我不知道了还有什么颜色?台北市台中市台南高中']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_14.wav\n",
      "['我不知道了,还有什么也是啊?台北市台中市台南、高雄、基隆然后就...四就是...这边也是一个市台北市、高雄、基隆、高雄台南还有什么地方啊?苗栗']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_15.wav\n",
      "['台南苗栗台南几个了不够啊台中好像有了唐侯够了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_2.wav\n",
      "['這個小朋友就在拿點心給妹妹啊這個媽媽媽媽就在洗這些盤子啊水就滴了滿地啊水龍頭開了沒關而且這個小朋友這個凳子好像蠻危險的他歇歇有摔跤他是媽媽我想是這個廚房盤子啊這個碗啊水龍頭啊這個啥的嘛還有這個椅子啊這個摔跤了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_3.wav\n",
      "['好 那他們在']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_4.wav\n",
      "['這個是鍋鳥筆這個仙人掌剪刀聽診器駱駝這個人家那個色的標題口琴衣架這個是一個畫了一個三角龍三角器嗎?這是一種斜斜的這樣剪著叫做什麼金什麼這個三角叫金什麼不曉得沒看過這個這一段金什麼金字塔']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_5.wav\n",
      "['金什麼 這個三角叫金什麼 不曉得沒關係 這一段金什麼金字塔這是一朵花這是牛水牛的 豆牛的這種犀牛啊對好來這是一個漏斗這個呢 這是一個呢 棧板這個是拉的那個 像縫紙就是琴這樣拉的手風琴啊這張手風琴這張球 兩角器這個是電器']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_6.wav\n",
      "['手風琴啊?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_7.wav\n",
      "['好這個這個就是皮毯了今天彈的這個琴叫做什麼琴我不知道這個是人意這個就是一個架子上面給它長東西腳架叫什麼叫做花器我不知道尾巴這種東西還有這個海馬很好這個呢這個香菇好這個呢這個是一個好像蓋了一個房子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_8.wav\n",
      "['這是海馬這個呢?這個箱子這個呢?這個是一個好像蓋了一個房子給小狗進去的就是雕堡變成的你一直告訴我這叫雕堡這是入口啊然後我一直會畫圖這個圓錐是不是腳腳叫反正這個要釘在那個釘上面然後這個畫圖圓龜啊太久不用學了獅子老虎']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/038_9.wav\n",
      "['對對對']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_1.wav\n",
      "['王陽文醫伯母再來我要請妳告訴我所有妳想得到的動物喔有哪些動物那我們不管按到什麼順序請妳告訴我越多種越好請妳開始說獅子老虎袋鼠企鵝還有企鵝鴨子雞大象']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_10.wav\n",
      "['有其他的,要越詳細越好']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_11.wav\n",
      "['不是喔就在廚房裡面這樣子媽媽在洗碗水滿出來啦好,伯母那我請問妳喔這個圖上面有哪些的人有媽媽跟姊姊弟弟然後這個圖上面還有沒有看到什麼東西是剛剛沒有講到的東西剛剛沒講到的盤子餅乾還有其他的東西然後他們在做些什麼事情有沒有剛剛沒有講到的他們就在']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_12.wav\n",
      "['他們在做些什麼事情?有沒有剛剛沒有講到的?他們就在洗碗啦弟弟在拿點心啦他站不好會摔下來椅子傾斜大概就這樣子好,然後請問您喔我們一般都說這個叫什麼名字?柱然後這個呢?瓜苗這個呢?鉛筆這個呢?仙人掌很好這個呢?剪刀']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_13.wav\n",
      "['然後這個呢?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_14.wav\n",
      "['這個呢']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_15.wav\n",
      "['這個叫什麼?什麼?半圓規可以然後這個呢?電梯對然後這個這個是圓規這不是圓規喔那照相腳架它有個名字叫什麼名字?一般我們都說這個叫三什麼三腳架對那這個呢?掃把然後這個這個叫叫什麼?叫什麼琴一般我們都說這個叫豎什麼豎琴那這個呢?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_16.wav\n",
      "['叫什麼 叫什麼琴一般我們都說這個叫樹什麼樹琴那這個呢輪椅然後這個這個就是花架對這個呢海馬對 很好這個香菇對 這個這個 這個是搖對 可以這個呢圓規很好喔好']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_2.wav\n",
      "['好,够多了哦!好,伯母,接下来我要请你告诉我所有你想得到的水果哦!有哪些水果?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_3.wav\n",
      "['母親,請告訴我所有你想得到的水果有哪些水果?請你盡快告訴我,越多種越好']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_4.wav\n",
      "['櫻桃草莓楊桃自家水梨還有哪些?柚子好,夠多了喔再來我要請姊姊告訴我所有你想得到的顏色喔有哪些顏色?那一樣我們不管按照什麼順序你盡快告訴我越多種顏色越好喔請你開始說紅藍綠白紫']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_5.wav\n",
      "['你盡快告訴我越多種顏色越好喔請你開始說紅藍綠白紫橙淺綠淺藍黃色紫色黑色白色桃紅色深紫灰色淺灰差不多吧再想想看橘色好 可以喔好 伯母再來請你告訴我所有你想得到的在台灣的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_6.wav\n",
      "['姜姜 橘色姜姜 好 可以喔姜姜 好 伯母再來請妳告訴我姜姜 所有妳想得到的在台灣的縣市鄉鎮有哪些喔姜姜 那也是不管按照什麼順序姜姜 請妳盡快告訴我越多個縣市鄉鎮越好喔姜姜 好 請妳開始說']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_7.wav\n",
      "['桃園市桃園縣三重市三重縣還有彰化縣市台中縣市台南縣市還有台東縣市高雄縣市彰化有了有雲林雲林縣市南投南投縣南投市谷坑市南投市谷坑']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_8.wav\n",
      "['姑姑先是南投南投先 南投是古坑是南投是古坑可以雲林吧對好 夠多囉古坑先這樣夠不夠夠了 夠多了好 再來喔再來我要給姑姑看一張圖片然後請你媽先仔細的把這個圖片整個把它看過一遍喔先看過 然後詳細的告訴我']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/039_9.wav\n",
      "['媽媽會仔細的把這個圖片整個把它看過一遍喔先看過然後詳細的告訴我你看到什麼然後他們在做些什麼媽媽洗碗把水溢出來小朋友拿餅乾拿椅子站不穩會掉下來他們其他的會詳細就好不要爬高高會跌倒']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/041_1.wav\n",
      "['他好像是在洗盘子在洗盘子这里还有一些杯子他拿那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那个那']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/041_10.wav\n",
      "['青黄蓝白黑 还有金色的 绿的我讲过了嘛台北县 台北市 桃园县 桃园镇 中历市 银歌镇 台北县的银歌 三重 林林 台中 彰化 园林']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/041_11.wav\n",
      "[' me']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/041_2.wav\n",
      "['他也得告訴她要特別注意這個就是水你看弄得到處都是這樣太危險了美心西是嗎好像是西蘇病是不是這個水流下來了這個是個女生這好像是個男生這個是個女生這兩個這個好像是在家裡的嘛這裡啊這裡她在洗盤子洗碗嘛水流下來了這個她踩了個凳子不小心不行了她手上拿了個什麼水']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/041_3.wav\n",
      "['这是他在洗盘子洗碗嘛水流下来了这个他踩了个凳子不小心不行了他手上拿了个什么水果什么东西洗点面包什么东西这是个竖这是一个锅油这是铅笔这也是一个竖那个叫什么那是那个说不起来的线槽剪刀这你们用的那个听筒听真器这是骡头这是小孩子玩的那个飞镖']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/041_4.wav\n",
      "['这是剪刀这是你们用的那个听筒听真器这是骡驼这是小孩子玩的那个飞镖这是个锯子这个我都不晓得了乐器是一种风琴是吧口琴有这样的我再看一下这是这个吊衣服的这个吊衣服泥浆这个好像是可以放东西什么东西啊金字塔这是一个花这是一个水牛象犀牛这是漏斗这叫那个钳子什么东西']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/041_5.wav\n",
      "['这是一个花这是一个水牛象犀牛这是漏斗这叫那个钳子什么东西这算盘这书架手琴风琴手拉风琴手提琴这是我们球拍这是一个那个计算的这个半元器就一般的对它叫做什么元器这是计算器对出来角度有点好的这是聊那个这是个什么']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/041_6.wav\n",
      "['计算机对 侧脸角度有点这是个什么这是上楼梯的这是个三脚架这是一个刷子刷子 或者是毛毯刷子这是个手风琴是吧这是手琴什么东西手琴这是个轮椅这是窗户窗户架什么']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/041_7.wav\n",
      "['这是窗户窗户架什么荒原里面的那时候隔那个就是叫人不要随便进去的那个围篱篱帮这是一个什么这不懂对对对是个动物海盗这是那个我一直想不起来叫那个吃的那个叫魔头魔肉魔头这是一个']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/041_8.wav\n",
      "['这是一个']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/041_9.wav\n",
      "['像是驴 猫像是字说过了哈 只要是它词 黑 黄 蓝 凤梨 羊 桃哎呀 于是想不起来了甘蔗 凤梨 凤梨讲过了 嗯 它词红 黄 蓝 白 黑 绿 金色的 嗯紫色的 黄色 红黄蓝白黑 红黄蓝白黑紫 还有金色的 绿的我讲过了嘛']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/044_1.wav\n",
      "['鸚鵡鸟马雀老鹰那个蜀雀乌鸦蛇老虎豹子那个蛇蝶舞铃子叶子一直喝那个水那个柳丁百香果汽车火车飞机人船那个潜水艇游轮']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/044_10.wav\n",
      "['一个猪尾巴这是黑马相公这是那个那个S寂寞人的那个那个住的地方这个也不是吊爆也可以说是吊爆冰雾这是野龟']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/044_2.wav\n",
      "['汽车、火车、飞机、人船潜水艇、流泪高铁、机应碟加拿大车、摩托车轿车、休闲车红色、黄色、白色、黑色紫色、粉红色、蓝色、草绿色、黄色差不多就这些颜色']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/044_3.wav\n",
      "['紫色 粉红色 蓝色 草绿色 黄色差不多就这些颜色蓝色蓝色就Blue那个Green草绿色台北市台北县这个桃叶县桃叶市那个新洲市新洲县苗栗县苗栗市还有那个苗栗人民县 九六市那个九六还有那个那个彰化县']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/044_4.wav\n",
      "['人名县 九六市那个 九六 还有那个那个张化县 张化市嘉义县 嘉义市这个台南县 台南市高雍县 高雄市小孩子在拿点心吃但是他这个凳子因为重心不稳好像要摔下来他妈妈在下面']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/044_5.wav\n",
      "['凳子因为重心不稳好像要摔下来他妹妹在下面接他拿的东西他妈妈正在洗衣服这是洗牌子吧洗牌子洗完了要擦擦干在厨房里工作他是一个family那个是妈妈跟孩子姐妹那个大概是一个是哥哥一个是妹妹']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/044_6.wav\n",
      "['那个是妈妈跟孩子姐妹那个大概是一个是哥哥一个是妹妹因为他妈妈在厨房工作洗碗盘外面是他们的那个后面的好像是花椰吧他那个水买出来了买到那个地板上了他妈妈是在擦那个盘子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/044_7.wav\n",
      "['买出来了买到那个地板上来他妈妈是在擦那个盘子因为这个支来水开得太大都买出来了他哥哥在拿饼干吃也拿给他妹妹但是他的重心不稳这个凳子好像要摔跤这样这是一棵树这是一个蜗牛一只蜻蜓这是那个叫做什么']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/044_8.wav\n",
      "['这是一棵树这是一个蜗牛一只蜻蜓这是那个那个那个叫做什么那个那个那个仙人掌哎没错这个呢剪刀听真器这是骆驼这是那个飞镖剂子口琴这是鱼架这是金字塔这是一朵花这是那个河马还有犀牛这是一个漏斗这个是夹子加那个方舱']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/044_9.wav\n",
      "['这是一个河马 犀牛这是一个漏斗 这是夹子加了个方舱 这是帅牌这是手风琴 这是网球拍这是一个野怪 这是两脚签这是那个楼梯 这是一个赛车架这是扫把 这是竖筋 这是人影这是一个猪列巴 这是黑马相公这是那个那个S寂寞人的那个']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/045_1.wav\n",
      "['媽媽在洗碗那水槽的水溢出來了水龍頭沒關水溢出來了那這是哥哥還是弟弟在拿餅乾在櫃子上拿餅乾妹妹在下面等哥哥拿餅乾給他伸手等餅乾那哥哥的椅子快要半飽了還有這是一個夏天所以他們都是穿著短袖子媽媽工作得很快樂所以']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/045_2.wav\n",
      "['還有這是一個夏天所以他們都是穿著短袖子媽媽工作得很快樂所以有點笑容妹妹想要跟哥哥不要講什麼應該這樣OK吧廚房他看到從有個窗戶廚房有個窗戶窗戶窗簾打開的時候看到外面一個小花園那花園有花還有對面的對面這是應該是對面的吧對面的風景']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/045_3.wav\n",
      "['花園有花,還有對面的風景從窗戶裡看過去有棵樹,有個房子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/045_4.wav\n",
      "['金銅駱駝色標色紅心的柄子口琴衣架金字塔花犀牛駱駝夾冰塊的夾子算盤手風琴羽毛拍瓏龜']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/045_5.wav\n",
      "['這個叫做尾毛拍']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/045_6.wav\n",
      "['扫帚']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/045_7.wav\n",
      "['海...海什麼?海...海...海魚什麼?海什麼?叫不出來我知道可是我叫不出來這個是香菇蒙古包這樣子啊這個是什麼?冰包冰...冰包嘛冰餃這個才是原歸']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/046_1.wav\n",
      "['不管道就盡說']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/046_10.wav\n",
      "['你叫他 告诉他说你这个要摔跤了对大概就是这样然后看到盘子对 很好弄头 水 窗子窗外有点镜子这个垫子蛋糕这个半灯两个小朋友这个厨房的这个用具这个厨具这个厨柜对就这些他在擦盘子他在拿这个蛋糕他在和他讲话对话窗帘呢']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/046_11.wav\n",
      "['对就这些他在擦饭纸他在拿这个蛋糕他在和他讲话对话窗帘啊窗外的外镜啊窗外镜外镜啊还有花铺啊花铺也有对这边是看到的是壁书吧凳子吧两个小朋友嘛蛋糕 皮帖这是书这是蝸牛铅笔这是写印章剪刀听听器骆驼飞镖']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/046_12.wav\n",
      "['这是蝸牛 铅笔这是仙人掌 剪刀听针器 骆驼 飞镖 锯子这是扣钦 这是衣架这是戟子塔 这是花这是犀牛 这是漏斗 这是夹子这是黄铜的夹子 算盘手风琴 网球盘这个是圆规 半圆规这个是楼梯 垫幅梯这个是三脚架这个是圆规呀 圆规是三脚架']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/046_13.wav\n",
      "['半圆规这个是楼梯 垫付梯这个是三角架这个是圆规呀是不是圆规是三角架应该是三角架这是扫把这个是竖青这个是鳞衣这个是华府里面的这个花甲这是黑马黑马这个是军这是S军的房子我们都叫他叫这个呢这是圆规']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/046_14.wav\n",
      "['这是阿斯金沃的房子我们都叫它冰屋这是烟柜']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/046_2.wav\n",
      "['快跟我說']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/046_3.wav\n",
      "['好快跟我說香蕉、鳳梨、釋迦、蓮霧、西瓜、香瓜、荔枝、龍眼、草莓、鳳梨、蘋果、梨、荔枝、起鍋、葡萄、石榴、椰子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/046_4.wav\n",
      "['石榴,椰子,木瓜,台灣常吃的木瓜,楊桃,桂圓,紅黃藍白黑,綠,靛,紫,土黃色,灰白色']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/046_5.wav\n",
      "['黃藍白黑綠電汁土黃色灰白色藏青色咖啡色橄欖色白色紅色橘色橘色天藍色']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/046_6.wav\n",
      "['好']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/046_7.wav\n",
      "['嘉义、台南、高雄市、高雄县台南市、屏东县然后乡镇方面就是基隆的七都、八都、五都台北的是这个路州、三重、新庄、云鹤、中鹤、班峭班峭、八里、内湖']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/046_8.wav\n",
      "['雲鶴、中鶴、班轎巴黎、內湖、中壢、平鎮、普新我都去過這兒我看到媽媽在整理廚房因為水龍頭沒管好水都漫出來了接地兩個修飛兩個']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/046_9.wav\n",
      "['因為水龍頭沒管好水都漫出來了然後接地兩個修閉兩個房子接地兩個就在開閉處來找東西吃因為哥哥的動作太超率太貪婪了妹妹就很驚嚇的叫她告訴她說你這個要摔跤了大概就是這樣然後看到潘子龍頭']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/048_1.wav\n",
      "['动物就可以了不管是热血的冷血的猪牛羊马鸡兔龙乌龟鸟蟹叶香香姜了老鼠猫elephant蛇snake选过了蜈蚣跳躁跳躁算不算鸡牛羊都讲过了蟹叶差不多了蜂蜜香蕉芭乐羊桃桃子西瓜杨梅番茄柳五花果水梅藻香菜']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/048_2.wav\n",
      "['這樣好']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/048_3.wav\n",
      "['有一個小孩在拿美信吸點一個女孩子在旁邊問他要這個東西他的媽媽在吸盆子但是吸水槽裡面的水都滿到碗裡來了她的窗簾把它拉開來的可以看到碗裡的風景拿美信吸點的餅乾那個雨之外下的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/048_4.wav\n",
      "['把它拉開來的可以看到完美的風景那個像拿那個美心美心西地的餅乾那個魚之外下的它一定要掉下來了其他沒有了你看那個這個應該是媽媽這個應該是她兒子這個是她的女兒廚房裡面對那個她這個燴氣台了還有一個這個這個帶回來開的這個窗還有一個這個廚子還有一個凳子那個那個那個櫃台細碎槽兩個盆子這個兩個碗一個盆子窗簾']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/048_5.wav\n",
      "['还有一个凳子那个柜台吸水槽两个盆子两个碗一个盆子窗帘好了 没了树 蜗牛 铅笔仙人掌 剪刀 清真纸骆驼 标 锯子口琴 衣夹精神厂画 仙牛楼斗 家具 算盘寿风镜 网球盘 六分椅半圆滚楼 垫护梯 三居家 沙发拖把 沙发 沙发寿风镜 提琴寿梯琴 蜡琴 树琴']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/048_6.wav\n",
      "['手提琴啦,蠟琴,豎琴啦,這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?這個呢?这个呢?这个呢?这个呢?这个呢?这个呢?这个呢?这个呢?这个呢?这个呢?这个呢?这个呢?这个呢?这个呢?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/049_1.wav\n",
      "['老虎豹 猫 狗 猫有吧狗香了香不起来了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/049_10.wav\n",
      "['很乖']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/049_2.wav\n",
      "['那个香蕉 军风的橘子枸杞那个想不起来了苹果红黄蓝白褐还有绿颜色还有黄颜色还有红颜色还有紫颜色还有白颜色蓝颜色黄颜色有吧还有想不起来紫颜色还有台中']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/049_3.wav\n",
      "['还有白颜色蓝颜色黄颜色有吧还有想不起来紫颜色还有台中高雄台南很好台北青年港这个台中的这个这个中间的还有我来看原子明想不起来原这个原子明']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/049_4.wav\n",
      "['原住民,想不起来原住民这个是老百姓地方在乡下在哪一个地方三角洞他在看窗户窗户把他打起来他在告诉他拿东西,知道吧这个盆子他在看盆子他手里拿的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/049_5.wav\n",
      "['拿东西的啦这个盆子啊他在看盆子他手里拿的是丝丝那个圆盆子的四个角窗户窗户外面没行李垫他在看洗碟拿洗碟给他吃不晓得他是妈妈他是儿子他是女儿在家里 客厅里 自来水窗户外面有屋子那个窗户窗户门这个看着']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/049_6.wav\n",
      "['家里 客厅里 自来水窗户外面有屋子那个窗户 窗户门这个看着他们在拿吸尖针 妹妹吃他妈妈在弄电信书 蜗牛 铅笔这个是这个是这个是箱子看不出来的这是杉 植物有 有 仙龙杖剪刀 听机 医生用的听 听 听']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/049_7.wav\n",
      "['有']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/049_8.wav\n",
      "['这个没有看到过']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/049_9.wav\n",
      "['人鱼 这个是叉叉这个草哪里用的有这个三角虾 泥巴 水 蚝牛 虾 虾骨 土豆 火炉 冰壶花都用的 花三角 这个是不晓得 云龟']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_1.wav\n",
      "['动物我家里都没有养动物动物我现在我都没有给动物接近就自从我猫 猴 鸡 鸭这个那个鱼类算不算动物成见的就是这些了其他动物那就很复杂了那都古古怪怪在电视上看到的动物一时想也想不起来很复杂']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_10.wav\n",
      "['他就是上去拿东西啊这是窗帘呢还有看到什么这个好像是放着什么东西这都说不上来了他放在家里每一个家庭它各有它的这个这边呢好像是一个桌子吧还有看到什么看不上说不上来的这个好像这个小孩子上去拿东西好像是']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_11.wav\n",
      "['这个好像这个小孩子上去拿东西好像是拿这个究竟是吃的东西还是什么这个也要要你也给我大概意思你也给我一点吧这个是一棵树吧这个是蜗牛啊这个原子笔也是这样这个显印章这个剪刀这个大夫用的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_12.wav\n",
      "['这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约翰逊的这个约�']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_13.wav\n",
      "['这个不知道什么东西看着说不上来金铃驰这是一朵花这个是牛它不是牛这是犀牛这是杯子好像是厨房好像是个漏斗是什么东西这个夹子夹缸算了这个挖丝漏又不像']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_14.wav\n",
      "['这个漏斗是什么东西这个夹子夹钢算吗这个这挖丝漏又不像啊越挖越对对这个这叫什么拉琴是什么东西手琴呢这个是球拍这个是画图用的这个工具这个画图有个尺有尺子是不是量它的这个需要的尺子需要的这个这个这个这个度数不知道我用我不用这个东西这个好像是']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_15.wav\n",
      "['需要的这个这个这个这个度数不知道我用我不用这个东西这个好像是这个可以上楼梯一样这个是三角架吧这个扫把这个说不上来了而且呢它这个一个柱子这个有时候有些那我就说不上来了这个这个这个病人用的这个车子坐车坐轮呢']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_16.wav\n",
      "['这个病人用的车子坐车坐轮轮车这个好像花园那个花棚子是不是花棚啊轮那叫指甲是什么轮甲花甲这个是一个动物是什么东西这个好像是一个动物叫什么我不常见不说白说这个好像是一个杯子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_17.wav\n",
      "['叫什么我不常见不说不明白这个好像是一个杯子吧哦那个叫什么我说不上来了蘑菇这个是一个这个说不上来哎对对对有一个像不知他叫哎说不上来我说不来这个呢这个画图的一个工具叫画图这个叫哎圆尺']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_18.wav\n",
      "['用工具就画图这个叫花哎 渊池']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_2.wav\n",
      "['古古怪怪的在电视上看到的对我一时想也想不起来很复杂那个龟啊那个动物还有呢龟啊猫啊狗啊这些东西很好还有呢我家都不养这些东西我伯伯知道的老虎 豹子这个什么的很好水果都是经常吃的这个柳丁啊杨桃啊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_3.wav\n",
      "['这个柳丁啊,羊头啊有的时候小孩子买贵的水果,荔啊,那都买很贵的也不是经常吃还有什么? 还有什么? 柳丁是经常吃的,是不是? 还有什么? 羊头,尽量讲 柳丁是经常吃的,是不是? 还有什么? 羊头,尽量讲黄瓜像不像水果? 黄瓜像不像水果?没有 没有西瓜,香瓜,那个羊头我已经想过了 西瓜,香瓜,那个羊头我已经想过了请说 请说红蓝黑']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_4.wav\n",
      "['这个 这个那个阳台我已经想过了请说红 蓝 贺 鲜 绿这个四红色就这几种了四色 浅蓝色浅红的没有这想不起来最初想不起来很复杂就是说我家小孩子去了好请说高雄 高雄县 屏东 桃园']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_5.wav\n",
      "['我家小孩子,高雄縣,屏東,桃園,台中,新竹,台北縣,台北市,雲林縣,雲林縣我想不起來了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_6.wav\n",
      "['这个小孩子好像是拿一个凳子上去拿东西这个小孩子好像是在地上看着够不到']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_7.wav\n",
      "['好像是拿一个凳子上去拿东西这个小孩子好像是在地下看着够不到手够不到是这样的尽量讲这个好像是桌子吧这是窗帘这桌子放着什么东西这是桌子吗这个他个子够不到的拿个凳子站起来他去这个东西']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_8.wav\n",
      "['隔着够不到的,拿个凳子站起来,取这个东西他好像是拿这个什么东西这个在爹这个小孩子他说你拿的东西给我了好像他趁热要这个东西就这样这个不知什么意思了这个是什么这个好像是一个是个束缚,什么也不像']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/050_9.wav\n",
      "['这个是什么这个好像是一个是一个书壶上也不像这些人他就可能是这个好像是妈妈这个好像是孩子这个是哥哥好像这个是妹妹他们好像是在家里的那种家里的书店家里的一个他就是上去拿东西拿东西的这个这是窗帘']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/052_1.wav\n",
      "['狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗狗']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/052_10.wav\n",
      "['跟米拉石一樣的,做木頭的,做畫的到了到了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/052_2.wav\n",
      "['有很多想不出來']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/052_3.wav\n",
      "['荷蘭進口的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/052_4.wav\n",
      "['屏東縣台中縣台南縣南道縣遠寧縣六里縣桃園縣新竹縣黃陵港黃陵縣宜蘭縣六里縣沒有了南道縣好我再這樣修半年就歪了對你夾不住了還有那隧道那裡上面換什麼架子沒有了想詳細一點對這個完了擺給你修多快八個人四四姐妹在那裡在火花']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/052_5.wav\n",
      "['想詳細一點這個碗擺給你修圖八個人四四姐妹在那裡在佛環在住坡照咖照咖照咖裡面的東西這邊這個布子蓋著什麼有的倒水這個布門拉開門窗了她們不知道今天她在撿東西了拿下來雞蛋什麼東西拿下來一個接一個接半天快快做倒了沒有了灰啊樹啊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/052_6.wav\n",
      "['雞蛋什麼東西拿下來一個接一個接半天快快做倒了沒有了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/052_7.wav\n",
      "['落刀 镖 锯 这个纹钱啊 钩钱挂衣服里挂纸的衣挂这个不晓得说什么这些都没有意义啊这个酒什么的这个东西都有这个黑马什么 驸马黑马什么酒对啊杯子 烙水 烙油的东西我讲不出来是不是油倒里面有的东西对我回去我还想 有碗啊 烙油接盘子的 接盘子的 接碗子的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/052_8.wav\n",
      "['我回去玩了 又玩了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/052_9.wav\n",
      "['蓋房子什麼的 算什麼的你看池 電臺啊這個呢照相機架上酒架 掃把這個不曉得 被冷住的那個農爺這個泥巴這個不曉得叫什麼東西啊 海馬這個什麼 吃的東西是不是香菇這個什麼 好像收納的那種東西這個有個建築物 家住的好冷 天空裡面跟米納車一樣']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/054_1.wav\n",
      "['不論造型說動物是不是啊?名稱還是動物的名稱?就是鳥、蛋、鳥、獅子動物的名稱是不是啊?鳥、老鷹白鷲鷗、鸚鵡、麻鞘、鵝子、鳳凰老虎、獅子、羚羊、龍獅子、羚羊牛、馬、犀牛、牦牛']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/054_10.wav\n",
      "['这个是树 树芹 梁芋这个是人家那个窗子外面的花架这个是海麻 这是蜷 蜷缕过了这是S级默认这个冰 冰的房子了冰窝 燃烧器圆规 这圆规 怎么的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/054_2.wav\n",
      "['土豆']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/054_3.wav\n",
      "['葡萄柚']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/054_4.wav\n",
      "['還有']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/054_5.wav\n",
      "['彰化縣 彰化市 元林市 永齡縣嘉義市 嘉義縣 台南市 台南縣高雄市 高雄縣 台東縣 台東市 屏東 花蓮 宜蘭 宜蘭 過了是基隆 基隆是台北縣就象徵不一樣也可以啊那再過來就兜圈了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/054_6.wav\n",
      "['基隆是台北縣有象徵都一樣也可以啊那你再過來就兜圈了那到基隆七堵八堵七堵八堵雙山有看到什麼東西有講的故事說越詳細越好在洗糰子可是呢大概在講話的時候呢水龍頭都沒關留下來了那麼這個小孩子呢在站在凳子上呢去拿餅乾吃不小心呢凳子滑倒了那他的姐姐或者妹妹']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/054_7.wav\n",
      "['他要看不可以講']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/054_8.wav\n",
      "['那個媽媽在擦盆子水龍頭忘了關都留下來了廚房的櫃子上面有兩個盆子這是我們小碗的一個盆子窗子外面是一個花園有草還有一個小路窗子有兩個窗簾這顆是蚵牛千比仙人掌剪刀金針器鹿頭錐錶橘子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/054_9.wav\n",
      "['這是人家車輛的架子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/055_1.wav\n",
      "['狗、猫、兔子、羊、牛、老虎、狮子差不多吧还有龙、牛、还有什么兔子差不多了吧你说这个小动物的老鼠、狗、猫、鸟、猴子差不多吧龙、狮子、老虎、牛差不多吧哎呀 这样子吧水果嘛 水果嘛 葡萄、核桃']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/055_10.wav\n",
      "['这个玩具我不懂 没有玩过飞人我不晓得这个鞠子嘛口径的嘛衣服的架子这个倒不要这个什么看不懂这个什么金字塔这个花牛这个是牛的什么梅兰的东方圆圆的不是牛啊象啊牛啊茶杯嘛茶那个叫什么流水的那个豆子豆豆子这个茄子切东西的蒜派']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/055_11.wav\n",
      "['那個叫什麼流水的那個豆子豆豆的肉豆啊這個茄子啊切東西的蒜白啊這個看的風景啊手機鏡手機風景嘛王炮啊王劍炮子這個米德菜嘛這個用的這個是工程方面的米德菜嘛蒜的菜啦這個可以菜的涼菜的工程師用的涼那個涼什麼菜這個工程方面用的啊這個樓梯啊三角架掃帚這是什麼風景啊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/055_12.wav\n",
      "['這個樓梯啊,三角架,掃帚,風景啊,樂器啊,這個叫樂器什麼樂器啊,這個我沒看過,那個能藝,這個倉利吧,倉利的倉練步啊,這個倉,這個是一個一個,這個老不曉得,這個沒看過嘛,臉什麼,挖臉啊,這個什麼,好像羊的吧,什麼什麼,這個不是羊,這個我看不懂,這個什麼沒看過,還不曉得,這個沒看過,這個好像蒙古人啊,']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/055_13.wav\n",
      "['什麼什麼這個不是羊這個我看不懂這個什麼沒看過還不曉得這個好像蒙古這個叫什麼菇啊吃的香菇的吧這個防空洞吧但是它有個建築物這個是北方人家在那睡在裡面的感覺這個叫不出來冰什麼這個沒得測的吧這個不是美甲器嗎這個是畫頭用的原測的吧']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/055_14.wav\n",
      "['是先画头用的原测的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/055_2.wav\n",
      "['牛差不多吧水果 葡萄 核桃 龍眼 蘋果 香蕉 鳳梨差不多了吧西瓜西瓜 還有 楊梅 草莓差不多了龍眼 柱子 核桃差不多了蘋果 生梨 梨子差不多了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/055_3.wav\n",
      "['蘋果的生理離子差不多紅黃藍白和紅黃藍白和紅黃藍白和深綠藍綠可以了咖啡淡綠草綠可以了差不多了白色的褐色黃色天色天藍色可以了草綠淡黃深藍粉紅可以差不多了褐色褐色白色差不多了淡黃這樣可以了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/055_4.wav\n",
      "['可以差不多了黑色白色差不多了淡黄这样可以了台北台南台中高雄麻豆澎湖还有嘉义台南县苗栗差不多了吧新座差不多了还有台中县台南县高雄县高雄市台北市差不多了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/055_5.wav\n",
      "['还有台中县台南县高雄县高雄市台北市台南差不多了还有什么地方台南市高雄市高雄苗栗县新座县新座市这个我比较懂我以前在地方政府做事的在哪里要做好他在厨房里洗碗洗碗嘛水流出来他两个一个妹妹一个哥哥吧来帮他拿东西啊拿点心拿给他吃是不是']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/055_6.wav\n",
      "['一個妹妹一個哥哥吧來幫她拿東西啊拿餅心拿給她吃是不是啊你看她拿什麼東西啊給她妹妹吃妹妹在旁邊她站在那個椅子上面要像跌下來的樣子還可以啊詳細一點哦她都要差不多要跌下來了斜下來了這個大概一個哥哥一個妹妹一個媽媽大概廚房裡面的東西啊那個水要流下來了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/055_7.wav\n",
      "['大概一個哥哥一個妹妹一個媽媽大概廚房裡面的東西水有流下來吸完嘛廚房裡的東西啊所以留在外面的這裡外面的外面一樣外面的鏡子嘛火這個水燒了嘛外面看不出來外面外鏡嘛窗口外面它是外鏡它在裡面嘛它在廚房裡面吸完嘛它這個掉下來的意思啊斜下來的要偷東西吃的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/055_8.wav\n",
      "['它在厨房里面洗碗嘛它这个好像掉下来了,椅子啊斜下来了要偷东西吃美心疾病嘛吃饼干嘛,大概拿饼干椅子怕掉下来,踩地上那你妹妹来等着它,给它吃这个树,这个泥这个叫什么叫吧这个叫什么叫不出来这个叫好像那个叫啥叫不出来瓜什么瓜']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/055_9.wav\n",
      "['這個叫好像那個叫啥我叫不出來瓜什麼瓜看不懂這個辮這個不曉得什麼這個是熱帶的有熱帶的植物好像是什麼叫不出來這個仙草剪刀這個聽筒羊米這個米這個駱駝駱駝駱駝這個什麼魚貓的魚貓劍這個完全我不懂沒有玩過飛我不曉得這個這個鋸子口徑的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/056_1.wav\n",
      "['马牛羊鸡鸭鹅狗猫鸟兔子鱼鹿象河马长颈鹿斑马狐狸水獭梨子苹果葱 林 香 椒 芒果']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/056_10.wav\n",
      "['有点像窗户的格子一样对 就是这个那就是攀爬架 滑架 海马什么孤 骏子这个我看是个蒙古堡还是一个逍遥的地方逍遥的吧这个是圆规']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/056_2.wav\n",
      "['梨子 苹果葱 柠檬 香蕉 芒果 芭乐 芭蕉哈密瓜福壽桃子草绿玫瑰红']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/056_3.wav\n",
      "['灰色草綠玫瑰紅這樣子可以算嗎?可以']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/056_4.wav\n",
      "['高雄、名同、宜蘭、花蓮、台東、礁溪、錫羅、淡水三芝、鳳林整張書的越想越好這個女孩好像在擦一個盤子可是心想到別的事情']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/056_5.wav\n",
      "['这个女孩好像在擦一个盘子,可是心想到别的事情那个水池里面水一直放,龙头也没有关,所以水就流到外面来了那这个男孩到那个上面柜子里面去拿点心吃一不小心凳子快要翻了所以这个女孩子就在叫他小心一点可是叫他小心一点还是叫他把东西吃了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/056_6.wav\n",
      "['所以這個女孩子在教堂要小心一點可是教堂小心一點還是教不好東西這個是快要跌倒了這個是水都快要淹到她的腳了這邊有好像有兩個咖啡杯等著要洗完這個窗戶外面有風景廚房一個盤子咖啡杯底下有櫥櫃']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/056_7.wav\n",
      "['厨房盘子,咖啡杯底下有橱柜上面也是个橱柜她已经把盖子打开了手拉了一个可能是一朵糖吧那个盒子上面写的是美心西冰这个女孩一个手指着她的嘴巴一个手就伸出来讨厌要拿东西的样子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/056_8.wav\n",
      "['吃在他的嘴巴那个时候就伸出来讨厌要拿东西的样子树蝸牛铅笔这个是这是野外的那种剪刀听筒骆驼飞镖鋸子口琴衣架这是金字塔吧一朵花一枝花杏仁漏斗假糖的夹子三排手风琴']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/056_9.wav\n",
      "['這是一個...']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/057_1.wav\n",
      "['狗、猴子、老虎、豹牛、羊、猪还有骆驼长颈鹿熊还有浣熊还有这个狮子还有狮子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/057_10.wav\n",
      "['一家人啊窗帘啊餐具啊就炉台在看到外面的风景这边就兄妹两个在这里在游玩啊一边吃东西一边在那里调皮捣蛋树 蝸牛 铅笔这是那个不是像什么这是那个哎呀 它名字我讲不上来了这是热带的那个']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/057_11.wav\n",
      "['不是像什么 这是那个哎呀 它名字我讲不上来了这是热带的那个仙人掌剪刀听诊器骆驼镖啊我们这不就叫飞镖吗对 这个呢鋸子口琴衣架金字塔菊花犀牛漏斗夹子算盘手风琴网球拍']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/057_12.wav\n",
      "['漏斗夹子算盘手风琴网球拍量尺这种是怎么测量测量做数学用的那个我们叫它量什么半规是吧半原规是吧这个垫幅梯三角架扫把这个理数琴轮椅这是爬花的那个架子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/057_13.wav\n",
      "['这个是爬花的架子这个是爬藤子的篱笆啊这算是篱笆吧这是河马这不叫河马叫海马说错了这个那个菇那个蒙古包吧碉堡啊不是叫蒙古包啊叫做冰窖是吧']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/057_14.wav\n",
      "['蒙古包吧 碉堡似的不是叫蒙古包啊叫做冰轿是吧这个呢这个是圆龟']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/057_2.wav\n",
      "['狮子还有狮子,我想还有驴子松鼠都可以是吧松鼠大象,还要吗?蛇鳄鱼河马苹果梨凤梨香蕉火龙果香瓜七果']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/057_3.wav\n",
      "['香蕉、火龍果、香瓜、奇異果、柳丁、葡萄、桃子、李子、百香果、芭樂']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/057_4.wav\n",
      "['香蕉也說過了吧?有,很好還有百香果芭樂榴蓮什麼那個...七果說過了吧?有,很好還有那個...柚子、蓮子紅的、綠的、藍的、白的紫的、黑的、黃的、橙色']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/057_5.wav\n",
      "['藍的白的紫的黑的黃的橙色對深藍那個淺綠對那個灰色咖啡色好還要嗎再進行一下那個咖啡色還有那個磚紅色對還有秋香色還有這個墨綠']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/057_6.wav\n",
      "['还有秋香色还有这个墨绿墨绿浅咖啡浅咖啡 深咖啡铁灰 藏青水蓝色对好怕快的跟我台北市台北县桃园嘉义台南高雄台中那个关渡']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/057_7.wav\n",
      "['嘉義、台南、高雄、台中那個關渡三重三峽、基隆土城、社子、鳳山、屏東宜蘭,還要嗎?國中七堵、八堵、野柳、淡水、金山還要啥?盡量想那個鹿港']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/057_8.wav\n",
      "['淡水金山還有啥盡量想路港彰化花壇豐原阿里山好很多地方家庭主婦在洗盤碗洗餐具水都漫出來了小孩子在拿點心妹妹給他要']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/057_9.wav\n",
      "['洗餐具啊水都漫出來了小孩子在拿點心妹妹給他拿給我點心吃就住在廚房裡的生活外面有院子啊有花草小孩子要摔倒了他沒有站穩椅子上摔下來了差不多在些一家人啊窗簾啊餐具啊爐台在看到外面的風景']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_1.wav\n",
      "['你越讨好动物太多了 这个动物读不出来了所以我有些事情所以我又想得不像又想得不多也不敢也不敢想肉 马 猪 水果这些平常对那我平常吃的吃的要什么什么苹果啊 水果啊这个 苹果 笛子对这些东西']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_10.wav\n",
      "['叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫什麼叫一蕨�']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_11.wav\n",
      "['這個叫什麼東西呢?這個叫什麼?這個叫什麼東西?這個就說不出來了哦哦哦這個就說不出來了這個是一個花吧這個叫什麼?這個叫什麼?這個叫什麼?這個叫廚房的用具這個叫什麼?這個叫什麼東西?對這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼?這個叫什麼']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_12.wav\n",
      "['老什麼東西對老什麼他比你走什麼什麼叫什麼肉~~這跟吃過什麼東西我也說不出來了拿冰塊給夾什麼夾子對船舶什麼他叫做那是一個樂器樂器樂器我就不知道了我就不知道了這不說何辦什麼什麼這個叫什麼我也說不出來畫用的他說的花紙如果說什麼兩尺八']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_13.wav\n",
      "['這是座椅面的哦']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_14.wav\n",
      "['我放在上面的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_15.wav\n",
      "['孩子的孩子叫孩子们的孩子我都教不出来可是很多东西我都说不出来你教我说说我也接着接过来就说不教不教你这个是买美和什么什么菜美呢然后地球地盘哦什么什么搞不清楚这个是画什么图啊面纸面纸面纸面纸搞不清楚']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_16.wav\n",
      "[' Go.']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_2.wav\n",
      "['蘋果啊 水果啊這個 蘋果桔子這些都是桃子啊或者說都想不想吃都要吃到了就想吃了別吃了你就會想了啊這是皮啊現在顏色呢都是武漢的顏色的褐色對青色褐色 青色 褐色褐色 青 藍']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_3.wav\n",
      "['對']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_4.wav\n",
      "['現在的話,像也不算像']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_5.wav\n",
      "['好']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_6.wav\n",
      "['这个男孩子讲的证字里面有个勾什么东西这个女孩子呢告诉他这个证字讲的这个证字里面往上面看这个女孩子告诉他']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_7.wav\n",
      "['那女孩子告诉他说不出来,就这样站在凳子里面对,结果呢?结果呢?就拿东西,想拿什么东西发现什么事情的话呢,空人把什么东西拿了拿了拿了,拿给一个女孩子这个是属于一个窗户']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_8.wav\n",
      "['这个是水,一个窗户这个是什么地方呢这个是家里面家里的哪里家里的这个是盘子,全部加盘子这个是什么,我说不出来这个是什么,我都说不出来这个是树,这个是叫什么东西,我都说不出来']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/058_9.wav\n",
      "['這是熱帶地方的植物']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/059_1.wav\n",
      "['嗯...狗、貓、雞、鴨、鵝還有...這個...怎麼講動物是很多的嗯...雞、鴨、魚、水、雞、鴨、魚、雞子啊雞子啊蓮霧啊水果是很多的有時候想不起來而已龍眼荔枝']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/059_10.wav\n",
      "['拍像的三角架這個掃把這個方式什麼對對對 豎琴這個是推椅我記得好像都是講推椅因為也可以當推東西的也可以做的這個比如說一般都是這個人做的推這個年紀大的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/059_11.wav\n",
      "['一般都是人做的,年紀大的這個是花架,這是一種潛水類的海馬,這是一個吃的材料,蘑菇,這是鮑魚']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/059_12.wav\n",
      "['蘑菇這個是花園的圓棍']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/059_2.wav\n",
      "['原物啊,水果是很多的,有時候想不起來而已。農園,荔枝,這個都是啦。還有一些,這個乳菜,這個乳菜有時候是會出去買買。顏色,紅黃藍錠,黑的,咖啡色的,這個都很漂亮。']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/059_3.wav\n",
      "['黑的這個咖啡色的這個都很漂亮還有這個木瓜色的縣市鄉鎮都可以台北再下去就是宜蘭高雄台南台東']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/059_4.wav\n",
      "['這個']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/059_5.wav\n",
      "['還是兄妹啦在整理他們的櫃子有那個椅子拿去當那個墊子然後在那個壁櫥裡面拿東西下來拿這個什麼酒是不是還有吃的東西還有那個媽媽在廚房裡面的那個廚房那邊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/059_6.wav\n",
      "['還有那個媽媽在廚房裡面的那個廚房那邊水滿出來了還有那個哥哥哥哥在整理那個櫃子那個椅子也倒下來了這個窗簾還有那個盤子都這樣他在幫忙他哥哥在整理這個櫃子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/059_7.wav\n",
      "['嗯,都這樣齁']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/059_8.wav\n",
      "['好 水槽就寫滿出來了這個 這個是應該是榕樹吧蝸牛鉛筆這個是仙人掌 剪刀 冰桶 駱駝這個羽毛子彈丸的模具喔對 對 對這個它是羽毛標這個木具口琴衣架這個也是鉗子夾著好 把它夾起來算盤']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/059_9.wav\n",
      "['衣架,這個也是前面夾著算盤,這個手工紙網拍這個是這個叫,一個名字忘記了這個電梯拍相的那個架子三角架這個道板']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_1.wav\n",
      "['狗、猫、鞋、鹿狗有了吼?有!鹿就是很考验它是吧?都可以讲!']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_10.wav\n",
      "['一對兄妹哥哥跑上去拿東西給妹妹吃這邊他媽媽在洗廚具他好像在廚房上面有東西他哥哥拿下來給他妹妹吃這邊他媽媽在擦這個器具擦什麼?這個沒有什麼了他在把廚房門打開拿東西給他妹妹吃']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_11.wav\n",
      "['這個沒有什麼啦他在把廚房門打開拿東西給他妹妹吃他媽媽在洗廚具啊這個樹啊 蝸牛啊這個壁啊這個好像是一個智物叫什麼我都說不出來叫一個智物對仙草 這是什麼我告訴你這個呢剪刀這個聽具']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_12.wav\n",
      "['那些是什麼我告訴你剪刀聽劇放在耳朵裡面來量那個在量的時候叫我學著聽我不懂我還要玩那個聽劇聽劇在聽新部的那個駱駝這個就是打針的那個這不是打針這個是玩具']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_13.wav\n",
      "['這是玩具']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_14.wav\n",
      "['我这个在这一堆这是什么花什么牛啊这叫什么牛它有个猫对有个什么牛我搞忘记了忘记是牛牛牛类搞一搞牛这对对对我们都不信什么那这个呢这好像这就讲很简单啊这说不出来有四言句啊']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_15.wav\n",
      "['这说不出是有用句,是用句的,露头露头,用夹的,那个那个,搞不清楚这个是女生知道,男生夹东西要,女生也不知道夹东西用的,那个那个,然后这个呢,这个呢,这个好像是一个听,像风琴外边的那个,这个是风琴的那个那个那个,内置啊,这个没学过,手琴,这个是什么']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_16.wav\n",
      "['我没打过这个东西这个东西这个东西好像是画图用的我没用过']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_17.wav\n",
      "['結合電梯啊那個東西結合做三腳架結合掃這個電梯掃把這樣掃就是風情味的就是整部東西女樂器子啊我都跟風情一樣起來它不是風情不曉得我們聽覺得很容易啊結合幹什麼呢這還不懂結合用來種東西沒看過也沒用過我們火花這個沒有沒有沒有結合還是動物類一個對這個很素']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_18.wav\n",
      "['我沒看過,也沒用過火花這個沒有沒有沒有這個好像是動物類一個對這個很素質,你最說不出來我們叫它海鳥叫什麼?菇啊,就是好像等於這個房子啊,就說不出來所以房子,我房子講的就是在裡面住家的對對對怎麼名稱我倒是沒有,我不懂這個我好討厭']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_19.wav\n",
      "['外行這個原什麼是化頭院的搞不清楚,我不是搞這個玩意']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_2.wav\n",
      "['都可以講']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_3.wav\n",
      "['有']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_4.wav\n",
      "['水分很多']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_5.wav\n",
      "['金黃色是吧?蘆葉?對蘋果那個顏色很好那是金黃色的還有這個金黃色的這個有那個什麼水梨那個那個那個哪些好奇的?你要告訴我才行限制啊我對這個還是很陌生這樣子的因為我們都是在台灣']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_6.wav\n",
      "['我對這個人還是很陌生這樣子的因為我們都是在台北很多時候在台北還有基隆台北、基隆、高雄、桃園去的地方經常有去的地方桃園還有什麼...基隆經常有去的地方還有金門、馬祖我們都去了金門、馬祖都去當兵還']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_7.wav\n",
      "['经常有去的地方还有金门、马祖我们都去了金门、马祖都去当兵还得中立也在中立过还有高雄高雄也去过了好 伯伯 这样可以了第一个就是要到上面拿去的东西要去把厨房的这个人的厨房上面那个']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_8.wav\n",
      "['把厨房里面的厨具打开把东西拿下来给他清洗']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/061_9.wav\n",
      "['对,还有什么?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/063_1.wav\n",
      "['一个女孩子在擦盘子怎么是镜子啊 擦镜子啊怎么有个人头然后这个小孩子在上面拿吸点这个凳子好像是要倒了她的妹妹叫她小心啊 小心啊 倒了这个女孩子擦盘子然后一个小男孩爬上去拿蛋糕这个凳子结果倒下来了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/063_2.wav\n",
      "['一个小男孩爬上去拿蛋糕这个凳子结果倒下来了厨房镜子 窗户 窗户柜子自来水流出来了太满足了这男孩的凳子就倒了这个小女孩就说 啊小心哦树蜗牛鼻 铅笔这就是什么树啊这个热带的那个什么东西心脏 剪刀 听枕听筒 骆驼']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/063_3.wav\n",
      "['这个日代的那个什么东西']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/063_4.wav\n",
      "['圆规这个叫车啊这个叫圆规啊这个叫车两车这是电梯照相的架子照相架子这三角架照本哈普哈普他叫哈普吗这个叫什么琴啊这个叫哈普琴英文叫哈普这个是那个退衣退衣啊叫做二轮椅花棚这是花棚']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/063_5.wav\n",
      "['這個是那個退衣 退衣啊 機制的二輪椅花棚 這是不是花棚啊牆 花架這個叫什麼啊這個叫什麼啊 犀牛是不是這個叫什麼啊這個叫什麼啊這個叫什麼啊我不知道 不知道啊花 三角這個叫什麼啊這個叫什麼啊圓規']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/063_6.wav\n",
      "['會助人的啦叫什麼 我不知道就知道了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/063_7.wav\n",
      "['差不多了西瓜講過了差不多了講錯了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/063_8.wav\n",
      "['军町市石牌没有啦台北台北还有哪里啊苏里台中后里嘉峪台南左林高雄凤山屏东莫拉比']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_1.wav\n",
      "['所有那些动物我喜欢的动物都可以动物啊我喜欢兔子我喜欢那个那个兔子所有的都可以讲喜欢猫又喜欢羊还喜欢牛猪啊马牛羊马猪狗']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_10.wav\n",
      "['这个是女的 女孩子这个是男的孩子他们两个在帮忙妈妈的忙你讲道理的东西这个就是他妈妈在他妈妈在那里忙他妈妈做那个有些东西嘛在洗呀那些嘛那个盘子啊那些那个就是你是洗的东西嘛所以他要做饭']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_11.wav\n",
      "['所以他要做饭他要擦牙一下他先洗干净嘛洗干净了他还没擦完他就拿着教孩子装在那个盒子里面装着等到死的时候他再来找没有嘛他这个那个他是他一头的死是他上面是装了一点东西嘛']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_12.wav\n",
      "['这个是芝麻']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_13.wav\n",
      "['这个叫什么 蜗牛这是千笛然后这个这个是那个芭蕉树是树啊 树子啊叫什么 仙人掌啊 剪刀这个叫一身霆铜这个骆驼这个是 好像是那个什么那个什么针吗好像是个椰子啊不晓得 我没有换这个叫橘子这个也不晓得叫什么这是鱿鱼 口琴这个叫衣角']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_14.wav\n",
      "['这个叫橘子这个也不晓得叫什么这是油芹口芹这个叫衣夹这个叫那个那是装东西的一个那个不是它好像在厨房里面那个盖这个叫什么我不知道这个是花吗对这个是西柳这个是那个叫什么什么我都讲不来厨房里那个漏斗这个橘子好像是橘子吗嗯橘就是那个这是什么我不晓得我们都叫夹']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_15.wav\n",
      "['这个橘子好像是橘子嘛,就是那个,这是什么我不晓得,什么夹子,哦夹子那个,对,这个是钻盘,这个是手提,它叫钢琴啊,叫什么,不是钢,是不晓得牌子,打球的牌子,这个是那个叫什么词子,就是那个两词啊,就是我们写我们画那个,叫什么我都讲不来,叫什么东西,对,是啊我记不到了,']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_16.wav\n",
      "['我们写我们画的叫什么我都讲不来叫什么东西了是啊我记不到了这个不是楼梯吗这个是那个画图的那个架子那个叫什么架子三个画的照相机就是那个照相机的架子嘛我记不了我没用过走吧这个叫那个那个银鹅啊那个什么琴啊书琴啊这个是做的车子嘛那个那是别人做的那个']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_17.wav\n",
      "['这个是做的车子嘛那个是别人做的轮椅这个是在画的那个是夹子嘛叫画夹这个是那个一个虫叫什么叫什么鬼啊叫什么这个是那个菌这个是那个叫什么人呢做的那个我都讲不出来不知道这个是个夹子']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_18.wav\n",
      "['这个是那个叫什么人呢?我都讲不出来,不知道这个是个夹子,那个两个东西,那个划划那个东西的夹子,鸳鸯,鸳鸯盔,鸳鸯夹子,不是吧?鸳什么鸯,不知道']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_2.wav\n",
      "['猪啊马有羊马猪马有羊马猪狗猪猫就是这些我喜欢这一块有羊猪狗想想看葡萄苹果这个葡萄苹果荔枝甘蔗葡萄苹果荔枝甘蔗我就是喜欢荔枝羊的其他的其他的水果苹果我告诉你了吗有']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_3.wav\n",
      "['苹果 栗子 甘莓我就是喜欢栗子其他的水果苹果我告诉你了吗有苹果那个苹果好多颜色红 黄 蓝 绿最喜欢的就是红 黄 蓝其他的不喜欢黑色最喜欢就是红 黄 绿不喜欢的就是黑颜色']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_4.wav\n",
      "['最喜欢就是红黄不给我我不喜欢不喜欢的就是黑颜色还有呢青色我也不喜欢就是这两样没有大的颜色黑色我最不喜欢没有了没有了我最喜欢的就是红黄绿黑色我不喜欢黑色最不喜欢纯色纯色象征了头发颜色象征了太白都想不出来']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_5.wav\n",
      "['我最不喜欢的城市乡镇啊都想不出来现在教一下乡想不出来教一下乡想不出来这个他们是在家里做那个西餐那些放在上面放在上面他们在那做放在那西餐']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_6.wav\n",
      "['他们在那里做西餐坐在那个口袋的柜子里面那个药他要他给他拿下来这个是在做这个也是在做这个在厨房里面做这个是在高丽街把那个材料']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_7.wav\n",
      "['在厨房里面做这个是在高丽街把材料拿下来她接到她在那里做做好了那个 装进去你有个盒子嘛 她坐下她装在上面这个在厨房里面做嘛在厨房里面做这是厨房的那个台子里面是睡台子 洗了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_8.wav\n",
      "['这是厨房的那个台子里面是睡台子,洗了东西洗好了,一个盘子洗好了,它装在里面装在,你送到过去,装在里面没看到,这个是那个吸材的这个台子嘛这个是盘子啊,这个是那个就是它要走的东西嘛,过到里面这个你看嘛,它去吸这个']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/064_9.wav\n",
      "['这个是那个就是他要做的东西嘛这个你看嘛他去这个盘子里装那个嘛这个松果机嘛松果机装在那个鼻涂里面嘛这个这个有这个是这个是祝福啊他在做这是那个是个妹妹是他的小姐这个是女的这个是男的孩子他们两个在帮忙']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/065_1.wav\n",
      "['還有什麼?']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/065_2.wav\n",
      "['甜瓜还有什么不想想看想不起来我刚才已经讲了很多想不起来还有什么想不起来红黄蓝绿白红白还有棕色的想不起来想想看还有黑色的还有什么颜色哎呦基隆台北桃园台中嘉义台南还有战华高雄屏东']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/065_3.wav\n",
      "['桃園、台中、嘉義、台南、彰化、高雄、屏東還有哪裡?唉呦,我都說不上來了想想看嗎?橫春、花蓮對還有還有還有想不起哪裡再來拿東西在這個水箭留下來拿餅給他']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/065_4.wav\n",
      "['這個']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/065_5.wav\n",
      "['方圓這個好像是一個什麼箱拿事情她在拿東西這個是在做什麼我想不起來你說這個是做什麼沒有了可以這個是什麼這個叫什麼昆蟲昆蟲對就這樣這個呢這個我知道鉛筆對這個好像是一個樹剪刀這個我知道剪刀這個是什麼放在耳朵裡對住聽心我們一不認識']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/065_6.wav\n",
      "['這個我知道,是個剪刀這個是什麼?放在耳朵裡對對不聽信我們不認識它,一種玩具叫什麼?我們一般...鋸齒?是我,我不知道這個就是要什麼東西啊?這個是掛東西的對,它叫什麼名字?這是什麼?我不知道,建築物?哎呦,這是建築物這好像是什麼?這批牛啊,這個是叫喇叭?漏勺?我不知道']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/065_7.wav\n",
      "['这好像是什么啊这个是叫喇叭漏哨我不知道这个是什么 插灯器 夹子对 那这个呢这个是什么 这是做什么用的 散发我不知道这个叫什么我都叫不出来了 怎么拍的 楼梯啊那这个呢 好像是扫把这个是什么我也不知道这个是做什么用的 我不知道']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/065_8.wav\n",
      "['这好像是扫把呀这个是什么我也不晓得这个呢这个是做什么用的这个呢这个我知道这个是轮椅那这个呢这好像是个窗帘呀这种东西也不晓得这是个什么动物啊叫海虫白马这好像像香菇呀对有这么多东西这个是它好像可以从里边走进去的']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/065_9.wav\n",
      "['對 還有這麼多東西人可以從裡面走進去']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/066_1.wav\n",
      "['还有什么']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/066_2.wav\n",
      "['是神教自从小一年香蕉橘子 苹果 凤梨 洋茶这经常吃的不常吃的就忘记了']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/066_3.wav\n",
      "['绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 绿色 ']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/066_4.wav\n",
      "['台北市新竹市台中市嘉義市彰化市這個彰化市嘉義市不算這個那是縣然後呢縣的市是另外一個下第一層的高雄縣高雄市台中縣花蓮縣宜蘭縣吉隆市台南縣嘉義縣嘉義市雲林縣澎湖縣這個地方跑了很多遍了很多遍了金門不算的金門是福建省的嘛福建啦馬祖啦']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/066_5.wav\n",
      "['这个应该是厨房这个地方我们叫它洗碗池这是一个什么树这个是那个蜗牛万国人家的铅笔仙人掌剪刀医生用的清洁器骆驼把尺可以表演']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/066_6.wav\n",
      "['对']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/066_7.wav\n",
      "['嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯']\n",
      "filepath:  data_process/Lu_CTTdeletion_o_d/066_8.wav\n",
      "['这叫什么椅子啊什么的这是什么呀这有花棚啊花架子这叫鳄鱼啊这叫鳄鱼啊没见过人天天都把我忘了叫什么东西看过了耳归啊这个什么的那个什么的什么的叫什么呢超市的地方这个下雨以后长出来的东西叫什么啊对香菊叶菊叶会叫菊']\n"
     ]
    }
   ],
   "source": [
    "# decode about 30 sec\n",
    "import torch\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, WhisperModel\n",
    "import soundfile as sf\n",
    "\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# from datasets import Audio, load_dataset\n",
    "\n",
    "# load model and processor\n",
    "device = torch.device('cuda:0')\n",
    "model_checkpoint = \"openai/whisper-large-v2\"  # distil-whisper/distil-large-v2\n",
    "processor = WhisperProcessor.from_pretrained(model_checkpoint)\n",
    "# outofCUDA\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_checkpoint).to(device)\n",
    "whisper = WhisperModel.from_pretrained(model_checkpoint).to(device)\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"zh\", task=\"transcribe\")\n",
    "model.config.output_attentions = True\n",
    "model.config.output_hidden_states = True\n",
    "\n",
    "# load streaming dataset and read first audio sample\n",
    "# common_voice_test_transcription = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"zh-TW\", split=\"test\")\n",
    "# ds = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"zh-TW\", split=\"test\", streaming=True)\n",
    "# ds = ds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "# input_speech = next(iter(ds))[\"audio\"]\n",
    "\n",
    "path = \"data_process/CTTsegment_diarization_overlap\"\n",
    "transcriptionlist = pd.DataFrame()\n",
    "for f in os.listdir(path):\n",
    "    filepath = path + '/' + f\n",
    "    if os.path.isfile(filepath) and f.find(\"wav\") != -1:\n",
    "        print(\"filepath: \", filepath)\n",
    "        wav, sr = sf.read(filepath)\n",
    "        temp = \"data_process/CTTsegment_diarization_overlap/temp.wav\"\n",
    "        sf.write(temp, wav, 16000)\n",
    "        wav, sr = sf.read(temp)\n",
    "\n",
    "        # import librosa    \n",
    "        # wav, sr = librosa.load(filepath, sr=16000) # Downsample 44.1kHz to 8kHz\n",
    "        # print(sr)\n",
    "        # outofCUDA\n",
    "        input_features = processor(wav, sampling_rate=sr, return_tensors=\"pt\").input_features.to(device)\n",
    "        \n",
    "        # generate token ids # outofCUDA\n",
    "        predicted_ids = model.generate(input_features).to(device)\n",
    "        # print(type(predicted_ids))\n",
    "        # decode token ids to text\n",
    "        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "        print(transcription)\n",
    "                \n",
    "        # input_features = input_features.to(device)\n",
    "        # predicted_ids = predicted_ids.to(device)\n",
    "\n",
    "        # outputs = whisper(input_features, decoder_input_ids=predicted_ids, output_attentions=True, output_hidden_states=True)\n",
    "        # print(\"hidden state size: \", len(outputs.last_hidden_state), outputs.last_hidden_state.shape)\n",
    "        # # print(\"hidden state: \", outputs.last_hidden_state)\n",
    "        # print(\"attention size: \", len(outputs.cross_attentions), outputs.cross_attentions[0].shape)\n",
    "        # print(\"mel spectrogram: \", input_features.shape)\n",
    "        # print(\"len: \", len(transcription[0]))\n",
    "\n",
    "        # mel_spectrum = input_features.cpu().detach().numpy()\n",
    "        # cross_attention_weights = outputs.cross_attentions[0].squeeze(0).cpu().detach().numpy()\n",
    "\n",
    "        # # from sklearn.preprocessing import MinMaxScaler\n",
    "        # # scaler = MinMaxScaler()\n",
    "        # # cross_attention_weights = scaler.fit_transform(cross_attention_weights.mean(axis=0))\n",
    "        \n",
    "        # cross_attention_weights = cross_attention_weights.mean(axis=0)\n",
    "\n",
    "        # # heat map / attention map\n",
    "        # plt.figure(figsize=(10, 6))\n",
    "        # sns.heatmap(cross_attention_weights, cmap='viridis', annot=True, fmt=\".2f\", xticklabels=False, yticklabels=False, linewidths = 0.05)\n",
    "        # plt.xlabel('Key Sequence')\n",
    "        # plt.ylabel('Query Sequence')\n",
    "        # plt.title('Cross Attention Weights Visualization')\n",
    "        # # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "        temp = pd.DataFrame({\"audio\": f, \"transcription\": transcription})\n",
    "        # temp = pd.DataFrame({\"audio\": f, \"predicted_ids\": predicted_ids})\n",
    "        transcriptionlist = pd.concat([transcriptionlist, temp])\n",
    "        # f_withoutwav = f.replace(\".wav\", \"\")\n",
    "        # torch.save(predicted_ids, f'data_process/CTTsegment_30/predicted_ids/{f_withoutwav}.pt')\n",
    "        \n",
    "transcriptionlist.to_csv(\"data_process/CTTsegment_diarization_overlap/transcription-v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450f9635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoFeatureExtractor, WhisperForAudioClassification\n",
    "import os\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from datasets import load_dataset\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"sanchit-gandhi/whisper-large-v3\")\n",
    "model = WhisperForAudioClassification.from_pretrained(\"sanchit-gandhi/whisper-large-v3\").to('cuda')\n",
    "\n",
    "path = \"data_process/CTTsegment\"\n",
    "transcriptionlist = pd.DataFrame()\n",
    "for f in os.listdir(path):\n",
    "    filepath = path + '/' + f\n",
    "    if os.path.isfile(filepath) and f.find(\"wav\") != -1:\n",
    "        print(\"filepath: \", filepath)\n",
    "        wav, sr = sf.read(filepath)\n",
    "        input_features = feature_extractor(wav, sampling_rate=sr, return_tensors=\"pt\").input_features.to('cuda')\n",
    "\n",
    "        # generate token ids\n",
    "        outputs = model(input_features, output_attentions=True, output_hidden_states=True)\n",
    "        print(\"hidden state size: \", len(outputs.hidden_states), outputs.hidden_states[0].shape)\n",
    "        print(\"hidden state: \", outputs.hidden_states[-1])\n",
    "        print(\"attention size: \", len(outputs.attentions), outputs.attentions[0].shape)\n",
    "        print(\"predict_label: \", model.config.id2label[torch.argmax(outputs.logits).item()])\n",
    "        print(\"loss: \", outputs.loss)\n",
    "        print(\"mel spectrogram: \", input_features.shape)\n",
    "\n",
    "        mel_spectrum = input_features.cpu().detach().numpy()\n",
    "        attention_weight = outputs.attentions[0]\n",
    "\n",
    "        mel_spect = librosa.feature.melspectrogram(y=wav, sr=16000, n_fft=400, hop_length=160, n_mels=128)\n",
    "        print(mel_spect.shape)\n",
    "\n",
    "        # mel = np.exp(mel_spectrum[0])\n",
    "        mel_db = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.specshow(mel_db, x_axis='s', y_axis='mel', sr=sr, hop_length=160, n_fft=400, cmap='viridis')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # from torch import nn\n",
    "        # conv1 = nn.ConvTranspose2d(in_channels=20, out_channels=20, kernel_size=2, stride=2, padding=0).cuda()\n",
    "        # outputs = conv1(attention_weight).squeeze(0).cpu().detach().numpy()\n",
    "        import torch.nn.functional as F\n",
    "        upsampled_output = F.interpolate(attention_weight, size=(3000, 3000), mode='bilinear', align_corners=False).squeeze(0).cpu().detach().numpy()\n",
    "\n",
    "        from validation_visualize import visualize_head, visualize_heads, visualize_head_average, visualize_heads_average, visualize_heads_resized\n",
    "        # target_shape = mel_spectrum[0].shape\n",
    "        # print(\"target_shape: \", target_shape)\n",
    "        # visualize_heads_resized(attention_weight, cols=4, target_shape=target_shape)\n",
    "        visualize_heads(upsampled_output, cols=4)\n",
    "\n",
    "        # 將 self-attention map 的尺寸調整為與 mel spectrogram 相同的大小\n",
    "        # target_shape = mel_spectrum[0].shape\n",
    "        # attention_resized = np.resize(attention_weight.mean(axis=0), target_shape)\n",
    "\n",
    "        # # 將 self-attention map 和 mel spectrogram 疊加在一起（這裡使用加權平均）\n",
    "        # alpha = 0.5  # 加權平均的權重\n",
    "        # overlay = alpha * attention_resized + (1 - alpha) * mel_spectrum[0]\n",
    "\n",
    "        # 繪製疊加後的圖像\n",
    "        plt.imshow(upsampled_output.mean(axis=0), cmap='viridis', aspect='auto', origin='lower')\n",
    "        plt.title('Whisper Encoder Self-Attention Map Overlay')\n",
    "        plt.colorbar()  \n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Mel Spectrogram Frequency')\n",
    "        plt.show()\n",
    "        \n",
    "        # # Mel Spectrogram\n",
    "        # plt.subplots(figsize=(10, 6))\n",
    "        # librosa.display.specshow(mel_db, y_axis='mel', sr=16000, hop_length=160, n_fft=400, cmap='viridis')\n",
    "        # plt.colorbar(format='%+2.0f dB', label='Intensity')\n",
    "\n",
    "        # # Cross-Attention Weights\n",
    "        # plt.imshow(attention_resized, cmap='viridis', aspect='auto', origin='lower', alpha=0.1)\n",
    "        # plt.title('Whisper Encoder Self-Attention Map Overlay')\n",
    "        # plt.xlabel('Time')\n",
    "        # plt.ylabel('Mel Spectrogram Frequency')\n",
    "        # plt.colorbar()  \n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2acf87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "# # os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "\n",
    "# torch.cuda.set_device(0)\n",
    "# print(torch.cuda.current_device())\n",
    "#! python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Author: kun\n",
    "# @Time: 2019-10-29 20:29\n",
    "\n",
    "import yaml\n",
    "# import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "class Para(object):\n",
    "    a=1\n",
    "\n",
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda:0')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
    "    \n",
    "#force_cudnn_initialization()\n",
    "def main():\n",
    "    # For reproducibility, comment these may speed up training\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Arguments\n",
    "#     parser = argparse.ArgumentParser(description='Training E2E asr.')\n",
    "#     parser.add_argument('--config', type=str, help='Path to experiment config.')\n",
    "#     parser.add_argument('--name', default=None, type=str, help='Name for logging.')\n",
    "#     parser.add_argument('--logdir', default='log/', type=str,\n",
    "#                         help='Logging path.', required=False)\n",
    "#     parser.add_argument('--ckpdir', default='ckpt/', type=str,\n",
    "#                         help='Checkpoint path.', required=False)\n",
    "#     parser.add_argument('--outdir', default='result/', type=str,\n",
    "#                         help='Decode output path.', required=False)\n",
    "#     parser.add_argument('--load', default=None, type=str,\n",
    "#                         help='Load pre-trained model (for training only)', required=False)\n",
    "#     parser.add_argument('--seed', default=0, type=int,\n",
    "#                         help='Random seed for reproducable results.', required=False)\n",
    "#     parser.add_argument('--cudnn-ctc', action='store_true',\n",
    "#                         help='Switches CTC backend from torch to cudnn')\n",
    "#     parser.add_argument('--njobs', default=32, type=int,\n",
    "#                         help='Number of threads for dataloader/decoding.', required=False)\n",
    "#     parser.add_argument('--cpu', action='store_true', help='Disable GPU training.')\n",
    "#     parser.add_argument('--no-pin', action='store_true',\n",
    "#                         help='Disable pin-memory for dataloader')\n",
    "#     parser.add_argument('--test', action='store_true', help='Test the model.')\n",
    "#     parser.add_argument('--no-msg', action='store_true', help='Hide all messages.')\n",
    "#     parser.add_argument('--lm', action='store_true',\n",
    "#                         help='Option for training RNNLM.')\n",
    "#     # Following features in development.\n",
    "#     parser.add_argument('--amp', action='store_true', help='Option to enable AMP.')\n",
    "#     parser.add_argument('--reserve-gpu', default=0, type=float,\n",
    "#                         help='Option to reserve GPU ram for training.')\n",
    "#     parser.add_argument('--jit', action='store_true',\n",
    "#                         help='Option for enabling jit in pytorch. (feature in development)')\n",
    "#     ###\n",
    "#     paras = parser.parse_args()\n",
    "    paras = Para()\n",
    "#     paras.config = './config/aishell_asr_example_lstm4atthead1-test.yaml'\n",
    "#     paras.name = None\n",
    "#     paras.logdir = 'log/'\n",
    "#     paras.ckpdir = 'ckpt/'\n",
    "#     paras.outdir = 'result/'\n",
    "#     paras.load = None\n",
    "#     paras.seed = 0\n",
    "#     paras.cudnn_ctc = False\n",
    "#     paras.cpu = False\n",
    "#     paras.no_pin = False\n",
    "#     paras.test = True\n",
    "#     paras.no_msg = False\n",
    "#     paras.lm = False\n",
    "#     paras.amp = False\n",
    "#     paras.reserve_gpu = 0\n",
    "#     paras.jit = False\n",
    "    setattr(paras, 'config', './config/cv11Lu_asr_lstm4atthead_allvocab-whisperclass.yaml')\n",
    "    setattr(paras, 'name', None)\n",
    "    setattr(paras, 'logdir', 'log/')\n",
    "    setattr(paras, 'ckpdir', 'LAS_ckpt/')\n",
    "    setattr(paras, 'outdir', 'result/')\n",
    "    setattr(paras, 'load', None)\n",
    "    setattr(paras, 'seed', 0)\n",
    "    setattr(paras, 'cudnn_ctc', False)\n",
    "    setattr(paras, 'njobs',0)\n",
    "    setattr(paras, 'cpu', False)\n",
    "    setattr(paras, 'no_pin', False)\n",
    "    setattr(paras, 'test', False)\n",
    "    setattr(paras, 'no_msg', False)\n",
    "    setattr(paras, 'lm', False)\n",
    "    setattr(paras, 'amp', False)\n",
    "    setattr(paras, 'reserve_gpu', 9)\n",
    "    setattr(paras, 'jit', False)\n",
    "    setattr(paras, 'gpu', not paras.cpu)\n",
    "    setattr(paras, 'pin_memory', not paras.no_pin)\n",
    "    setattr(paras, 'verbose', not paras.no_msg)\n",
    "    setattr(paras, 'finetune', False)\n",
    "    setattr(paras, 'binaryClass', True)\n",
    "#     force_cudnn_initialization()\n",
    "    print(torch.multiprocessing.get_start_method())\n",
    "#     torch.multiprocessing.set_start_method('spawn',force=True)\n",
    "    config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "    np.random.seed(paras.seed)\n",
    "    torch.manual_seed(paras.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(paras.seed)\n",
    "\n",
    "    # Hack to preserve GPU ram just incase OOM later on server\n",
    "    if paras.gpu and paras.reserve_gpu > 0:\n",
    "        buff = torch.randn(int(paras.reserve_gpu * 1e9 // 4)).cuda()\n",
    "        del buff\n",
    "\n",
    "    if paras.lm:\n",
    "        # Train RNNLM\n",
    "        from train_lm import Solver\n",
    "\n",
    "        mode = 'train'\n",
    "    else:\n",
    "        if paras.test:\n",
    "            # Test ASR\n",
    "            assert paras.load is None, 'Load option is mutually exclusive to --test'\n",
    "            from test_asr import Solver\n",
    "\n",
    "            mode = 'test'\n",
    "        elif paras.finetune:\n",
    "            assert paras.load is not None\n",
    "            from finetune_asr import Solver\n",
    "            mode = 'train'\n",
    "        elif paras.binaryClass:\n",
    "            # from train_whisperclass import Solver\n",
    "            from Whisper_Biclass_train import Solver\n",
    "            mode = 'train'\n",
    "        else:\n",
    "            # Train ASR\n",
    "            from train_asr import Solver\n",
    "\n",
    "            mode = 'train'\n",
    "\n",
    "    print(\"\\nUsing {} mode\\n\".format(mode))\n",
    "\n",
    "    for idx in range(0,5):\n",
    "        paras.config = f'./config/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-{idx+1}.yaml'#latest7k_4lstm.pth\n",
    "        paras.config = f'./config/cv11Lu_asr_lstm4atthead_allvocab-biclass-test-5-{idx+1}.yaml'#latest7k_4lstm.pth\n",
    "        \n",
    "        setattr(paras, 'load', f'LAS_ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-{idx+1}_sd0/whisper-v2-15k-r-a-final.pth') # whisper15k_with_id.pth\n",
    "        #要用vag01要改load_ckpt\n",
    "        config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "        solver = Solver(config, paras, mode)\n",
    "\n",
    "\n",
    "        solver.load_data()\n",
    "#         solver.print_model()\n",
    "        solver.set_model()\n",
    "        # solver.exec()\n",
    "        # solver.validate(idx)\n",
    "        solver.visualization()\n",
    "        del solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a571e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spawn\n",
      "\n",
      "Using train mode\n",
      "\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass-test-5-1_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: data_process, split: ['CTTsegment_diarization_overlap']\n",
      "Mozillacv11Dataset CTTsegment_diarization_overlap found wav data: 166\n",
      "text len: 166\n",
      "remove None, then wav data: 165, text len: 165\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "[INFO] Load ckpt from LAS_ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-1_sd0/whisper-v2-15k-r-a-final.pth, restarting at step 15001 \n",
      "fc.weight\n",
      "fc.bias\n",
      "output 0K] Valid step - 1/17tensor([0.6694], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Lulu\\Research\\0709\\LAS_Mandarin_PyTorch-master\\Whisper_Biclass_train.py:612: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\captum\\attr\\_utils\\visualization.py:338: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\captum\\_utils\\gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "d:\\Lulu\\Research\\0709\\LAS_Mandarin_PyTorch-master\\Whisper_Biclass_train.py:671: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "d:\\Lulu\\Research\\0709\\LAS_Mandarin_PyTorch-master\\Whisper_Biclass_train.py:707: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "d:\\Lulu\\Research\\0709\\LAS_Mandarin_PyTorch-master\\validation_visualize.py:24: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\captum\\_utils\\gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "d:\\Lulu\\Research\\0709\\LAS_Mandarin_PyTorch-master\\Whisper_Biclass_train.py:761: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output 0K] Valid step - 2/17tensor([0.6563], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Lulu\\Research\\0709\\LAS_Mandarin_PyTorch-master\\Whisper_Biclass_train.py:612: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\captum\\attr\\_utils\\visualization.py:338: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "d:\\Lulu\\Research\\0709\\LAS_Mandarin_PyTorch-master\\Whisper_Biclass_train.py:671: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output tensor([0.9293], device='cuda:0')\n",
      "output tensor([0.7947], device='cuda:0')\n",
      "output tensor([0.2388], device='cuda:0')\n",
      "output tensor([0.4073], device='cuda:0')\n",
      "output tensor([0.6801], device='cuda:0')\n",
      "output tensor([0.1474], device='cuda:0')\n",
      "output tensor([0.7532], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aedf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
