{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "governing-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "boolean-macedonia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "endangered-terrace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "direct-battlefield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "possible-integration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "outstanding-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudaSetDevice(0)\n",
    "#dataset transcript要在dataset資好夾調\n",
    "#cuda 在basesolver init調\n",
    "#dataset要在data.py設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "major-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "# # os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "\n",
    "# torch.cuda.set_device(0)\n",
    "# print(torch.cuda.current_device())\n",
    "\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "class Para(object):\n",
    "    a=1\n",
    "\n",
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda:0')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
    "    \n",
    "#force_cudnn_initialization()\n",
    "def main():\n",
    "    # For reproducibility, comment these may speed up training\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Arguments\n",
    "#     parser = argparse.ArgumentParser(description='Training E2E asr.')\n",
    "#     parser.add_argument('--config', type=str, help='Path to experiment config.')\n",
    "#     parser.add_argument('--name', default=None, type=str, help='Name for logging.')\n",
    "#     parser.add_argument('--logdir', default='log/', type=str,\n",
    "#                         help='Logging path.', required=False)\n",
    "#     parser.add_argument('--ckpdir', default='ckpt/', type=str,\n",
    "#                         help='Checkpoint path.', required=False)\n",
    "#     parser.add_argument('--outdir', default='result/', type=str,\n",
    "#                         help='Decode output path.', required=False)\n",
    "#     parser.add_argument('--load', default=None, type=str,\n",
    "#                         help='Load pre-trained model (for training only)', required=False)\n",
    "#     parser.add_argument('--seed', default=0, type=int,\n",
    "#                         help='Random seed for reproducable results.', required=False)\n",
    "#     parser.add_argument('--cudnn-ctc', action='store_true',\n",
    "#                         help='Switches CTC backend from torch to cudnn')\n",
    "#     parser.add_argument('--njobs', default=32, type=int,\n",
    "#                         help='Number of threads for dataloader/decoding.', required=False)\n",
    "#     parser.add_argument('--cpu', action='store_true', help='Disable GPU training.')\n",
    "#     parser.add_argument('--no-pin', action='store_true',\n",
    "#                         help='Disable pin-memory for dataloader')\n",
    "#     parser.add_argument('--test', action='store_true', help='Test the model.')\n",
    "#     parser.add_argument('--no-msg', action='store_true', help='Hide all messages.')\n",
    "#     parser.add_argument('--lm', action='store_true',\n",
    "#                         help='Option for training RNNLM.')\n",
    "#     # Following features in development.\n",
    "#     parser.add_argument('--amp', action='store_true', help='Option to enable AMP.')\n",
    "#     parser.add_argument('--reserve-gpu', default=0, type=float,\n",
    "#                         help='Option to reserve GPU ram for training.')\n",
    "#     parser.add_argument('--jit', action='store_true',\n",
    "#                         help='Option for enabling jit in pytorch. (feature in development)')\n",
    "#     ###\n",
    "#     paras = parser.parse_args()\n",
    "    paras = Para()\n",
    "#     paras.config = './config/aishell_asr_example_lstm4atthead1-test.yaml'\n",
    "#     paras.name = None\n",
    "#     paras.logdir = 'log/'\n",
    "#     paras.ckpdir = 'ckpt/'\n",
    "#     paras.outdir = 'result/'\n",
    "#     paras.load = None\n",
    "#     paras.seed = 0\n",
    "#     paras.cudnn_ctc = False\n",
    "#     paras.cpu = False\n",
    "#     paras.no_pin = False\n",
    "#     paras.test = True\n",
    "#     paras.no_msg = False\n",
    "#     paras.lm = False\n",
    "#     paras.amp = False\n",
    "#     paras.reserve_gpu = 0\n",
    "#     paras.jit = False\n",
    "    setattr(paras, 'config', './config/cv11Lu_asr_lstm4atthead_allvocab-whisperclass.yaml')\n",
    "    setattr(paras, 'name', None)\n",
    "    setattr(paras, 'logdir', 'log/')\n",
    "    setattr(paras, 'ckpdir', 'LAS_ckpt/')\n",
    "    setattr(paras, 'outdir', 'result/')\n",
    "    setattr(paras, 'load', None)\n",
    "    setattr(paras, 'seed', 0)\n",
    "    setattr(paras, 'cudnn_ctc', False)\n",
    "    setattr(paras, 'njobs',0)\n",
    "    setattr(paras, 'cpu', False)\n",
    "    setattr(paras, 'no_pin', False)\n",
    "    setattr(paras, 'test', False)\n",
    "    setattr(paras, 'no_msg', False)\n",
    "    setattr(paras, 'lm', False)\n",
    "    setattr(paras, 'amp', False)\n",
    "    setattr(paras, 'reserve_gpu', 9)\n",
    "    setattr(paras, 'jit', False)\n",
    "    setattr(paras, 'gpu', not paras.cpu)\n",
    "    setattr(paras, 'pin_memory', not paras.no_pin)\n",
    "    setattr(paras, 'verbose', not paras.no_msg)\n",
    "    setattr(paras, 'finetune', False)\n",
    "    setattr(paras, 'binaryClass', True)\n",
    "#     force_cudnn_initialization()\n",
    "    print(torch.multiprocessing.get_start_method())\n",
    "#     torch.multiprocessing.set_start_method('spawn',force=True)\n",
    "    config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "    np.random.seed(paras.seed)\n",
    "    torch.manual_seed(paras.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(paras.seed)\n",
    "\n",
    "    # Hack to preserve GPU ram just incase OOM later on server\n",
    "    if paras.gpu and paras.reserve_gpu > 0:\n",
    "        buff = torch.randn(int(paras.reserve_gpu * 1e9 // 4)).cuda()\n",
    "        del buff\n",
    "\n",
    "    if paras.lm:\n",
    "        # Train RNNLM\n",
    "        from train_lm import Solver\n",
    "\n",
    "        mode = 'train'\n",
    "    else:\n",
    "        if paras.test:\n",
    "            # Test ASR\n",
    "            assert paras.load is None, 'Load option is mutually exclusive to --test'\n",
    "            from test_asr import Solver\n",
    "\n",
    "            mode = 'test'\n",
    "        elif paras.finetune:\n",
    "            assert paras.load is not None\n",
    "            from finetune_asr import Solver\n",
    "            mode = 'train'\n",
    "        elif paras.binaryClass:\n",
    "            # assert paras.load is not None\n",
    "            from Whisper_CDRSOB_bert_train import Solver\n",
    "            mode = 'train'\n",
    "        else:\n",
    "            # Train ASR\n",
    "            from train_asr import Solver\n",
    "\n",
    "            mode = 'train'\n",
    "\n",
    "    print(\"\\nUsing {} mode\\n\".format(mode))\n",
    "\n",
    "    for idx in range(0,5):\n",
    "        paras.config = f'config/cv11Lu_asr_lstm4atthead_allvocab-CDRSOB-5fold-{idx+1}.yaml'#latest7k_4lstm.pth\n",
    "#         setattr(paras, 'load', f'./ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-{idx+1}_sd0/latest13knew_4LSTM.pth')\n",
    "        #要用vag01要改load_ckpt\n",
    "        config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "        solver = Solver(config, paras, mode)\n",
    "\n",
    "\n",
    "        solver.load_data()\n",
    "#         solver.print_model()\n",
    "        solver.set_model()\n",
    "        solver.exec()\n",
    "        del solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "consecutive-antique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spawn\n",
      "\n",
      "Using train mode\n",
      "\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-CDRSOB-5fold-1_sd0                                     \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetCDRSOB as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 16, text len: 16\n",
      "[VAGDataset] path: data_process, split: ['CTT5-5-16', 'CTT5-2-16', 'CTT5-3-16', 'CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 69\n",
      "remove None, then wav data: 69, text len: 69\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 69\n",
      "total_loss tensor(182.2125, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(156.6047, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(158.3463, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(154.0915, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(152.8319, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(151.0598, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(146.4622, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(146.8433, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(144.9311, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(137.6314, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(140.7233, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(137.2106, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(135.3413, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(131.5156, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(133.8878, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(132.1120, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(130.0246, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(130.2116, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(127.2219, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(124.7581, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(126.7014, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(123.7013, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(122.2602, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(125.0230, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(122.0658, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(121.6654, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(120.7184, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(119.5625, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(118.6416, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(117.4161, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(114.7075, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(118.9566, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(113.3588, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(114.7228, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(113.3719, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(114.8071, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(112.7640, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(113.3369, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(109.8482, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(111.2825, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(109.3726, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(107.8922, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(110.4670, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(109.0103, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(108.2077, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(106.7875, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(107.4221, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(106.2058, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(106.1756, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(107.4519, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(106.6458, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(104.8684, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(102.9479, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(103.9644, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(104.8005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(102.4676, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(101.2147, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(102.4139, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(102.2169, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(101.2307, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(101.1767, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(101.8006, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(101.1291, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(100.8616, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(101.2727, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(99.8095, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(98.8070, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(100.5816, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(98.3889, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(98.2622, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(98.8206, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(96.4943, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(97.8276, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(97.5691, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(96.2413, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(97.3792, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(95.6380, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(95.4883, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(94.9447, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(95.3966, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(95.0764, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(94.8617, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(94.8973, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(95.0399, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(93.1057, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(92.6406, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(92.5973, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(90.4705, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(92.0868, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(93.0941, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(93.0561, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(91.6295, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(91.7666, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(91.5824, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(90.9947, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(90.6864, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(89.2060, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(88.6514, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(89.8961, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(88.8521, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(87.5371, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(88.7130, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(87.3725, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(87.5870, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(85.6890, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(87.3786, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(86.4744, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(85.2587, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(85.8934, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(85.8803, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(86.1944, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(85.8560, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(85.3770, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(86.3366, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(85.9970, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(84.6690, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(85.1987, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(84.8677, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(85.3973, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(84.8819, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(84.0810, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(85.6149, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(84.3870, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(84.1747, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(84.3545, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(82.2664, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(82.2169, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(83.1374, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(82.9273, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(82.2834, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(82.5911, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(82.5212, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(81.8672, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(81.7944, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(81.6660, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(80.3183, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(80.6422, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(82.0377, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(78.9265, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(78.9017, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(80.9658, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(79.5415, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(79.4696, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(80.2343, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(78.6927, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(79.7614, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(80.1339, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(77.5924, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(78.3192, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(77.5618, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(77.7791, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(77.2408, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(77.5551, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(77.2836, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(77.4105, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(74.8506, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(77.5425, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(74.6363, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(76.6986, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(76.5891, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(76.2231, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(75.7065, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(73.1149, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(75.2170, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(74.6005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(74.4805, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(75.8001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(74.6216, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(73.6769, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(75.2052, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(74.6225, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(74.0410, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(73.5575, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(72.8588, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(73.4354, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(72.2485, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(73.8638, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(73.2648, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(73.1297, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(72.1595, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(72.0466, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(73.2140, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(72.6265, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(71.5559, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(72.0999, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(71.7270, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(71.3104, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(70.6213, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(71.7373, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(71.6941, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(71.0154, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(70.4432, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(69.9798, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(71.3369, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(70.5418, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(70.4984, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(70.0417, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(70.2060, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(69.5836, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(68.9363, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(69.9127, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(68.7612, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(69.1049, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(68.9876, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(67.5884, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(67.6526, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(68.2785, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(66.2458, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(67.7274, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(67.0970, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(67.7822, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(67.9636, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(67.9742, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(68.1444, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(66.5089, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(66.3278, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(67.4176, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-CDRSOB-5fold-2_sd0                                     \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetCDRSOB as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-2-16']\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "text len: 18\n",
      "remove None, then wav data: 18, text len: 18\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16', 'CTT5-5-16', 'CTT5-3-16', 'CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 68\n",
      "remove None, then wav data: 67, text len: 67\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 67\n",
      "total_loss tensor(124.5294, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(111.8160, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(108.1401, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(104.8716, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(103.8257, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(100.6897, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(94.8522, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(93.5502, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(90.8753, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(87.4118, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(86.3869, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(84.0986, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(81.9340, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(79.5502, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(79.1176, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(77.0500, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(74.4717, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(74.0083, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(71.6030, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(72.4518, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(69.9623, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(69.9637, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(69.7290, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(67.3795, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(67.0250, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(65.6293, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(67.0784, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(65.6940, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(64.4470, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(65.4184, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(64.8271, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(62.8348, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(63.2643, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(62.4430, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(62.9107, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(62.5205, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(62.3164, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(61.0044, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(58.8322, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(58.7841, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(60.8430, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(56.5579, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(59.7473, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(59.0989, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(57.8365, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(59.8567, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(56.6897, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(57.8818, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(57.1329, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(57.0747, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(57.3727, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(55.0359, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(57.2057, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(55.7787, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(55.3044, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(56.4148, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(55.1192, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(55.2435, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(55.0580, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(54.4597, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(54.3378, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(55.4171, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(54.9016, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(52.1059, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(54.0616, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(54.3287, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(50.6154, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(52.5626, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(53.3439, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(52.9216, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(50.4148, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(53.4615, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(53.0012, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(51.8153, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(50.4517, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(50.6937, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(50.9996, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(51.1346, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(51.7249, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(50.6177, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(50.9287, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(49.9871, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(49.9936, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(49.4852, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(49.6101, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(50.6475, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(50.3582, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(49.6806, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(50.1706, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(48.0595, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(49.2593, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(48.4505, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(48.3013, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(49.4940, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(49.0868, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(48.5034, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(48.2455, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(48.6760, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(46.4727, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(48.6127, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(47.9258, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(47.7706, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(46.8260, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(48.0094, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(47.0558, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(47.3196, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(46.3750, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(46.1030, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(46.6816, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(46.3115, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(45.6070, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(45.9325, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(45.3369, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(46.2985, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(46.5050, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(45.6981, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(44.9512, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(46.4341, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(45.8739, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(45.4744, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(45.3210, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(45.1296, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(44.9051, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(44.5427, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(43.8198, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(44.5722, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(44.3038, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(44.9978, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(43.9630, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(44.6694, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(43.6787, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(43.6304, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(43.3393, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(43.6793, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(42.7375, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(43.6919, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(42.0365, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(42.0279, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(42.5982, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(42.3606, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(42.7856, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(42.7724, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(42.8664, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(42.2971, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(42.5448, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(42.4011, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(41.8846, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(41.8407, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(41.4796, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(41.2923, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(40.1092, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(41.7265, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(40.2102, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(41.0338, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(40.4733, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(40.2921, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(40.9184, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(40.3611, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(40.7135, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(40.5833, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(40.4573, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(39.9027, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(39.9230, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(39.8513, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(39.4490, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(39.3237, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(39.2315, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(39.1952, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(38.8910, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(39.0483, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(39.0752, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(39.2574, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(39.3240, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(39.1286, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(39.3246, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(38.2000, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(38.4333, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(38.4946, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(38.7613, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(38.1452, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(37.8492, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(37.7525, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(37.9396, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(37.9802, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(37.0897, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(37.6320, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(37.5543, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(36.3637, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(38.0175, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(37.4611, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(36.9427, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(36.9672, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(36.0303, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(35.7954, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(36.2910, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(36.6642, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(35.2835, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(36.3008, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(36.6194, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(36.2060, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(35.6993, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(35.7285, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(34.9320, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(35.2662, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(35.5878, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(36.0375, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(35.0641, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(35.1829, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(34.6980, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(35.3775, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(34.6494, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(35.2029, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(34.1783, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(34.4845, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(34.6359, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(34.4269, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(33.9681, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(34.2369, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(34.3320, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(34.2889, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(33.5008, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(33.9391, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(33.7766, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-CDRSOB-5fold-3_sd0                                     \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetCDRSOB as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-3-16']\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16', 'CTT5-2-16', 'CTT5-5-16', 'CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 69\n",
      "remove None, then wav data: 68, text len: 68\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 68\n",
      "total_loss tensor(178.7433, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(175.3977, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(171.8389, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(170.4040, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(164.7329, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(164.1306, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(159.4156, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(158.8587, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(155.1811, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(154.2009, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(152.0249, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(151.5963, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(147.8125, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(147.2935, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(147.6194, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(143.9182, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(142.8844, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(143.1569, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(140.8730, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(138.9650, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(140.8461, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(139.2914, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(138.3628, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(139.4686, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(136.9633, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(136.3820, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(136.0126, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(133.2109, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(135.9000, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(132.9166, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(131.5950, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(133.5637, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(133.1465, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(133.0489, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(126.8415, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(130.6328, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(128.3636, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(129.8419, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(128.8273, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(129.8333, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(130.8245, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(125.8422, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(127.6651, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(127.8066, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(126.6115, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(125.2841, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(126.0299, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(125.4446, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(125.0490, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(124.5031, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(123.6057, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(121.7486, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(123.2187, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(121.8706, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(121.6959, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(121.7940, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(121.9726, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(122.4539, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(120.2401, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(120.8072, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(120.4187, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(122.1700, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(118.9925, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(119.8465, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(119.8745, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(118.7601, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(119.2615, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(119.0888, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(116.6320, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(117.8273, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(116.9106, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(117.3361, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(117.4672, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(117.9910, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(116.6615, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(117.9876, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(115.6488, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(115.2967, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(115.1557, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(112.8520, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(114.0488, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(115.6147, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(115.3134, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(114.6569, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(114.5695, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(112.8150, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(113.7176, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(113.7279, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(112.0434, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(113.1062, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(113.0056, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(113.3292, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(112.0091, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(110.1808, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(112.4071, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(111.6119, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(111.7940, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(109.2930, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(109.7749, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(112.1771, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(109.8623, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(111.3387, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(109.8504, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(107.7310, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(109.4328, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(106.6621, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(107.1559, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(110.1906, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(107.4212, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(107.1234, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(108.5308, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(108.1853, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(107.8773, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(106.5614, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(104.8822, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(105.6856, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(106.6439, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(107.4442, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(105.8994, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(105.3516, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(104.2492, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(106.6533, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(105.4611, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(105.2583, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(105.6466, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(105.1016, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(105.2543, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(104.9190, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(103.4270, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(104.1255, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(104.4468, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(103.8724, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(101.7916, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(103.2904, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(102.5419, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(100.1604, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(101.1373, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(102.0009, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(101.8563, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(100.5207, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(102.2321, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(101.3896, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(100.1561, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(100.9321, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(100.2840, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(99.7265, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(99.3944, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(99.3026, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(99.6970, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(99.6792, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(99.4568, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(97.9404, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(98.6022, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(99.1055, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(97.6613, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(99.0565, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(97.6635, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(98.6595, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(98.9445, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(97.7587, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(96.4668, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(96.9287, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(96.9597, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.5178, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(96.5216, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.9040, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.5914, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(96.8898, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(94.6786, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.4715, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(94.6161, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(94.2229, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(96.1215, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(94.8279, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(92.9039, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(93.7385, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(93.7771, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.9926, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(93.6373, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(93.2430, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(93.1763, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.5774, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(90.3984, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.8627, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(92.3042, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(93.3827, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(90.4395, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(92.4028, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.2435, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.7555, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(90.3827, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(88.9036, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.2235, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(90.0597, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(90.3668, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(90.5377, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.9627, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(90.0371, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(88.7847, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.3032, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.0048, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(88.9286, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.7881, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.6129, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.3315, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.0536, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.6343, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.9323, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.5945, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.4008, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.2802, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.6765, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(86.9231, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.0313, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(86.3405, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.1843, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.2969, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.7473, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(84.9287, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.4864, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-CDRSOB-5fold-4_sd0                                     \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetCDRSOB as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16', 'CTT5-2-16', 'CTT5-3-16', 'CTT5-5-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "text len: 69\n",
      "remove None, then wav data: 68, text len: 68\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 68\n",
      "total_loss tensor(142.3585, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(146.9029, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(145.1177, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(143.5973, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(141.3034, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(141.2763, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(139.4172, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(137.4718, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(138.2462, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(134.7752, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(136.8799, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(132.7705, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(132.8460, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(133.3929, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(129.3757, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(127.5298, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(127.4570, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(126.2082, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(126.1124, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(125.3311, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(124.0293, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(121.4141, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(122.4901, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(121.0887, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(120.3107, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(117.7143, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(120.1845, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(116.8731, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(117.0915, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(117.1640, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(118.3705, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(116.5632, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(116.2612, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(114.1090, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(115.8596, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(114.6805, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(114.0320, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(112.1146, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(112.7639, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(112.5554, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(111.1100, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(110.5353, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(111.6208, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(110.6697, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(108.4307, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(110.0550, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(109.5888, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(108.4712, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(108.2068, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(108.6865, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(107.7682, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(105.7905, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(105.3196, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(106.6106, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(107.3583, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(104.5808, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(106.1879, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(104.8585, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(104.9235, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(104.3613, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(101.9690, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(103.6249, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(103.7797, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(102.2714, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(102.3786, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(102.4018, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(102.6847, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(99.9287, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(101.9086, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(100.8764, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(101.3300, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(99.0789, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(102.0225, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(100.9324, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(100.7775, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(98.4390, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(98.9513, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(100.4593, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(98.8141, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(99.8928, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(98.3085, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(98.1112, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(98.6311, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(98.9665, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(97.4110, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(94.9981, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(97.6207, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(97.4607, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.0926, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(97.0225, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.5049, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(96.9238, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.7511, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.3481, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.3420, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.6815, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(96.2573, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(93.6516, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(92.7219, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.2357, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(93.6436, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(94.1215, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(92.6659, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(92.8850, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.9150, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(93.1889, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(93.4630, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(92.8745, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.9375, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(92.9143, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(92.2939, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.5218, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.8727, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.2031, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(88.9839, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.5817, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(90.2344, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.1545, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(90.6905, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(90.7444, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.0710, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.7851, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(90.6393, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.4421, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.9096, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.1576, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.0811, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.0849, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.1743, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.1508, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.0129, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.0745, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.5707, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(88.5849, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(88.1917, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(86.7394, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.5084, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.2807, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(86.7682, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.4001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(86.0976, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.0276, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(86.1726, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(86.3954, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.1121, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.2728, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.0679, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(84.4578, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(84.8704, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.0041, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(83.6371, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.3802, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(84.4487, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(83.8783, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(84.4200, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(84.1903, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(81.2552, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(83.3355, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(82.3969, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(82.7978, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(83.3597, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(82.0266, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(82.0029, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(82.7038, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(82.2992, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(81.7871, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(81.2641, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(81.5594, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(81.5253, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(80.7981, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(81.0435, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(80.4357, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(80.4365, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(79.8558, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(80.0692, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(79.2241, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(79.6669, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(79.3529, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(78.8357, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(78.2782, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(79.4300, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(78.7920, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(78.6057, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(79.0845, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(78.0749, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(79.0714, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(78.2844, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(79.2160, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(78.6460, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(77.8309, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(77.4079, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(76.9748, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(77.4674, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(76.8131, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(77.6957, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(76.0991, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(75.4404, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(76.9424, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(76.9127, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(73.9411, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(75.8612, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(76.2223, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(75.0432, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(75.6334, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(74.7967, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(74.6311, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(74.2588, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(74.9777, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(73.7137, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(74.4638, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(74.3086, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(74.9044, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(72.3275, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(74.0657, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(74.3233, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(73.0959, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(72.6670, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(72.8818, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(72.3326, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(73.3756, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-CDRSOB-5fold-5_sd0                                     \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetCDRSOB as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-5-16']\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16', 'CTT5-2-16', 'CTT5-3-16', 'CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 69\n",
      "remove None, then wav data: 68, text len: 68\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 68\n",
      "total_loss tensor(200.6228, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(177.4085, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(174.3586, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(174.1924, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(170.5947, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(167.0564, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(164.1772, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(165.2789, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(162.3283, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(161.7224, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(157.6310, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(155.1026, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(153.6671, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(150.9537, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(150.6501, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(148.2489, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(149.8540, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(146.4112, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(147.1865, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(142.0410, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(143.5825, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(142.4897, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(142.7002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(139.8390, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(139.3777, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(137.0511, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(136.6898, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(136.4412, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(136.1384, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(135.2055, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(134.3559, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(133.0607, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(133.1428, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(133.3398, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(130.5785, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(130.1749, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(129.5399, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(129.2421, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(128.9980, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(125.9603, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(127.0509, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(126.6492, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(125.6437, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(125.2648, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(124.4729, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(122.7658, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(123.1332, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(120.1778, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(122.0161, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(121.9450, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(124.2664, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(119.4923, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(118.1404, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(117.0551, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(117.6945, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(118.8288, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(117.1909, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(115.2069, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(116.1920, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(115.3747, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(115.4111, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(115.0843, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(115.3369, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(112.9517, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(114.2456, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(114.6676, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(112.8380, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(112.3023, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(112.6406, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(112.1431, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(108.1739, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(110.9242, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(110.5339, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(109.4031, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(109.6878, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(109.0197, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(108.0136, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(107.5251, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(107.7449, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(107.7086, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(107.5555, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(106.7764, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(105.9718, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(104.1583, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(105.1127, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(103.8009, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(106.8064, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(105.0341, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(103.3465, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(104.5972, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(102.0729, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(104.3237, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(103.1620, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(103.4670, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(101.9480, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(101.8967, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(102.6195, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(102.3729, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(101.5322, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(101.0807, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(101.1852, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(101.3729, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(100.9079, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(100.0610, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(99.9979, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(99.3896, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(97.5666, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(100.0739, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(99.1558, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(96.8248, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(97.7021, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(97.0193, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(98.2403, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(97.3662, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(96.8102, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(96.1757, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(96.4610, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.2049, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(97.0450, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.4848, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.5573, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(93.3751, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(94.7819, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(92.9517, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.0781, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(95.1666, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(94.0043, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(94.0238, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(93.6488, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(93.4124, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(94.3910, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(92.4921, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.7402, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(92.6841, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(92.2914, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(92.4367, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(93.1354, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.2999, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(90.9250, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.9096, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(91.4472, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(90.0988, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.0257, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.5088, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.0185, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.6643, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.6928, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(89.0312, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(86.9581, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(88.1699, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.4620, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(88.4037, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.2116, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.2452, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.0193, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.8188, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(87.0579, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(86.6807, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(86.2395, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(84.9592, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(86.3297, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(86.1039, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.2013, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.6874, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.1491, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.4659, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.0550, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(84.5533, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(84.5160, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(85.1517, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(83.6081, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(84.4092, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(82.6026, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(83.6186, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(82.5086, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(83.9745, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(82.6242, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(81.0430, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(81.6958, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(80.9716, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(82.1945, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(81.1151, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(81.8442, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(80.5901, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(80.2030, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(81.5343, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(80.0559, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(81.0871, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(80.8689, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(79.9461, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(80.0464, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(79.4917, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(79.6371, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(80.2629, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(78.4711, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(78.7582, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(77.8393, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(78.2895, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(77.8743, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(79.0364, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(78.2408, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(77.6650, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(79.2449, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(77.5371, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(76.8109, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(76.8657, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(77.1660, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(76.3153, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(76.9212, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(77.2960, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(76.8017, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(76.7473, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(76.4542, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(74.5690, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(76.6570, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(75.1626, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(75.4449, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(75.2566, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(75.8718, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(74.4387, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "15001\n"
     ]
    }
   ],
   "source": [
    "# res = False\n",
    "# import time\n",
    "# while (res == False):\n",
    "#     time.sleep(2)\n",
    "#     try:\n",
    "#         res = main()\n",
    "#     except:\n",
    "#         continue\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "infrared-denmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "============  Result of /home/jupyter-jason3/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv ============\r\n",
      " -----------------------------------------------------------------------\r\n",
      "| Statics\t\t|  Truth\t|  Prediction\t| Abs. Diff.\t|\r\n",
      " -----------------------------------------------------------------------\r\n",
      "| Avg. # of chars\t|  8.01\t|  8.10\t|  0.16\t\t|\r\n",
      "| Avg. # of words\t|  1.00\t|  1.00\t|  0.00\t\t|\r\n",
      " -----------------------------------------------------------------------\r\n",
      " ---------------------------------------------------------------\r\n",
      "| Error Rate (%)| Mean\t\t| Std.\t\t| Min./Max.\t|\r\n",
      " ---------------------------------------------------------------\r\n",
      "| Character\t| 7.9479\t| 21.68\t\t| 0.00/240.00\t|\r\n",
      "| Word\t\t| 18.1725\t| 38.56\t\t| 0.00/100.00\t|\r\n",
      " ---------------------------------------------------------------\r\n",
      "Note : If the text unit is phoneme, WER = PER and CER is meaningless.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval.py --file ~/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "230917",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
