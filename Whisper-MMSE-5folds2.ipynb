{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "distributed-bahrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intellectual-shade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "marine-stable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mexican-stevens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudaSetDevice(0)\n",
    "#dataset transcript要在dataset資好夾調\n",
    "#cuda 在basesolver init調\n",
    "#dataset要在data.py設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lonely-nickname",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n",
    "#! python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Author: kun\n",
    "# @Time: 2019-10-29 20:29\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "class Para(object):\n",
    "    a=1\n",
    "\n",
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda:0')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
    "    \n",
    "#force_cudnn_initialization()\n",
    "def main():\n",
    "    # For reproducibility, comment these may speed up training\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Arguments\n",
    "#     parser = argparse.ArgumentParser(description='Training E2E asr.')\n",
    "#     parser.add_argument('--config', type=str, help='Path to experiment config.')\n",
    "#     parser.add_argument('--name', default=None, type=str, help='Name for logging.')\n",
    "#     parser.add_argument('--logdir', default='log/', type=str,\n",
    "#                         help='Logging path.', required=False)\n",
    "#     parser.add_argument('--ckpdir', default='ckpt/', type=str,\n",
    "#                         help='Checkpoint path.', required=False)\n",
    "#     parser.add_argument('--outdir', default='result/', type=str,\n",
    "#                         help='Decode output path.', required=False)\n",
    "#     parser.add_argument('--load', default=None, type=str,\n",
    "#                         help='Load pre-trained model (for training only)', required=False)\n",
    "#     parser.add_argument('--seed', default=0, type=int,\n",
    "#                         help='Random seed for reproducable results.', required=False)\n",
    "#     parser.add_argument('--cudnn-ctc', action='store_true',\n",
    "#                         help='Switches CTC backend from torch to cudnn')\n",
    "#     parser.add_argument('--njobs', default=32, type=int,\n",
    "#                         help='Number of threads for dataloader/decoding.', required=False)\n",
    "#     parser.add_argument('--cpu', action='store_true', help='Disable GPU training.')\n",
    "#     parser.add_argument('--no-pin', action='store_true',\n",
    "#                         help='Disable pin-memory for dataloader')\n",
    "#     parser.add_argument('--test', action='store_true', help='Test the model.')\n",
    "#     parser.add_argument('--no-msg', action='store_true', help='Hide all messages.')\n",
    "#     parser.add_argument('--lm', action='store_true',\n",
    "#                         help='Option for training RNNLM.')\n",
    "#     # Following features in development.\n",
    "#     parser.add_argument('--amp', action='store_true', help='Option to enable AMP.')\n",
    "#     parser.add_argument('--reserve-gpu', default=0, type=float,\n",
    "#                         help='Option to reserve GPU ram for training.')\n",
    "#     parser.add_argument('--jit', action='store_true',\n",
    "#                         help='Option for enabling jit in pytorch. (feature in development)')\n",
    "#     ###\n",
    "#     paras = parser.parse_args()\n",
    "    paras = Para()\n",
    "#     paras.config = './config/aishell_asr_example_lstm4atthead1-test.yaml'\n",
    "#     paras.name = None\n",
    "#     paras.logdir = 'log/'\n",
    "#     paras.ckpdir = 'ckpt/'\n",
    "#     paras.outdir = 'result/'\n",
    "#     paras.load = None\n",
    "#     paras.seed = 0\n",
    "#     paras.cudnn_ctc = False\n",
    "#     paras.cpu = False\n",
    "#     paras.no_pin = False\n",
    "#     paras.test = True\n",
    "#     paras.no_msg = False\n",
    "#     paras.lm = False\n",
    "#     paras.amp = False\n",
    "#     paras.reserve_gpu = 0\n",
    "#     paras.jit = False\n",
    "    setattr(paras, 'config', 'config/cv11Lu_asr_lstm4atthead_allvocab-biclass2.yaml')\n",
    "    setattr(paras, 'name', None)\n",
    "    setattr(paras, 'logdir', 'log/')\n",
    "    setattr(paras, 'ckpdir', 'LAS_ckpt')\n",
    "    setattr(paras, 'outdir', 'result/')\n",
    "    setattr(paras, 'load', None)\n",
    "    setattr(paras, 'seed', 0)\n",
    "    setattr(paras, 'cudnn_ctc', False)\n",
    "    setattr(paras, 'njobs',0)\n",
    "    setattr(paras, 'cpu', False)\n",
    "    setattr(paras, 'no_pin', False)\n",
    "    setattr(paras, 'test', False)\n",
    "    setattr(paras, 'no_msg', False)\n",
    "    setattr(paras, 'lm', False)\n",
    "    setattr(paras, 'amp', False)\n",
    "    setattr(paras, 'reserve_gpu', 9)\n",
    "    setattr(paras, 'jit', False)\n",
    "    setattr(paras, 'gpu', not paras.cpu)\n",
    "    setattr(paras, 'pin_memory', not paras.no_pin)\n",
    "    setattr(paras, 'verbose', not paras.no_msg)\n",
    "    setattr(paras, 'finetune', False)\n",
    "    setattr(paras, 'binaryClass', True)\n",
    "\n",
    "\n",
    "    config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "    np.random.seed(paras.seed)\n",
    "    torch.manual_seed(paras.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(paras.seed)\n",
    "\n",
    "    # Hack to preserve GPU ram just incase OOM later on server\n",
    "    try:\n",
    "        if paras.gpu and paras.reserve_gpu > 0:\n",
    "            buff = torch.randn(int(paras.reserve_gpu * 1e9 // 4)).cuda()\n",
    "            del buff\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    if paras.lm:\n",
    "        # Train RNNLM\n",
    "        from train_lm import Solver\n",
    "\n",
    "        mode = 'train'\n",
    "    else:\n",
    "        if paras.test:\n",
    "            # Test ASR\n",
    "            assert paras.load is None, 'Load option is mutually exclusive to --test'\n",
    "            from test_asr import Solver\n",
    "\n",
    "            mode = 'test'\n",
    "        elif paras.finetune:\n",
    "            assert paras.load is not None\n",
    "            from finetune_asr import Solver\n",
    "            mode = 'train'\n",
    "        elif paras.binaryClass:\n",
    "            # assert paras.load is not None\n",
    "            from Whisper_MMSE_train import Solver\n",
    "            mode = 'train'\n",
    "        else:\n",
    "            # Train ASR\n",
    "            from train_asr import Solver\n",
    "\n",
    "            mode = 'train'\n",
    "\n",
    "    print(\"\\nUsing {} mode\\n\".format(mode))\n",
    "    for idx in range(0,5):\n",
    "        paras.config = f'config/cv11Lu_asr_lstm4atthead_allvocab-MMSE-5fold-{idx+1}.yaml'#latest7k_4lstm.pth\n",
    "#         setattr(paras, 'load', f'./ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-{idx+1}_sd0/latest13knew_4LSTM.pth')\n",
    "        #要用vag01要改load_ckpt\n",
    "        #改data要到 dataset\n",
    "        config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "        solver = Solver(config, paras, mode)\n",
    "\n",
    "        solver.load_data()\n",
    "    #     solver.print_model()\n",
    "        solver.set_model()\n",
    "        solver.exec()\n",
    "        del solver\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accepting-convenience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using train mode\n",
      "\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-MMSE-5fold-1_sd0                                       \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetMMSE as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: data_process, split: ['CTT5-5-16', 'CTT5-2-16', 'CTT5-3-16', 'CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 69\n",
      "remove None, then wav data: 68, text len: 68\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 68\n",
      "total_loss tensor(46370.2500, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(36952.3750, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(28085.4453, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(20018.6016, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(13574.6445, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(8725.3760, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(5597.4399, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(4186.8770, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3718.8616, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3635.1292, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3573.6399, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3590.9968, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3480.4160, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3489.6619, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3411.1162, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3371.9509, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3358.2690, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3327.9729, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3274.6333, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3204.8550, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3238.3945, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3232.0920, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3076.8530, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3153.8665, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3151.1440, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3083.0339, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2979.5420, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3089.4663, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2959.3164, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3022.7190, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2944.8801, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2889.8049, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2910.8945, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2939.1167, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2875.4302, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2741.1155, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2797.6733, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2824.1904, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2792.9937, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2783.6897, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2735.9268, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2809.7695, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2739.6558, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2779.8066, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2810.1624, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2798.8701, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2737.0530, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2794.8584, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2764.5330, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2773.4167, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2726.1284, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2791.5593, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2768.1184, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2759.3203, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2747.2776, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2752.8406, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2801.5386, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2760.9634, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2817.1892, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2783.5991, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2804.6841, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2824.1501, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2832.1897, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2829.8140, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2797.5068, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2768.5007, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2826.5908, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2790.5728, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2829.3696, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2744.2170, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2814.0259, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2798.2974, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2817.0361, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2812.0667, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2827.5305, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2779.3906, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2775.8584, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2781.3706, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2803.6914, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2795.8416, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2873.1628, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2753.9915, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2811.5889, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2819.7927, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2828.5498, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2759.9680, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2781.6216, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2789.0720, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2745.9487, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2799.9819, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2813.7046, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2804.2947, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2815.1479, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2795.5251, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2814.9587, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2824.2769, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2782.0857, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2797.8396, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2805.5083, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2784.8853, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2818.1714, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2787.7595, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2756.6333, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2764.4236, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2783.3149, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2751.9856, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2830.5530, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2757.1880, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2769.3440, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2844.8235, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2787.5183, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2822.2244, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2788.8606, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2768.3809, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2811.0081, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2754.2729, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2790.5693, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2788.0898, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2709.8279, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2792.1187, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2721.5642, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2757.5083, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2782.4849, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2743.3982, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2768.5620, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2748.2285, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2732.2939, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2806.2512, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2752.9990, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2719.5327, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2783.5027, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2717.6047, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2786.2197, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2732.4849, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2781.2361, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2816.0293, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2719.3757, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2818.4460, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2786.6230, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2756.6284, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2758.8457, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2788.5190, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2751.3342, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2759.6531, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2748.1099, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2722.4949, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2775.7437, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2705.0486, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2740.7620, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2708.5591, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2758.7793, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2754.8044, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2779.3479, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2770.8540, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2702.9290, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2742.3967, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2723.2144, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2720.9670, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2766.3455, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2745.0156, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2752.6895, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2752.8848, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2746.5320, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2759.1523, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2714.2800, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2781.6587, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2756.0022, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2696.6594, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2738.7046, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2710.2317, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2740.5408, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2741.3438, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2680.6621, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2738.6006, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2757.3052, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2758.4814, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2737.0046, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2698.9229, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2711.0754, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2738.9519, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2769.9417, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2735.0669, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2736.0535, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2694.9209, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2730.1465, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2740.4333, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2706.7490, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2739.4985, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2700.0300, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2722.8977, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2682.3247, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2709.8042, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2735.1406, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2693.9224, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2717.7180, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2725.4224, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2704.7495, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2725.3853, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2697.3623, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2696.8750, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2719.0479, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2713.5557, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2697.2874, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2688.0894, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2700.7710, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2684.0686, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2705.4897, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2695.2485, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2692.1340, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2674.2227, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2733.9675, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2703.6575, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2683.8647, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2695.4871, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2688.9712, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2694.4434, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2669.7402, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2693.0432, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2708.4739, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2705.8293, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-MMSE-5fold-2_sd0                                       \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetMMSE as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-2-16']\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "text len: 18\n",
      "remove None, then wav data: 18, text len: 18\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16', 'CTT5-5-16', 'CTT5-3-16', 'CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 68\n",
      "remove None, then wav data: 67, text len: 67\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 67\n",
      "total_loss tensor(47679.9570, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(39323.6875, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(30772.4375, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(22995.5410, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(16319.0547, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(10713.8398, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(6821.7197, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(4333.8911, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(3264.5659, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(3073.7014, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2986.9297, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2914.0195, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2849.2710, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2765.4185, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2700.8691, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2661.2285, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2594.2097, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2524.8535, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2529.4038, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2477.9702, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2419.8655, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2400.9272, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2359.5237, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2307.3245, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2273.8672, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2235.1729, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2211.9788, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2193.2996, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2175.3467, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2133.1372, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2105.5098, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2136.8853, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2107.7817, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2075.9592, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2120.4675, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2086.4895, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2086.9988, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2044.5641, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2054.4036, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2064.4087, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2022.2520, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2040.4962, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2075.1736, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2055.8833, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2016.9319, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2088.5605, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2055.0486, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2060.5537, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2058.6260, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2066.1624, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2069.6392, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2055.0903, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2071.0083, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2076.5027, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2053.6675, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2049.2637, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2077.9773, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2041.7985, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2081.5789, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2064.0386, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2038.9167, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2042.3600, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2047.5914, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2085.7761, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2058.1372, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2036.8572, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2096.1565, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2022.1954, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2087.1653, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2063.6360, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2096.0537, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2068.3027, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2036.6110, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2057.1519, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2082.7043, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2066.5249, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2039.4141, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2043.2664, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2046.1846, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2058.3328, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2073.2317, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2059.8779, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2059.5317, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2032.2251, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2045.0394, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2083.1060, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2044.9238, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2058.2024, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2054.4031, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2016.8677, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2046.4500, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2031.6718, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2071.2058, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2039.9297, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2050.3665, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2047.5404, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2041.3470, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2040.4657, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2057.8379, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2066.2454, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2021.6116, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2034.8140, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2014.6167, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2034.4647, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1998.5293, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2039.0037, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2043.6981, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1994.1704, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2043.6675, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1999.9967, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2021.4875, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2051.5923, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2021.0536, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2034.2048, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2022.8235, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2026.3488, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1999.9194, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1996.0193, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2044.8241, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2015.0399, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2017.1398, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2013.3411, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2011.6250, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2027.4746, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2019.6198, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2014.2091, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2010.2085, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2027.2017, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2002.0920, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1979.1166, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1995.5422, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2025.3265, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2023.8551, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2024.1041, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1994.3582, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1992.3633, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2023.0981, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1966.8781, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2003.3075, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1990.1943, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2009.7166, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1965.8848, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1999.7213, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2018.6649, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2017.2678, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1994.6393, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1993.1877, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2009.4766, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1978.5450, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1997.7976, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1971.8580, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1971.1770, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1997.3450, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1973.6630, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1993.7152, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1993.2582, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1994.6958, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1966.8065, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1986.6608, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1998.6663, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1967.7648, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1987.6189, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1955.7034, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2004.7255, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1972.7788, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1980.9165, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1980.5496, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1960.8527, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1958.1322, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1973.5536, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1978.9222, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1960.5208, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1963.9734, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1989.4031, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1958.0317, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1968.8619, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1965.8386, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1993.3492, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1960.4259, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1970.6299, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1950.8353, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1965.7640, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1953.0793, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1940.6167, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1978.3892, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1914.5120, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1971.9613, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1942.5973, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1953.4781, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1952.3877, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1913.7075, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1967.2036, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1957.9169, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1941.9608, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1962.4978, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1964.9694, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1914.7804, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1958.0662, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1943.5895, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1960.0430, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1914.5289, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1944.4871, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1933.3134, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1934.9224, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1968.3069, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1934.8833, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1946.8459, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1928.6506, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1917.4169, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1948.9497, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1928.9474, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1939.3512, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1928.4464, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1929.0312, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1912.2007, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1933.4512, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1923.2531, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1933.6099, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1942.4084, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1921.6373, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1931.3284, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1922.3993, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1923.2123, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-MMSE-5fold-3_sd0                                       \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetMMSE as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-3-16']\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16', 'CTT5-2-16', 'CTT5-5-16', 'CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 69\n",
      "remove None, then wav data: 68, text len: 68\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 68\n",
      "total_loss tensor(45754.8203, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(37376.0469, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(28923.5098, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(21334.2051, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(14822.1602, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(9939.8906, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(6794.0083, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(4912.1484, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3961.6108, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3734.8420, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3718.5200, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3670.9648, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3643.5051, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3580.2488, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3583.7974, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3552.6331, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3475.7334, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3462.3982, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3426.4187, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3365.4167, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3312.3748, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3350.8013, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3273.6384, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3294.6182, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3197.5447, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3132.9771, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3210.7170, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3157.3801, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3134.9192, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3032.6169, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3147.1243, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3072.8943, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3031.1023, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3047.5718, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3043.2556, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3003.8481, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3031.1370, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3062.5310, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3060.2471, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3032.4180, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3032.0740, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2984.3943, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3115.1831, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3049.4709, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3035.7480, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3011.3367, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3020.6865, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3077.1360, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3044.2727, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3013.7271, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3018.3164, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3045.1125, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3042.8125, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3024.5591, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3034.9519, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3011.8723, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3006.3257, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3014.3938, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3026.7966, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2980.7063, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2977.3359, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2977.6428, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3019.2051, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2997.2764, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2973.3152, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2996.4780, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2988.0813, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2947.4280, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3020.3635, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2989.5979, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2923.6089, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3039.9441, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2964.6699, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2966.3787, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2984.7544, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2926.3948, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2975.1714, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2936.0479, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2945.1460, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2972.5422, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2973.2043, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2951.6516, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2943.6375, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2974.7859, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2894.7534, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2977.9902, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2891.7361, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2928.2544, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2947.6448, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2918.9065, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2928.1543, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2902.5017, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2915.6135, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2875.8652, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2914.2446, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2920.7705, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2943.0325, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2892.7078, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2865.7366, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2902.5742, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2905.7781, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2908.3354, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2885.8550, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2815.3323, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2888.1995, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2848.5276, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2898.7087, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2869.4006, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2833.2180, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2886.0559, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2866.6506, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2889.0286, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2809.5005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2879.7563, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2865.4658, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2818.6790, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2841.1760, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2808.4968, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2807.1160, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2856.5347, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2821.1191, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2868.6365, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2763.4185, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2846.7639, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2840.0671, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2809.5181, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2850.4414, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2815.7935, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2774.9001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2845.4199, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2799.3962, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2787.6733, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2818.4546, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2773.4863, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2811.2383, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2827.5315, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2789.1208, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2818.4946, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2829.5718, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2814.6514, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2720.0122, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2836.8716, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2792.5627, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2813.5283, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2797.4236, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2815.2874, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2780.9023, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2771.0088, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2808.8069, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2783.9263, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2792.0505, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2814.2874, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2764.7578, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2787.1541, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2761.6152, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2783.7053, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2703.8147, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2820.6353, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2755.4556, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2792.9414, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2756.6616, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2751.9028, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2785.8501, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2773.1387, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2781.1628, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2749.8625, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2763.7798, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2752.9487, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2787.4382, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2686.7007, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2762.1814, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2754.3167, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2730.5525, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2767.8091, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2715.3853, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2769.7625, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2749.2041, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2721.6694, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2739.8960, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2730.0500, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2724.5303, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2714.9355, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2730.6240, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2739.8484, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2726.9897, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2762.6909, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2731.8384, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2763.4905, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2746.2336, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2742.6443, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2706.7791, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2749.1550, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2692.1340, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2714.7263, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2750.5796, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2711.8364, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2722.8220, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2723.7397, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2712.0842, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2737.4937, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2731.9565, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2660.1035, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2737.8228, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2705.4858, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2714.5713, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2744.1392, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2696.3032, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2704.9431, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2696.5293, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2715.5369, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2684.5767, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2730.7488, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2698.9563, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2666.7478, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2735.7446, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2670.9204, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2672.5125, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2714.9067, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2671.9429, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2714.1023, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-MMSE-5fold-4_sd0                                       \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetMMSE as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16', 'CTT5-2-16', 'CTT5-3-16', 'CTT5-5-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "text len: 69\n",
      "remove None, then wav data: 68, text len: 68\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 68\n",
      "total_loss tensor(48874.2266, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(39917.6953, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(31153.1016, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(22657.7871, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(15536.2109, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(10047.1270, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(6188.7661, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3939.2151, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3148.3599, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2931.0688, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2870.6487, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2802.1675, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2765.1411, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2715.9377, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2690.6304, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2618.5776, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2576.0972, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2568.1060, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2499.5261, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2482.7825, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2438.0339, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2433.1968, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2371.2683, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2328.5220, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2307.5483, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2327.2610, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2286.1470, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2239.9038, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2240.7324, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2190.8267, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2122.3149, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2184.9160, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2141.9863, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2124.8711, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2121.2390, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2099.2407, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2022.7869, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2074.5432, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2060.9829, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2021.4934, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2095.9358, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2067.3923, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2039.7177, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2047.6909, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2063.5999, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2072.2629, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2058.7908, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2068.7324, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2061.5178, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2037.3799, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2052.5164, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2103.2651, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2077.8972, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2037.1300, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2104.5034, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2097.3459, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2054.8076, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2082.6140, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2079.0273, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2041.6571, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2105.7236, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2047.0609, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2072.5955, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2105.1511, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2070.9504, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2076.6963, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2095.7827, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2082.8191, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2111.5461, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2137.8926, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2102.0056, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2078.1699, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2121.1108, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2061.8047, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2118.6858, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2166.4607, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2135.3818, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2076.3730, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2105.8276, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2115.8950, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2158.8342, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2063.4705, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2117.2471, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2147.6528, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2119.0222, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2130.6309, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2138.1499, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2146.3323, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2135.6855, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2121.6147, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2112.8689, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2121.5059, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2101.9360, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2091.0071, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2160.1362, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2106.3408, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2137.0767, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2110.4001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2132.6711, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2118.7566, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2085.4277, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2123.1343, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2130.1633, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2132.8354, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2105.5347, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2120.4641, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2133.7751, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2090.8218, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2092.3589, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2147.5142, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2081.0598, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2144.0618, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2145.3911, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2086.7869, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2100.3267, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2110.3865, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2104.1133, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2140.0811, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2073.2505, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2116.4868, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2124.4204, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2119.2434, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2090.0601, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2077.2021, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2133.2471, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2102.1592, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2094.0190, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2116.4849, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2099.1265, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2098.4045, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2112.1724, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2113.2458, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2082.3098, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2106.7754, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2124.3691, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2110.3652, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2056.3857, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2098.1155, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2094.1687, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2077.2073, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2087.1624, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2082.3831, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2086.7878, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2099.6787, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2083.4663, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2096.0962, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2057.4573, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2092.2361, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2102.7957, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2109.0869, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2071.5188, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2088.3782, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2052.7437, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2097.8733, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2087.8650, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2088.8289, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2084.8555, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2065.5552, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2082.2075, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2093.3257, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2070.5442, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2080.5032, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2071.7388, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2073.2937, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2086.9893, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2059.8213, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2073.0703, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2070.2776, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2071.4509, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2108.0725, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2030.9182, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2058.2871, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2092.0388, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2046.3688, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2084.3232, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2069.2769, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2047.6558, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2056.0537, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2067.9390, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2073.5652, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2065.2429, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2061.9434, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2067.3401, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2052.1306, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2050.9971, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2053.0151, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2073.3215, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2052.6689, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2070.3872, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2057.4062, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2027.8024, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2060.9985, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2040.5430, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2043.5570, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2045.1970, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2049.3765, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2063.6648, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2022.9952, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2055.4431, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2035.2603, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2063.8411, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2045.4325, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2029.2777, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2039.2754, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2052.4272, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2036.2544, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2034.8845, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2011.0165, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2035.8412, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2028.6693, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1998.6478, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2043.1157, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2042.6449, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2044.7585, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2000.9653, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2033.7510, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2027.7434, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2048.3145, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2013.6571, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2036.0646, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-MMSE-5fold-5_sd0                                       \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetMMSE as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-5-16']\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 16, text len: 16\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16', 'CTT5-2-16', 'CTT5-3-16', 'CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 69\n",
      "remove None, then wav data: 69, text len: 69\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 69\n",
      "total_loss tensor(48325.6719, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(39398.4688, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(30695.2363, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(22642.8262, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(15825.5293, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(10483.4805, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(6996.1162, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(4601.0718, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(3524.9099, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(3183.3599, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(3101.3782, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(3069.2788, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(3039.9238, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2993.5610, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2942.2559, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2927.4148, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2841.2219, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2894.7498, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2848.4314, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2854.8142, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2797.1899, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2816.7922, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2775.6123, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2764.5540, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2740.8132, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2729.3030, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2741.6436, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2697.9875, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2704.0225, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2682.9204, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2707.0525, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2652.6428, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2727.2188, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2671.9041, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2683.7070, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2699.6655, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2725.3809, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2687.2947, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2680.2363, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2717.5203, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2721.5422, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2718.0659, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2690.5142, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2735.9209, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2769.4082, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2717.8447, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2751.5767, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2716.6992, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2770.2214, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2764.1260, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2676.5149, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2792.6533, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2763.8127, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2720.0515, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2742.2275, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2766.3381, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2672.9187, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2795.9773, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2741.6458, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2743.9958, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2770.0515, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2683.4048, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2805.7095, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2800.7375, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2762.1150, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2787.4480, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2785.3721, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2748.2720, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2751.3896, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2788.1631, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2786.3530, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2735.6016, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2800.3591, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2782.5596, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2694.8250, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2796.3198, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2749.4460, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2749.0374, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2781.0437, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2794.9431, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2782.1411, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2751.6968, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2812.4343, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2750.0503, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2781.4849, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2771.5730, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2795.1353, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2735.0037, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2762.5396, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2762.2876, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2724.8462, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2781.6707, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2732.5242, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2756.7991, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2724.8269, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2729.3279, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2712.2139, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2765.6824, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2745.0918, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2734.6604, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2733.4124, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2703.2314, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2756.6675, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2730.2046, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2727.9226, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2722.7725, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2744.8987, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2704.8381, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2725.0320, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2735.4385, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2735.3169, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2701.4253, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2725.0413, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2709.0923, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2722.0254, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2730.8979, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2727.9167, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2664.2605, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2723.9385, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2725.6431, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2627.3428, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2727.0654, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2717.5291, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2683.2571, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2714.3433, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2698.2913, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2686.8354, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2715.6782, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2655.9817, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2672.1477, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2681.4341, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2696.8357, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2660.8203, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2705.7898, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2640.5635, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2715.5044, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2663.9285, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2672.7764, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2676.4834, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2696.2256, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2679.7690, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2672.6794, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2636.9414, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2698.5728, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2649.1873, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2650.9702, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2687.6377, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2668.5740, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2651.4885, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2592.8833, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2655.0422, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2659.0791, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2677.2393, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2649.9131, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2669.0969, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2673.1819, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2646.8811, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2677.7144, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2601.6738, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2647.2104, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2640.7561, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2621.3333, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2650.4453, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2628.6816, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2635.1858, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2660.1155, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2618.8010, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2658.5229, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2637.5608, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2633.7976, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2651.4858, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2637.1646, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2633.2183, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2605.3870, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2639.1506, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2653.2039, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2637.4504, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2600.5833, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2639.5852, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2653.3726, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2586.4441, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2645.3345, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2628.0725, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2638.5259, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2611.1887, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2609.4441, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2629.7881, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2609.1814, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2640.3013, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2623.9385, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2581.0454, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2625.1724, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2589.2268, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2619.3196, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2611.0571, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2615.3777, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2620.3979, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2607.9409, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2629.7771, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2587.5789, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2632.4468, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2595.7744, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2623.7078, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2601.1099, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2608.4893, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2606.0942, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2600.3381, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2606.0195, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2602.5017, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2629.4099, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2592.4250, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2584.6863, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2594.3025, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2611.7305, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2563.6958, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2598.6055, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2577.7080, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "15001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# res = False\n",
    "# import time\n",
    "# while (res == False):\n",
    "#     time.sleep(2)\n",
    "#     try:\n",
    "#         res = main()\n",
    "#     except:\n",
    "#         continue\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-cliff",
   "metadata": {},
   "source": [
    "### print('asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval.py --file ~/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-australia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
