{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "heavy-exercise",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'export' ���O�����Υ~���R�O�B�i���檺�{���Χ妸�ɡC\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "convertible-fight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "assured-participation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "legal-responsibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caroline-baking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cordless-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudaSetDevice(0)\n",
    "#dataset transcript要在dataset資好夾調\n",
    "#cuda 在basesolver init調\n",
    "#dataset要在data.py設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "champion-kingston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n",
    "#! python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Author: kun\n",
    "# @Time: 2019-10-29 20:29\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dfs = []\n",
    "alldf =pd.DataFrame()\n",
    "\n",
    "class Para(object):\n",
    "    a=1\n",
    "\n",
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda:0')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
    "    \n",
    "#force_cudnn_initialization()\n",
    "def main():\n",
    "    # For reproducibility, comment these may speed up training\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Arguments\n",
    "#     parser = argparse.ArgumentParser(description='Training E2E asr.')\n",
    "#     parser.add_argument('--config', type=str, help='Path to experiment config.')\n",
    "#     parser.add_argument('--name', default=None, type=str, help='Name for logging.')\n",
    "#     parser.add_argument('--logdir', default='log/', type=str,\n",
    "#                         help='Logging path.', required=False)\n",
    "#     parser.add_argument('--ckpdir', default='ckpt/', type=str,\n",
    "#                         help='Checkpoint path.', required=False)\n",
    "#     parser.add_argument('--outdir', default='result/', type=str,\n",
    "#                         help='Decode output path.', required=False)\n",
    "#     parser.add_argument('--load', default=None, type=str,\n",
    "#                         help='Load pre-trained model (for training only)', required=False)\n",
    "#     parser.add_argument('--seed', default=0, type=int,\n",
    "#                         help='Random seed for reproducable results.', required=False)\n",
    "#     parser.add_argument('--cudnn-ctc', action='store_true',\n",
    "#                         help='Switches CTC backend from torch to cudnn')\n",
    "#     parser.add_argument('--njobs', default=32, type=int,\n",
    "#                         help='Number of threads for dataloader/decoding.', required=False)\n",
    "#     parser.add_argument('--cpu', action='store_true', help='Disable GPU training.')\n",
    "#     parser.add_argument('--no-pin', action='store_true',\n",
    "#                         help='Disable pin-memory for dataloader')\n",
    "#     parser.add_argument('--test', action='store_true', help='Test the model.')\n",
    "#     parser.add_argument('--no-msg', action='store_true', help='Hide all messages.')\n",
    "#     parser.add_argument('--lm', action='store_true',\n",
    "#                         help='Option for training RNNLM.')\n",
    "#     # Following features in development.\n",
    "#     parser.add_argument('--amp', action='store_true', help='Option to enable AMP.')\n",
    "#     parser.add_argument('--reserve-gpu', default=0, type=float,\n",
    "#                         help='Option to reserve GPU ram for training.')\n",
    "#     parser.add_argument('--jit', action='store_true',\n",
    "#                         help='Option for enabling jit in pytorch. (feature in development)')\n",
    "#     ###\n",
    "#     paras = parser.parse_args()\n",
    "    paras = Para()\n",
    "#     paras.config = './config/aishell_asr_example_lstm4atthead1-test.yaml'\n",
    "#     paras.name = None\n",
    "#     paras.logdir = 'log/'\n",
    "#     paras.ckpdir = 'ckpt/'\n",
    "#     paras.outdir = 'result/'\n",
    "#     paras.load = None\n",
    "#     paras.seed = 0\n",
    "#     paras.cudnn_ctc = False\n",
    "#     paras.cpu = False\n",
    "#     paras.no_pin = False\n",
    "#     paras.test = True\n",
    "#     paras.no_msg = False\n",
    "#     paras.lm = False\n",
    "#     paras.amp = False\n",
    "#     paras.reserve_gpu = 0\n",
    "#     paras.jit = False\n",
    "    setattr(paras, 'config', './config/cv11Lu_asr_lstm4atthead_allvocab-whisperclass-test.yaml')\n",
    "    setattr(paras, 'name', None)\n",
    "    setattr(paras, 'logdir', 'log/')\n",
    "    setattr(paras, 'ckpdir', 'ckpt/')\n",
    "    setattr(paras, 'outdir', 'result/')\n",
    "    setattr(paras, 'load', None)\n",
    "    setattr(paras, 'seed', 0)\n",
    "    setattr(paras, 'cudnn_ctc', False)\n",
    "    setattr(paras, 'njobs',0)\n",
    "    setattr(paras, 'cpu', False)\n",
    "    setattr(paras, 'no_pin', False)\n",
    "    setattr(paras, 'test', True)\n",
    "    setattr(paras, 'no_msg', False)\n",
    "    setattr(paras, 'lm', False)\n",
    "    setattr(paras, 'amp', False)\n",
    "    setattr(paras, 'reserve_gpu', 9)\n",
    "    setattr(paras, 'jit', False)\n",
    "    setattr(paras, 'gpu', not paras.cpu)\n",
    "    setattr(paras, 'pin_memory', not paras.no_pin)\n",
    "    setattr(paras, 'verbose', not paras.no_msg)\n",
    "    setattr(paras, 'finetune', False)\n",
    "    setattr(paras, 'binaryClass', True)\n",
    "    force_cudnn_initialization()\n",
    "\n",
    "    config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "    np.random.seed(paras.seed)\n",
    "    torch.manual_seed(paras.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(paras.seed)\n",
    "\n",
    "    # Hack to preserve GPU ram just incase OOM later on server\n",
    "    if paras.gpu and paras.reserve_gpu > 0:\n",
    "        buff = torch.randn(int(paras.reserve_gpu * 1e9 // 4)).cuda()\n",
    "        del buff\n",
    "\n",
    "    if paras.lm:\n",
    "        # Train RNNLM\n",
    "        from train_lm import Solver\n",
    "\n",
    "        mode = 'train'\n",
    "    else:\n",
    "        if paras.test:\n",
    "            # Test ASR\n",
    "            assert paras.load is None, 'Load option is mutually exclusive to --test'\n",
    "            # from test_whisperclass import Solver\n",
    "            from Whisper_Biclass_test import Solver\n",
    "\n",
    "            mode = 'test'\n",
    "        elif paras.finetune:\n",
    "            assert paras.load is not None\n",
    "            from finetune_asr import Solver\n",
    "            mode = 'train'\n",
    "        elif paras.binaryClass:\n",
    "            assert paras.load is not None\n",
    "            from train_binaryclass2_5folds2 import Solver\n",
    "            mode = 'train'\n",
    "        else:\n",
    "            # Train ASR\n",
    "            from train_asr import Solver\n",
    "\n",
    "            mode = 'train'\n",
    "\n",
    "    print(\"\\nUsing {} mode\\n\".format(mode))\n",
    "    for idx in range(5):\n",
    "        paras.config = f'./config/cv11Lu_asr_lstm4atthead_allvocab-biclass-test-5-{idx+1}.yaml'\n",
    "        config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "        config['core']['ckpt'] = f'LAS_ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-{idx+1}_sd0/wav2vec-15k-r-a-final.pth'\n",
    "        solver = Solver(config, paras, mode)\n",
    "\n",
    "        solver.load_data()\n",
    "    #     solver.print_model()\n",
    "        solver.set_model()\n",
    "        names, hyps, txts, ans = solver.exec()\n",
    "        dfs.append(pd.DataFrame(\n",
    "            {'name': names,\n",
    "             'hyps': hyps,\n",
    "             'truth': txts,\n",
    "             'ifcorrect': ans\n",
    "            }))\n",
    "        print(dfs[idx])\n",
    "        print(names)\n",
    "        print(hyps)\n",
    "        print(txts)\n",
    "        print(ans)\n",
    "        del solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metric-twenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using test mode\n",
      "\n",
      "[INFO] Evaluating result of tr. config @ ../LAS_Mandarin_PyTorch-master/config/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-1.yaml\n",
      "[INFO] Evaluating result of tr. ckpt @ LAS_ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-1_sd0/wav2vec-15k-r-a-final.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: data_process, split: ['CTTsegment_remove']\n",
      "Mozillacv11Dataset CTTsegment_remove found wav data: 100\n",
      "text len: 100\n",
      "remove None, then wav data: 99, text len: 99\n",
      "Setup ASR model and optimizer \n",
      "('data_process\\\\CTT5-1-16\\\\15CTT.wav',)   0.5295692086219788   0.0   False\n",
      "('data_process\\\\CTT5-1-16\\\\16CTT.wav',)   0.6331841349601746   1.0   True\n",
      "('data_process\\\\CTT5-1-16\\\\22CTT.wav',)   0.5417379140853882   0.0   False\n",
      "('data_process\\\\CTT5-1-16\\\\28CTT.wav',)   0.6009120941162109   1.0   True\n",
      "('data_process\\\\CTT5-1-16\\\\34CTT.wav',)   0.5316822528839111   0.0   False\n",
      "('data_process\\\\CTT5-1-16\\\\35CTT.wav',)   0.5422372817993164   1.0   True\n",
      "('data_process\\\\CTT5-1-16\\\\40CTT.wav',)   0.6705402731895447   1.0   True\n",
      "('data_process\\\\CTT5-1-16\\\\42CTT.wav',)   0.5422487258911133   0.0   False\n",
      "('data_process\\\\CTT5-1-16\\\\51CTT.wav',)   0.5655835270881653   0.0   False\n",
      "('data_process\\\\CTT5-1-16\\\\53CTT.wav',)   0.5622854828834534   0.0   False\n",
      "('data_process\\\\CTT5-1-16\\\\55CTT.wav',)   0.5773441791534424   0.0   False\n",
      "('data_process\\\\CTT5-1-16\\\\70CTT.wav',)   0.48926129937171936   0.0   True\n",
      "('data_process\\\\CTT5-1-16\\\\83CTT.wav',)   0.5148881077766418   0.0   False\n",
      "('data_process\\\\CTT5-1-16\\\\84CTT.wav',)   0.5440090894699097   0.0   False\n",
      "('data_process\\\\CTT5-1-16\\\\85CTT.wav',)   0.6521697640419006   0.0   False\n",
      "('data_process\\\\CTT5-1-16\\\\97CTT.wav',)   0.4914812445640564   0.0   True\n",
      "('data_process\\\\CTT5-1-16\\\\99CTT.wav',)   0.5284495949745178   0.0   False\n",
      "[INFO] All done !                                                                                          \n",
      "                                name      hyps  truth  ifcorrect\n",
      "0   data_process\\CTT5-1-16\\15CTT.wav  0.529569    0.0      False\n",
      "1   data_process\\CTT5-1-16\\16CTT.wav  0.633184    1.0       True\n",
      "2   data_process\\CTT5-1-16\\22CTT.wav  0.541738    0.0      False\n",
      "3   data_process\\CTT5-1-16\\28CTT.wav  0.600912    1.0       True\n",
      "4   data_process\\CTT5-1-16\\34CTT.wav  0.531682    0.0      False\n",
      "5   data_process\\CTT5-1-16\\35CTT.wav  0.542237    1.0       True\n",
      "6   data_process\\CTT5-1-16\\40CTT.wav  0.670540    1.0       True\n",
      "7   data_process\\CTT5-1-16\\42CTT.wav  0.542249    0.0      False\n",
      "8   data_process\\CTT5-1-16\\51CTT.wav  0.565584    0.0      False\n",
      "9   data_process\\CTT5-1-16\\53CTT.wav  0.562285    0.0      False\n",
      "10  data_process\\CTT5-1-16\\55CTT.wav  0.577344    0.0      False\n",
      "11  data_process\\CTT5-1-16\\70CTT.wav  0.489261    0.0       True\n",
      "12  data_process\\CTT5-1-16\\83CTT.wav  0.514888    0.0      False\n",
      "13  data_process\\CTT5-1-16\\84CTT.wav  0.544009    0.0      False\n",
      "14  data_process\\CTT5-1-16\\85CTT.wav  0.652170    0.0      False\n",
      "15  data_process\\CTT5-1-16\\97CTT.wav  0.491481    0.0       True\n",
      "16  data_process\\CTT5-1-16\\99CTT.wav  0.528450    0.0      False\n",
      "['data_process\\\\CTT5-1-16\\\\15CTT.wav', 'data_process\\\\CTT5-1-16\\\\16CTT.wav', 'data_process\\\\CTT5-1-16\\\\22CTT.wav', 'data_process\\\\CTT5-1-16\\\\28CTT.wav', 'data_process\\\\CTT5-1-16\\\\34CTT.wav', 'data_process\\\\CTT5-1-16\\\\35CTT.wav', 'data_process\\\\CTT5-1-16\\\\40CTT.wav', 'data_process\\\\CTT5-1-16\\\\42CTT.wav', 'data_process\\\\CTT5-1-16\\\\51CTT.wav', 'data_process\\\\CTT5-1-16\\\\53CTT.wav', 'data_process\\\\CTT5-1-16\\\\55CTT.wav', 'data_process\\\\CTT5-1-16\\\\70CTT.wav', 'data_process\\\\CTT5-1-16\\\\83CTT.wav', 'data_process\\\\CTT5-1-16\\\\84CTT.wav', 'data_process\\\\CTT5-1-16\\\\85CTT.wav', 'data_process\\\\CTT5-1-16\\\\97CTT.wav', 'data_process\\\\CTT5-1-16\\\\99CTT.wav']\n",
      "[0.5295692086219788, 0.6331841349601746, 0.5417379140853882, 0.6009120941162109, 0.5316822528839111, 0.5422372817993164, 0.6705402731895447, 0.5422487258911133, 0.5655835270881653, 0.5622854828834534, 0.5773441791534424, 0.48926129937171936, 0.5148881077766418, 0.5440090894699097, 0.6521697640419006, 0.4914812445640564, 0.5284495949745178]\n",
      "[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[False, True, False, True, False, True, True, False, False, False, False, True, False, False, False, True, False]\n",
      "[INFO] Evaluating result of tr. config @ ../LAS_Mandarin_PyTorch-master/config/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-2.yaml\n",
      "[INFO] Evaluating result of tr. ckpt @ LAS_ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-2_sd0/wav2vec-15k-r-a-final.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-2-16']\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "text len: 18\n",
      "remove None, then wav data: 18, text len: 18\n",
      "[VAGDataset] path: data_process, split: ['CTTsegment_remove']\n",
      "Mozillacv11Dataset CTTsegment_remove found wav data: 100\n",
      "text len: 100\n",
      "remove None, then wav data: 99, text len: 99\n",
      "Setup ASR model and optimizer \n",
      "('data_process\\\\CTT5-2-16\\\\11CTT.wav',)   0.5866975784301758   1.0   True\n",
      "('data_process\\\\CTT5-2-16\\\\25CTT.wav',)   0.43155378103256226   1.0   False\n",
      "('data_process\\\\CTT5-2-16\\\\2CTT.wav',)   0.4161677360534668   0.0   True\n",
      "('data_process\\\\CTT5-2-16\\\\37CTT.wav',)   0.4869794249534607   1.0   False\n",
      "('data_process\\\\CTT5-2-16\\\\39CTT.wav',)   0.5239807963371277   1.0   True\n",
      "('data_process\\\\CTT5-2-16\\\\45CTT.wav',)   0.4274613857269287   1.0   False\n",
      "('data_process\\\\CTT5-2-16\\\\46CTT.wav',)   0.47576674818992615   1.0   False\n",
      "('data_process\\\\CTT5-2-16\\\\65CTT.wav',)   0.5228338241577148   1.0   True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naomi\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\wav2vec2\\feature_extraction_wav2vec2.py:92: RuntimeWarning: Mean of empty slice.\n",
      "  normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:length].var() + 1e-7)\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\naomi\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\wav2vec2\\feature_extraction_wav2vec2.py:92: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:length].var() + 1e-7)\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data_process\\\\CTT5-2-16\\\\67CTT.wav',)   0.43182769417762756   1.0   False\n",
      "('data_process\\\\CTT5-2-16\\\\68CTT.wav',)   0.5084540247917175   0.0   False\n",
      "('data_process\\\\CTT5-2-16\\\\71CTT.wav',)   0.38945135474205017   0.0   True\n",
      "('data_process\\\\CTT5-2-16\\\\74CTT.wav',)   0.401603102684021   0.0   True\n",
      "('data_process\\\\CTT5-2-16\\\\76CTT.wav',)   0.3855699598789215   0.0   True\n",
      "('data_process\\\\CTT5-2-16\\\\77CTT.wav',)   0.4168136417865753   0.0   True\n",
      "('data_process\\\\CTT5-2-16\\\\78CTT.wav',)   0.4424956738948822   0.0   True\n",
      "('data_process\\\\CTT5-2-16\\\\80CTT.wav',)   0.3987681567668915   0.0   True\n",
      "('data_process\\\\CTT5-2-16\\\\91CTT.wav',)   0.40355169773101807   0.0   True\n",
      "('data_process\\\\CTT5-2-16\\\\94CTT.wav',)   0.44257044792175293   0.0   True\n",
      "[INFO] All done !                                                                                          \n",
      "                                name      hyps  truth  ifcorrect\n",
      "0   data_process\\CTT5-2-16\\11CTT.wav  0.586698    1.0       True\n",
      "1   data_process\\CTT5-2-16\\25CTT.wav  0.431554    1.0      False\n",
      "2    data_process\\CTT5-2-16\\2CTT.wav  0.416168    0.0       True\n",
      "3   data_process\\CTT5-2-16\\37CTT.wav  0.486979    1.0      False\n",
      "4   data_process\\CTT5-2-16\\39CTT.wav  0.523981    1.0       True\n",
      "5   data_process\\CTT5-2-16\\45CTT.wav  0.427461    1.0      False\n",
      "6   data_process\\CTT5-2-16\\46CTT.wav  0.475767    1.0      False\n",
      "7   data_process\\CTT5-2-16\\65CTT.wav  0.522834    1.0       True\n",
      "8   data_process\\CTT5-2-16\\67CTT.wav  0.431828    1.0      False\n",
      "9   data_process\\CTT5-2-16\\68CTT.wav  0.508454    0.0      False\n",
      "10  data_process\\CTT5-2-16\\71CTT.wav  0.389451    0.0       True\n",
      "11  data_process\\CTT5-2-16\\74CTT.wav  0.401603    0.0       True\n",
      "12  data_process\\CTT5-2-16\\76CTT.wav  0.385570    0.0       True\n",
      "13  data_process\\CTT5-2-16\\77CTT.wav  0.416814    0.0       True\n",
      "14  data_process\\CTT5-2-16\\78CTT.wav  0.442496    0.0       True\n",
      "15  data_process\\CTT5-2-16\\80CTT.wav  0.398768    0.0       True\n",
      "16  data_process\\CTT5-2-16\\91CTT.wav  0.403552    0.0       True\n",
      "17  data_process\\CTT5-2-16\\94CTT.wav  0.442570    0.0       True\n",
      "['data_process\\\\CTT5-2-16\\\\11CTT.wav', 'data_process\\\\CTT5-2-16\\\\25CTT.wav', 'data_process\\\\CTT5-2-16\\\\2CTT.wav', 'data_process\\\\CTT5-2-16\\\\37CTT.wav', 'data_process\\\\CTT5-2-16\\\\39CTT.wav', 'data_process\\\\CTT5-2-16\\\\45CTT.wav', 'data_process\\\\CTT5-2-16\\\\46CTT.wav', 'data_process\\\\CTT5-2-16\\\\65CTT.wav', 'data_process\\\\CTT5-2-16\\\\67CTT.wav', 'data_process\\\\CTT5-2-16\\\\68CTT.wav', 'data_process\\\\CTT5-2-16\\\\71CTT.wav', 'data_process\\\\CTT5-2-16\\\\74CTT.wav', 'data_process\\\\CTT5-2-16\\\\76CTT.wav', 'data_process\\\\CTT5-2-16\\\\77CTT.wav', 'data_process\\\\CTT5-2-16\\\\78CTT.wav', 'data_process\\\\CTT5-2-16\\\\80CTT.wav', 'data_process\\\\CTT5-2-16\\\\91CTT.wav', 'data_process\\\\CTT5-2-16\\\\94CTT.wav']\n",
      "[0.5866975784301758, 0.43155378103256226, 0.4161677360534668, 0.4869794249534607, 0.5239807963371277, 0.4274613857269287, 0.47576674818992615, 0.5228338241577148, 0.43182769417762756, 0.5084540247917175, 0.38945135474205017, 0.401603102684021, 0.3855699598789215, 0.4168136417865753, 0.4424956738948822, 0.3987681567668915, 0.40355169773101807, 0.44257044792175293]\n",
      "[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[True, False, True, False, True, False, False, True, False, False, True, True, True, True, True, True, True, True]\n",
      "[INFO] Evaluating result of tr. config @ ../LAS_Mandarin_PyTorch-master/config/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-3.yaml\n",
      "[INFO] Evaluating result of tr. ckpt @ LAS_ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-3_sd0/wav2vec-15k-r-a-final.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-3-16']\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: data_process, split: ['CTTsegment_remove']\n",
      "Mozillacv11Dataset CTTsegment_remove found wav data: 100\n",
      "text len: 100\n",
      "remove None, then wav data: 99, text len: 99\n",
      "Setup ASR model and optimizer \n",
      "('data_process\\\\CTT5-3-16\\\\18CTT.wav',)   0.4995405077934265   1.0   False\n",
      "('data_process\\\\CTT5-3-16\\\\1CTT.wav',)   0.4677567780017853   0.0   True\n",
      "('data_process\\\\CTT5-3-16\\\\20CTT.wav',)   0.5639072060585022   1.0   True\n",
      "('data_process\\\\CTT5-3-16\\\\30CTT.wav',)   0.49152907729148865   0.0   True\n",
      "('data_process\\\\CTT5-3-16\\\\32CTT.wav',)   0.5001237392425537   1.0   True\n",
      "('data_process\\\\CTT5-3-16\\\\38CTT.wav',)   0.5972130298614502   1.0   True\n",
      "('data_process\\\\CTT5-3-16\\\\3CTT.wav',)   0.4998966157436371   0.0   True\n",
      "('data_process\\\\CTT5-3-16\\\\43CTT.wav',)   0.4938359260559082   0.0   True\n",
      "('data_process\\\\CTT5-3-16\\\\52CTT.wav',)   0.5212187170982361   0.0   False\n",
      "('data_process\\\\CTT5-3-16\\\\57CTT.wav',)   0.49139708280563354   1.0   False\n",
      "('data_process\\\\CTT5-3-16\\\\58CTT.wav',)   0.5803796648979187   1.0   True\n",
      "('data_process\\\\CTT5-3-16\\\\75CTT.wav',)   0.47764843702316284   0.0   True\n",
      "('data_process\\\\CTT5-3-16\\\\81CTT.wav',)   0.5044451951980591   0.0   False\n",
      "('data_process\\\\CTT5-3-16\\\\82CTT.wav',)   0.49903449416160583   0.0   True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naomi\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\wav2vec2\\feature_extraction_wav2vec2.py:92: RuntimeWarning: Mean of empty slice.\n",
      "  normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:length].var() + 1e-7)\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\naomi\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\wav2vec2\\feature_extraction_wav2vec2.py:92: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:length].var() + 1e-7)\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data_process\\\\CTT5-3-16\\\\87CTT.wav',)   0.5566044449806213   0.0   False\n",
      "('data_process\\\\CTT5-3-16\\\\93CTT.wav',)   0.5048454999923706   0.0   False\n",
      "('data_process\\\\CTT5-3-16\\\\98CTT.wav',)   0.4892975986003876   0.0   True\n",
      "[INFO] All done !                                                                                          \n",
      "                                name      hyps  truth  ifcorrect\n",
      "0   data_process\\CTT5-3-16\\18CTT.wav  0.499541    1.0      False\n",
      "1    data_process\\CTT5-3-16\\1CTT.wav  0.467757    0.0       True\n",
      "2   data_process\\CTT5-3-16\\20CTT.wav  0.563907    1.0       True\n",
      "3   data_process\\CTT5-3-16\\30CTT.wav  0.491529    0.0       True\n",
      "4   data_process\\CTT5-3-16\\32CTT.wav  0.500124    1.0       True\n",
      "5   data_process\\CTT5-3-16\\38CTT.wav  0.597213    1.0       True\n",
      "6    data_process\\CTT5-3-16\\3CTT.wav  0.499897    0.0       True\n",
      "7   data_process\\CTT5-3-16\\43CTT.wav  0.493836    0.0       True\n",
      "8   data_process\\CTT5-3-16\\52CTT.wav  0.521219    0.0      False\n",
      "9   data_process\\CTT5-3-16\\57CTT.wav  0.491397    1.0      False\n",
      "10  data_process\\CTT5-3-16\\58CTT.wav  0.580380    1.0       True\n",
      "11  data_process\\CTT5-3-16\\75CTT.wav  0.477648    0.0       True\n",
      "12  data_process\\CTT5-3-16\\81CTT.wav  0.504445    0.0      False\n",
      "13  data_process\\CTT5-3-16\\82CTT.wav  0.499034    0.0       True\n",
      "14  data_process\\CTT5-3-16\\87CTT.wav  0.556604    0.0      False\n",
      "15  data_process\\CTT5-3-16\\93CTT.wav  0.504845    0.0      False\n",
      "16  data_process\\CTT5-3-16\\98CTT.wav  0.489298    0.0       True\n",
      "['data_process\\\\CTT5-3-16\\\\18CTT.wav', 'data_process\\\\CTT5-3-16\\\\1CTT.wav', 'data_process\\\\CTT5-3-16\\\\20CTT.wav', 'data_process\\\\CTT5-3-16\\\\30CTT.wav', 'data_process\\\\CTT5-3-16\\\\32CTT.wav', 'data_process\\\\CTT5-3-16\\\\38CTT.wav', 'data_process\\\\CTT5-3-16\\\\3CTT.wav', 'data_process\\\\CTT5-3-16\\\\43CTT.wav', 'data_process\\\\CTT5-3-16\\\\52CTT.wav', 'data_process\\\\CTT5-3-16\\\\57CTT.wav', 'data_process\\\\CTT5-3-16\\\\58CTT.wav', 'data_process\\\\CTT5-3-16\\\\75CTT.wav', 'data_process\\\\CTT5-3-16\\\\81CTT.wav', 'data_process\\\\CTT5-3-16\\\\82CTT.wav', 'data_process\\\\CTT5-3-16\\\\87CTT.wav', 'data_process\\\\CTT5-3-16\\\\93CTT.wav', 'data_process\\\\CTT5-3-16\\\\98CTT.wav']\n",
      "[0.4995405077934265, 0.4677567780017853, 0.5639072060585022, 0.49152907729148865, 0.5001237392425537, 0.5972130298614502, 0.4998966157436371, 0.4938359260559082, 0.5212187170982361, 0.49139708280563354, 0.5803796648979187, 0.47764843702316284, 0.5044451951980591, 0.49903449416160583, 0.5566044449806213, 0.5048454999923706, 0.4892975986003876]\n",
      "[1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[False, True, True, True, True, True, True, True, False, False, True, True, False, True, False, False, True]\n",
      "[INFO] Evaluating result of tr. config @ ../LAS_Mandarin_PyTorch-master/config/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-4.yaml\n",
      "[INFO] Evaluating result of tr. ckpt @ LAS_ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-4_sd0/wav2vec-15k-r-a-final.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: data_process, split: ['CTTsegment_remove']\n",
      "Mozillacv11Dataset CTTsegment_remove found wav data: 100\n",
      "text len: 100\n",
      "remove None, then wav data: 99, text len: 99\n",
      "Setup ASR model and optimizer \n",
      "('data_process\\\\CTT5-4-16\\\\100CTT.wav',)   0.4967343807220459   0.0   True\n",
      "('data_process\\\\CTT5-4-16\\\\12CTT.wav',)   0.5643101930618286   1.0   True\n",
      "('data_process\\\\CTT5-4-16\\\\17CTT.wav',)   0.6593894958496094   1.0   True\n",
      "('data_process\\\\CTT5-4-16\\\\21CTT.wav',)   0.4887368083000183   0.0   True\n",
      "('data_process\\\\CTT5-4-16\\\\29CTT.wav',)   0.5266346335411072   0.0   False\n",
      "('data_process\\\\CTT5-4-16\\\\4CTT.wav',)   0.5065240263938904   1.0   True\n",
      "('data_process\\\\CTT5-4-16\\\\54CTT.wav',)   0.4744000732898712   0.0   True\n",
      "('data_process\\\\CTT5-4-16\\\\56CTT.wav',)   0.4855041801929474   0.0   True\n",
      "('data_process\\\\CTT5-4-16\\\\63CTT.wav',)   0.48254629969596863   1.0   False\n",
      "('data_process\\\\CTT5-4-16\\\\6CTT.wav',)   0.4887223243713379   0.0   True\n",
      "('data_process\\\\CTT5-4-16\\\\7CTT.wav',)   0.48308953642845154   0.0   True\n",
      "('data_process\\\\CTT5-4-16\\\\86CTT.wav',)   0.530518651008606   0.0   False\n",
      "('data_process\\\\CTT5-4-16\\\\88CTT.wav',)   0.4820404052734375   0.0   True\n",
      "('data_process\\\\CTT5-4-16\\\\89CTT.wav',)   0.4745695888996124   0.0   True\n",
      "('data_process\\\\CTT5-4-16\\\\92CTT.wav',)   0.4566064774990082   0.0   True\n",
      "('data_process\\\\CTT5-4-16\\\\96CTT.wav',)   0.4840613007545471   0.0   True\n",
      "('data_process\\\\CTT5-4-16\\\\9CTT.wav',)   0.5399928689002991   1.0   True\n",
      "[INFO] All done !                                                                                          \n",
      "                                 name      hyps  truth  ifcorrect\n",
      "0   data_process\\CTT5-4-16\\100CTT.wav  0.496734    0.0       True\n",
      "1    data_process\\CTT5-4-16\\12CTT.wav  0.564310    1.0       True\n",
      "2    data_process\\CTT5-4-16\\17CTT.wav  0.659389    1.0       True\n",
      "3    data_process\\CTT5-4-16\\21CTT.wav  0.488737    0.0       True\n",
      "4    data_process\\CTT5-4-16\\29CTT.wav  0.526635    0.0      False\n",
      "5     data_process\\CTT5-4-16\\4CTT.wav  0.506524    1.0       True\n",
      "6    data_process\\CTT5-4-16\\54CTT.wav  0.474400    0.0       True\n",
      "7    data_process\\CTT5-4-16\\56CTT.wav  0.485504    0.0       True\n",
      "8    data_process\\CTT5-4-16\\63CTT.wav  0.482546    1.0      False\n",
      "9     data_process\\CTT5-4-16\\6CTT.wav  0.488722    0.0       True\n",
      "10    data_process\\CTT5-4-16\\7CTT.wav  0.483090    0.0       True\n",
      "11   data_process\\CTT5-4-16\\86CTT.wav  0.530519    0.0      False\n",
      "12   data_process\\CTT5-4-16\\88CTT.wav  0.482040    0.0       True\n",
      "13   data_process\\CTT5-4-16\\89CTT.wav  0.474570    0.0       True\n",
      "14   data_process\\CTT5-4-16\\92CTT.wav  0.456606    0.0       True\n",
      "15   data_process\\CTT5-4-16\\96CTT.wav  0.484061    0.0       True\n",
      "16    data_process\\CTT5-4-16\\9CTT.wav  0.539993    1.0       True\n",
      "['data_process\\\\CTT5-4-16\\\\100CTT.wav', 'data_process\\\\CTT5-4-16\\\\12CTT.wav', 'data_process\\\\CTT5-4-16\\\\17CTT.wav', 'data_process\\\\CTT5-4-16\\\\21CTT.wav', 'data_process\\\\CTT5-4-16\\\\29CTT.wav', 'data_process\\\\CTT5-4-16\\\\4CTT.wav', 'data_process\\\\CTT5-4-16\\\\54CTT.wav', 'data_process\\\\CTT5-4-16\\\\56CTT.wav', 'data_process\\\\CTT5-4-16\\\\63CTT.wav', 'data_process\\\\CTT5-4-16\\\\6CTT.wav', 'data_process\\\\CTT5-4-16\\\\7CTT.wav', 'data_process\\\\CTT5-4-16\\\\86CTT.wav', 'data_process\\\\CTT5-4-16\\\\88CTT.wav', 'data_process\\\\CTT5-4-16\\\\89CTT.wav', 'data_process\\\\CTT5-4-16\\\\92CTT.wav', 'data_process\\\\CTT5-4-16\\\\96CTT.wav', 'data_process\\\\CTT5-4-16\\\\9CTT.wav']\n",
      "[0.4967343807220459, 0.5643101930618286, 0.6593894958496094, 0.4887368083000183, 0.5266346335411072, 0.5065240263938904, 0.4744000732898712, 0.4855041801929474, 0.48254629969596863, 0.4887223243713379, 0.48308953642845154, 0.530518651008606, 0.4820404052734375, 0.4745695888996124, 0.4566064774990082, 0.4840613007545471, 0.5399928689002991]\n",
      "[0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "[True, True, True, True, False, True, True, True, False, True, True, False, True, True, True, True, True]\n",
      "[INFO] Evaluating result of tr. config @ ../LAS_Mandarin_PyTorch-master/config/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-5.yaml\n",
      "[INFO] Evaluating result of tr. ckpt @ LAS_ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-5_sd0/wav2vec-15k-r-a-final.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at sanchit-gandhi/whisper-large-v2-ft-ls-960h and are newly initialized: ['model.classifier.bias', 'model.classifier.weight', 'model.projector.bias', 'model.projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-5-16']\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: data_process, split: ['CTTsegment_remove']\n",
      "Mozillacv11Dataset CTTsegment_remove found wav data: 100\n",
      "text len: 100\n",
      "remove None, then wav data: 99, text len: 99\n",
      "Setup ASR model and optimizer \n",
      "('data_process\\\\CTT5-5-16\\\\10CTT.wav',)   0.600223958492279   1.0   True\n",
      "('data_process\\\\CTT5-5-16\\\\13CTT.wav',)   0.518591046333313   0.0   False\n",
      "('data_process\\\\CTT5-5-16\\\\14CTT.wav',)   0.4763298034667969   0.0   True\n",
      "('data_process\\\\CTT5-5-16\\\\24CTT.wav',)   0.5320809483528137   1.0   True\n",
      "('data_process\\\\CTT5-5-16\\\\31CTT.wav',)   0.5997482538223267   1.0   True\n",
      "('data_process\\\\CTT5-5-16\\\\44CTT.wav',)   0.5340210199356079   0.0   False\n",
      "('data_process\\\\CTT5-5-16\\\\47CTT.wav',)   0.5046550035476685   0.0   False\n",
      "('data_process\\\\CTT5-5-16\\\\50CTT.wav',)   0.4853803515434265   0.0   True\n",
      "('data_process\\\\CTT5-5-16\\\\5CTT.wav',)   0.5477676391601562   1.0   True\n",
      "('data_process\\\\CTT5-5-16\\\\64CTT.wav',)   0.5902838706970215   1.0   True\n",
      "('data_process\\\\CTT5-5-16\\\\69CTT.wav',)   0.5291058421134949   0.0   False\n",
      "('data_process\\\\CTT5-5-16\\\\72CTT.wav',)   0.5512875318527222   0.0   False\n",
      "('data_process\\\\CTT5-5-16\\\\73CTT.wav',)   0.47151950001716614   0.0   True\n",
      "('data_process\\\\CTT5-5-16\\\\79CTT.wav',)   0.49928659200668335   0.0   True\n",
      "('data_process\\\\CTT5-5-16\\\\8CTT.wav',)   0.545281708240509   0.0   False\n",
      "('data_process\\\\CTT5-5-16\\\\90CTT.wav',)   0.5481990575790405   0.0   False\n",
      "('data_process\\\\CTT5-5-16\\\\95CTT.wav',)   0.5724031925201416   0.0   False\n",
      "[INFO] All done !                                                                                          \n",
      "                                name      hyps  truth  ifcorrect\n",
      "0   data_process\\CTT5-5-16\\10CTT.wav  0.600224    1.0       True\n",
      "1   data_process\\CTT5-5-16\\13CTT.wav  0.518591    0.0      False\n",
      "2   data_process\\CTT5-5-16\\14CTT.wav  0.476330    0.0       True\n",
      "3   data_process\\CTT5-5-16\\24CTT.wav  0.532081    1.0       True\n",
      "4   data_process\\CTT5-5-16\\31CTT.wav  0.599748    1.0       True\n",
      "5   data_process\\CTT5-5-16\\44CTT.wav  0.534021    0.0      False\n",
      "6   data_process\\CTT5-5-16\\47CTT.wav  0.504655    0.0      False\n",
      "7   data_process\\CTT5-5-16\\50CTT.wav  0.485380    0.0       True\n",
      "8    data_process\\CTT5-5-16\\5CTT.wav  0.547768    1.0       True\n",
      "9   data_process\\CTT5-5-16\\64CTT.wav  0.590284    1.0       True\n",
      "10  data_process\\CTT5-5-16\\69CTT.wav  0.529106    0.0      False\n",
      "11  data_process\\CTT5-5-16\\72CTT.wav  0.551288    0.0      False\n",
      "12  data_process\\CTT5-5-16\\73CTT.wav  0.471520    0.0       True\n",
      "13  data_process\\CTT5-5-16\\79CTT.wav  0.499287    0.0       True\n",
      "14   data_process\\CTT5-5-16\\8CTT.wav  0.545282    0.0      False\n",
      "15  data_process\\CTT5-5-16\\90CTT.wav  0.548199    0.0      False\n",
      "16  data_process\\CTT5-5-16\\95CTT.wav  0.572403    0.0      False\n",
      "['data_process\\\\CTT5-5-16\\\\10CTT.wav', 'data_process\\\\CTT5-5-16\\\\13CTT.wav', 'data_process\\\\CTT5-5-16\\\\14CTT.wav', 'data_process\\\\CTT5-5-16\\\\24CTT.wav', 'data_process\\\\CTT5-5-16\\\\31CTT.wav', 'data_process\\\\CTT5-5-16\\\\44CTT.wav', 'data_process\\\\CTT5-5-16\\\\47CTT.wav', 'data_process\\\\CTT5-5-16\\\\50CTT.wav', 'data_process\\\\CTT5-5-16\\\\5CTT.wav', 'data_process\\\\CTT5-5-16\\\\64CTT.wav', 'data_process\\\\CTT5-5-16\\\\69CTT.wav', 'data_process\\\\CTT5-5-16\\\\72CTT.wav', 'data_process\\\\CTT5-5-16\\\\73CTT.wav', 'data_process\\\\CTT5-5-16\\\\79CTT.wav', 'data_process\\\\CTT5-5-16\\\\8CTT.wav', 'data_process\\\\CTT5-5-16\\\\90CTT.wav', 'data_process\\\\CTT5-5-16\\\\95CTT.wav']\n",
      "[0.600223958492279, 0.518591046333313, 0.4763298034667969, 0.5320809483528137, 0.5997482538223267, 0.5340210199356079, 0.5046550035476685, 0.4853803515434265, 0.5477676391601562, 0.5902838706970215, 0.5291058421134949, 0.5512875318527222, 0.47151950001716614, 0.49928659200668335, 0.545281708240509, 0.5481990575790405, 0.5724031925201416]\n",
      "[1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[True, False, True, True, True, False, False, True, True, True, False, False, True, True, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exact-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, df in enumerate(dfs):\n",
    "    alldf = pd.concat([alldf, df])\n",
    "    # df.to_csv(f'./biclass_result/whisper-WhisperForAudioClassification-v3-10k-{idx+1}_2', index=False)\n",
    "alldf.to_csv(f'./biclass_result/wav2vec-15k-r-a-final.csv', index=False)\n",
    "# whisper-v2-10k-{idx+1}_with_id_2.csv\n",
    "# whisper-v2-15k_with_id_2.csv\n",
    "# whisper-WhisperForAudioClassification-v3-10k-{idx+1}_2\n",
    "# whisper-WhisperForAudioClassification-v3-10k_2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-marble",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"eval.py\", line 33, in <module>\n",
      "    result['hyp_char_cnt'] = result.apply(lambda x: len(x.hyp), axis=1)\n",
      "  File \"c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\pandas\\core\\frame.py\", line 9423, in apply\n",
      "    return op.apply().__finalize__(self, method=\"apply\")\n",
      "  File \"c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\pandas\\core\\apply.py\", line 678, in apply\n",
      "    return self.apply_standard()\n",
      "  File \"c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\pandas\\core\\apply.py\", line 798, in apply_standard\n",
      "    results, res_index = self.apply_series_generator()\n",
      "  File \"c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\pandas\\core\\apply.py\", line 814, in apply_series_generator\n",
      "    results[i] = self.f(v)\n",
      "  File \"eval.py\", line 33, in <lambda>\n",
      "    result['hyp_char_cnt'] = result.apply(lambda x: len(x.hyp), axis=1)\n",
      "  File \"c:\\Users\\naomi\\anaconda3\\envs\\230917\\lib\\site-packages\\pandas\\core\\generic.py\", line 5989, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "AttributeError: 'Series' object has no attribute 'hyp'\n"
     ]
    }
   ],
   "source": [
    "!python eval.py --file ~/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-upset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-patient       0.80      0.92      0.86        13\n",
      "     patient       0.83      0.62      0.71         8\n",
      "\n",
      "    accuracy                           0.81        21\n",
      "   macro avg       0.82      0.77      0.79        21\n",
      "weighted avg       0.81      0.81      0.80        21\n",
      "\n",
      "sensitivity:  0.625\n",
      "specificity:  0.9230769230769231\n",
      "AUC:  0.5288461538461539\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "y_true = [0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0] \n",
    "y_pred = [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
    "target_names = ['non-patient', 'patient']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "print('sensitivity: ',tp / (fn+tp))\n",
    "print('specificity: ',tn / (fp+tn))\n",
    "pred = np.array([0.0443, 0.0140, 0.3337, 0.0560, 0.0385, 0.5118, 0.1961, 0.1746, 0.0268, 0.2939, 0.0169, 0.6525, 0.3661, 0.1010, 0.0077, 0.0994, 0.2264, 0.6143, 0.0750, 0.4048, 0.2368])\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np.array(y_true), np.array(pred), pos_label=1)\n",
    "print('AUC: ',metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-training",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
