{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "governing-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "boolean-macedonia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "endangered-terrace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "direct-battlefield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "possible-integration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "outstanding-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudaSetDevice(0)\n",
    "#dataset transcript要在dataset資好夾調\n",
    "#cuda 在basesolver init調\n",
    "#dataset要在data.py設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "major-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "# # os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "\n",
    "# torch.cuda.set_device(0)\n",
    "# print(torch.cuda.current_device())\n",
    "\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "class Para(object):\n",
    "    a=1\n",
    "\n",
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda:0')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
    "    \n",
    "#force_cudnn_initialization()\n",
    "def main():\n",
    "    # For reproducibility, comment these may speed up training\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Arguments\n",
    "#     parser = argparse.ArgumentParser(description='Training E2E asr.')\n",
    "#     parser.add_argument('--config', type=str, help='Path to experiment config.')\n",
    "#     parser.add_argument('--name', default=None, type=str, help='Name for logging.')\n",
    "#     parser.add_argument('--logdir', default='log/', type=str,\n",
    "#                         help='Logging path.', required=False)\n",
    "#     parser.add_argument('--ckpdir', default='ckpt/', type=str,\n",
    "#                         help='Checkpoint path.', required=False)\n",
    "#     parser.add_argument('--outdir', default='result/', type=str,\n",
    "#                         help='Decode output path.', required=False)\n",
    "#     parser.add_argument('--load', default=None, type=str,\n",
    "#                         help='Load pre-trained model (for training only)', required=False)\n",
    "#     parser.add_argument('--seed', default=0, type=int,\n",
    "#                         help='Random seed for reproducable results.', required=False)\n",
    "#     parser.add_argument('--cudnn-ctc', action='store_true',\n",
    "#                         help='Switches CTC backend from torch to cudnn')\n",
    "#     parser.add_argument('--njobs', default=32, type=int,\n",
    "#                         help='Number of threads for dataloader/decoding.', required=False)\n",
    "#     parser.add_argument('--cpu', action='store_true', help='Disable GPU training.')\n",
    "#     parser.add_argument('--no-pin', action='store_true',\n",
    "#                         help='Disable pin-memory for dataloader')\n",
    "#     parser.add_argument('--test', action='store_true', help='Test the model.')\n",
    "#     parser.add_argument('--no-msg', action='store_true', help='Hide all messages.')\n",
    "#     parser.add_argument('--lm', action='store_true',\n",
    "#                         help='Option for training RNNLM.')\n",
    "#     # Following features in development.\n",
    "#     parser.add_argument('--amp', action='store_true', help='Option to enable AMP.')\n",
    "#     parser.add_argument('--reserve-gpu', default=0, type=float,\n",
    "#                         help='Option to reserve GPU ram for training.')\n",
    "#     parser.add_argument('--jit', action='store_true',\n",
    "#                         help='Option for enabling jit in pytorch. (feature in development)')\n",
    "#     ###\n",
    "#     paras = parser.parse_args()\n",
    "    paras = Para()\n",
    "#     paras.config = './config/aishell_asr_example_lstm4atthead1-test.yaml'\n",
    "#     paras.name = None\n",
    "#     paras.logdir = 'log/'\n",
    "#     paras.ckpdir = 'ckpt/'\n",
    "#     paras.outdir = 'result/'\n",
    "#     paras.load = None\n",
    "#     paras.seed = 0\n",
    "#     paras.cudnn_ctc = False\n",
    "#     paras.cpu = False\n",
    "#     paras.no_pin = False\n",
    "#     paras.test = True\n",
    "#     paras.no_msg = False\n",
    "#     paras.lm = False\n",
    "#     paras.amp = False\n",
    "#     paras.reserve_gpu = 0\n",
    "#     paras.jit = False\n",
    "    setattr(paras, 'config', './config/cv11Lu_asr_lstm4atthead_allvocab-whisperclass.yaml')\n",
    "    setattr(paras, 'name', None)\n",
    "    setattr(paras, 'logdir', 'log/')\n",
    "    setattr(paras, 'ckpdir', 'LAS_ckpt/')\n",
    "    setattr(paras, 'outdir', 'result/')\n",
    "    setattr(paras, 'load', None)\n",
    "    setattr(paras, 'seed', 0)\n",
    "    setattr(paras, 'cudnn_ctc', False)\n",
    "    setattr(paras, 'njobs',0)\n",
    "    setattr(paras, 'cpu', False)\n",
    "    setattr(paras, 'no_pin', False)\n",
    "    setattr(paras, 'test', False)\n",
    "    setattr(paras, 'no_msg', False)\n",
    "    setattr(paras, 'lm', False)\n",
    "    setattr(paras, 'amp', False)\n",
    "    setattr(paras, 'reserve_gpu', 9)\n",
    "    setattr(paras, 'jit', False)\n",
    "    setattr(paras, 'gpu', not paras.cpu)\n",
    "    setattr(paras, 'pin_memory', not paras.no_pin)\n",
    "    setattr(paras, 'verbose', not paras.no_msg)\n",
    "    setattr(paras, 'finetune', False)\n",
    "    setattr(paras, 'binaryClass', True)\n",
    "#     force_cudnn_initialization()\n",
    "    print(torch.multiprocessing.get_start_method())\n",
    "#     torch.multiprocessing.set_start_method('spawn',force=True)\n",
    "    config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "    np.random.seed(paras.seed)\n",
    "    torch.manual_seed(paras.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(paras.seed)\n",
    "\n",
    "    # Hack to preserve GPU ram just incase OOM later on server\n",
    "    if paras.gpu and paras.reserve_gpu > 0:\n",
    "        buff = torch.randn(int(paras.reserve_gpu * 1e9 // 4)).cuda()\n",
    "        del buff\n",
    "\n",
    "    if paras.lm:\n",
    "        # Train RNNLM\n",
    "        from train_lm import Solver\n",
    "\n",
    "        mode = 'train'\n",
    "    else:\n",
    "        if paras.test:\n",
    "            # Test ASR\n",
    "            assert paras.load is None, 'Load option is mutually exclusive to --test'\n",
    "            from test_asr import Solver\n",
    "\n",
    "            mode = 'test'\n",
    "        elif paras.finetune:\n",
    "            assert paras.load is not None\n",
    "            from finetune_asr import Solver\n",
    "            mode = 'train'\n",
    "        elif paras.binaryClass:\n",
    "            # assert paras.load is not None\n",
    "            from Whisper_MMSE_bert_train import Solver\n",
    "            mode = 'train'\n",
    "        else:\n",
    "            # Train ASR\n",
    "            from train_asr import Solver\n",
    "\n",
    "            mode = 'train'\n",
    "\n",
    "    print(\"\\nUsing {} mode\\n\".format(mode))\n",
    "\n",
    "    for idx in range(0,5):\n",
    "        paras.config = f'config/cv11Lu_asr_lstm4atthead_allvocab-MMSE-5fold-{idx+1}.yaml'#latest7k_4lstm.pth\n",
    "#         setattr(paras, 'load', f'./ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-{idx+1}_sd0/latest13knew_4LSTM.pth')\n",
    "        #要用vag01要改load_ckpt\n",
    "        config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "        solver = Solver(config, paras, mode)\n",
    "\n",
    "\n",
    "        solver.load_data()\n",
    "#         solver.print_model()\n",
    "        solver.set_model()\n",
    "        solver.exec()\n",
    "        del solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "consecutive-antique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spawn\n",
      "\n",
      "Using train mode\n",
      "\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-MMSE-5fold-1_sd0                                       \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetMMSE as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: data_process, split: ['CTT5-5-16', 'CTT5-2-16', 'CTT5-3-16', 'CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 69\n",
      "remove None, then wav data: 68, text len: 68\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 68\n",
      "total_loss tensor(48042.2461, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(39255.7148, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(30711.5137, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(22914.0781, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(16278.2979, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(10802.7129, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(7172.7852, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(4560.8872, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3010.2256, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2348.1157, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2146.8572, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2191.7949, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2447.2114, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2447.1541, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2431.3877, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2373.4651, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2418.6416, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2369.3188, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2396.4583, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2331.6477, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2346.2729, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2288.2815, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2309.5444, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2273.6885, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2285.1047, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2261.1116, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2223.8679, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2203.6372, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2204.3650, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2176.5544, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2181.6440, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2170.1501, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2182.3005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2128.6375, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2110.2148, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2123.6606, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2095.5122, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2091.0962, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2061.7947, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2073.0283, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2074.0554, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2029.1941, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2001.0453, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2003.6940, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2017.0138, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1997.0181, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1992.5005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1961.5625, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1928.9808, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1987.5204, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1921.5914, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1933.2997, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1932.2073, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1896.4302, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1885.7905, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1893.0244, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1877.7021, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1869.9518, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1872.1027, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1840.4230, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1839.3809, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1807.2300, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1858.3774, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1802.3641, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1791.5286, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1795.2794, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1782.0975, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1776.7354, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1740.0320, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1782.3152, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1747.2860, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1710.8036, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1736.1028, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1695.5697, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1694.4620, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1710.3477, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1681.7297, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1676.0076, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1684.0408, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1674.4673, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1686.7308, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1670.9291, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1629.3557, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1626.5913, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1666.3875, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1600.2158, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1646.9893, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1603.8933, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1623.0857, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1599.4698, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1604.1281, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1595.5361, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1574.1525, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1603.0598, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1585.3810, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1578.0829, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1582.6703, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1558.2878, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1579.3627, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1565.1804, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1557.6868, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1556.5914, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1528.5638, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1569.2662, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1533.2848, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1533.3953, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1521.7726, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1518.3385, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1525.4139, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1518.5673, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1497.6208, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1509.1223, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1506.2991, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1498.3373, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1485.8274, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1495.0837, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1493.7915, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1451.4186, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1475.5702, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1473.3882, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1476.4083, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1460.4633, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1459.0675, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1460.5101, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1453.3485, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1448.5648, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1443.6549, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1457.1050, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1449.0376, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1447.8546, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1422.5094, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1434.0159, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1441.3986, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1422.2671, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1420.4648, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1413.9917, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1383.9753, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1406.2822, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1417.9353, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1393.5635, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1406.0138, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1400.2268, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1411.4060, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1382.6316, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1374.1802, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1384.3195, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1376.4791, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1381.8643, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1373.1290, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1369.2493, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1376.3253, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1375.0581, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1366.4017, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1354.5967, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1358.9119, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1348.8794, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1349.6117, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1352.4973, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1346.3011, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1351.8613, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1344.9901, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1335.9950, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1339.5321, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1335.8198, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1334.0176, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1328.3910, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1325.4451, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1322.3171, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1310.5653, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1325.0295, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1324.9603, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1322.1163, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1308.8619, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1291.8215, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1330.4253, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1300.8468, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1309.6472, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1292.8944, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1308.2260, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1300.4949, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1298.0333, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1298.3293, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1276.2351, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1288.2274, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1269.6592, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1274.2856, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1283.4410, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1287.1786, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1275.6979, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1288.2104, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1269.2234, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1265.4290, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1269.8640, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1257.5613, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1267.7030, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1263.0894, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1279.1813, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1254.4017, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1258.6359, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1254.1466, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1256.3529, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1255.6809, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1255.5142, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1234.5221, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1251.6952, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1243.8685, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1246.4988, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1242.6970, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1238.8427, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1242.5515, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1223.1354, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1236.4449, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1228.8705, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1235.0321, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1223.2421, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1222.4292, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1233.7277, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1216.6875, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1218.7604, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1218.4783, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-MMSE-5fold-2_sd0                                       \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetMMSE as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-2-16']\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "text len: 18\n",
      "remove None, then wav data: 18, text len: 18\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16', 'CTT5-5-16', 'CTT5-3-16', 'CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 68\n",
      "remove None, then wav data: 67, text len: 67\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 67\n",
      "total_loss tensor(47545.3945, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(40709.0508, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(33656.2266, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(26995.0508, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(20980.5488, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(15478.7295, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(10936.3066, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(7352.2759, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(4731.1577, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(2967.9929, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1970.0396, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1517.0330, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1577.7483, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1576.4623, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1614.2699, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1571.5533, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1611.9684, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1653.2202, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1573.5366, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1559.2126, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1548.7627, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1535.3380, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1535.9880, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1504.7725, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1504.8264, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1519.5426, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1479.7190, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1463.1085, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1455.9578, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1445.3147, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1440.9777, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1407.1266, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1402.1909, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1408.5992, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1390.4497, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1399.9131, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1400.8051, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1330.9282, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1339.7545, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1353.6206, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1325.4387, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1348.0936, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1305.5212, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1309.4015, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1289.4736, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1279.9205, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1284.1580, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1270.2249, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1241.0436, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1270.8892, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1256.4087, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1257.3351, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1240.4670, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1220.4058, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1221.6073, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1204.6052, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1210.9885, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1193.8868, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1222.3025, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1190.9930, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1166.3339, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1200.9307, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1168.5374, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1187.6371, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1140.8610, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1165.0273, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1157.2766, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1136.9535, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1142.3485, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1145.9429, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1135.7588, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1128.1788, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1133.1906, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1112.9010, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1133.7397, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1129.5144, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1116.9138, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1106.4077, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1110.8790, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1078.7844, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1114.5303, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1073.6832, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1100.7146, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1105.4872, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1087.2472, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1083.5016, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1078.5262, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1064.2620, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1077.2153, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1058.5188, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1071.2477, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1059.2078, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1067.3448, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1055.4891, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1045.9568, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1046.4076, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1040.2599, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1016.3746, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1059.9183, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1038.7748, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1040.2660, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1031.4420, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1011.4998, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1024.8649, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1029.9573, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1014.0587, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1014.7028, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1017.9678, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1017.5543, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1010.0406, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1011.3766, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(997.9769, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1011.3776, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(995.3378, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(996.0974, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(1003.3995, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(994.0305, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(991.1130, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(985.6023, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(992.6689, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(976.9357, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(977.6622, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(992.2250, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(978.3239, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(978.6852, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(976.2881, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(979.0961, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(958.8274, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(958.1351, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(970.9698, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(961.5424, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(954.8455, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(963.8593, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(960.4508, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(951.2416, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(964.7100, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(952.7170, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(941.0842, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(945.6019, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(953.0573, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(943.2991, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(943.1272, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(942.3084, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(937.2197, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(935.5577, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(932.7114, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(927.5846, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(930.1133, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(922.4856, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(929.2908, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(923.2178, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(922.7244, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(919.6105, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(922.2324, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(912.6818, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(922.6097, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(911.5919, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(916.9453, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(912.2144, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(907.2908, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(907.6924, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(899.4190, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(915.3824, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(904.3817, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(898.5058, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(898.0670, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(900.7170, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(897.6029, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(896.4383, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(893.4234, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(902.7608, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(890.0188, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(876.6110, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(888.3605, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(890.9232, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(883.6566, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(887.8608, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(891.8452, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(883.8319, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(892.3053, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(877.0273, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(876.1592, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(874.9041, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(876.0623, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(867.5560, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(877.9595, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(872.4604, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(860.5591, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(865.1581, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(867.0546, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(867.1187, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(866.0693, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(863.1964, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(856.1236, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(871.3304, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(861.5623, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(858.7416, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(851.4954, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(856.5276, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(861.4176, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(865.2880, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(857.6251, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(859.4073, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(854.4477, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(858.5391, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(852.9800, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(850.7206, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(847.2705, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(841.1399, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(846.6780, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(843.9677, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(843.6467, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(839.3740, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(849.0620, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(847.3368, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(839.2466, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(843.7236, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(839.6774, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(840.1852, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(822.1265, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(839.0215, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(833.6543, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "total_loss tensor(833.0081, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 67\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-MMSE-5fold-3_sd0                                       \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetMMSE as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-3-16']\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16', 'CTT5-2-16', 'CTT5-5-16', 'CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 69\n",
      "remove None, then wav data: 68, text len: 68\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 68\n",
      "total_loss tensor(48644.0820, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(40295.1992, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(32341.3184, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(24762.4492, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(18107.5215, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(12465.4746, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(8268.7295, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(5187.0527, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3343.4111, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2324.7390, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1828.3671, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1942.2795, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2087.9282, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2108.2197, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2073.7144, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2068.1189, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2100.1597, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2009.1113, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2050.3416, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(2034.0378, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1990.7054, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1965.8522, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1987.9156, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1911.6980, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1965.5402, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1928.0012, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1891.5944, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1890.5570, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1912.3807, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1843.8231, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1865.1632, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1844.9871, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1850.4590, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1817.2880, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1819.5782, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1790.4791, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1788.4164, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1779.5984, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1744.4780, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1753.2257, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1719.5988, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1720.0365, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1730.0278, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1720.4930, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1698.5874, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1684.8936, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1682.7760, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1653.7552, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1676.8922, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1660.2551, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1650.1344, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1603.3317, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1647.7736, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1623.6130, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1611.5509, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1600.1470, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1603.5997, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1603.9917, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1587.9028, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1572.4899, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1560.3014, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1572.3411, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1513.3854, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1559.2385, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1550.9086, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1534.8674, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1508.6412, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1539.8688, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1517.2762, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1533.4978, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1505.1632, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1504.3202, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1493.4257, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1496.9534, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1472.4133, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1498.5598, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1487.2622, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1475.1646, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1463.0121, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1475.2263, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1455.6844, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1451.9484, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1445.0417, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1447.6835, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1424.1125, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1419.1140, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1405.2394, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1414.8593, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1409.5424, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1381.0598, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1410.5254, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1390.9928, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1405.0754, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1389.9094, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1377.6046, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1378.9347, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1366.8440, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1375.3546, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1350.4531, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1363.7983, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1358.8226, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1341.9548, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1348.6975, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1338.3479, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1340.6702, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1320.7731, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1324.8251, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1322.9607, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1311.3040, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1314.8563, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1318.0934, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1313.6002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1305.6814, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1317.7958, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1301.8678, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1300.0762, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1290.3947, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1298.2286, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1296.4646, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1281.8746, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1280.4021, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1271.8214, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1269.7422, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1273.5923, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1260.9146, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1261.6691, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1250.7264, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1242.6432, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1251.4851, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1243.7615, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1245.0432, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1241.7303, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1230.3030, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1230.2057, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1233.9934, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1242.2190, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1229.4066, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1220.4894, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1208.0934, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1229.5840, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1205.5142, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1227.6897, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1204.8337, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1206.8915, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1194.6056, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1198.6327, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1195.6981, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1189.2618, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1185.0167, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1194.0768, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1192.3052, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1193.2151, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1177.8684, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1186.8698, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1186.4044, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1189.3766, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1181.8235, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1180.6133, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1177.6227, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1159.6489, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1167.1715, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1169.9561, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1160.7388, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1156.1208, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1160.6880, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1156.0972, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1162.4979, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1138.1532, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1154.1354, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1153.2583, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1146.0964, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1143.4338, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1141.1246, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1149.0895, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1144.1965, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1126.3090, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1140.3816, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1133.5098, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1130.6045, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1131.6637, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1132.9092, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1128.2728, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1126.2469, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1122.3318, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1113.5237, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1125.2120, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1121.0702, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1119.6609, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1105.3488, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1120.2867, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1106.1034, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1110.2169, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1104.6929, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1111.2047, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1104.4830, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1105.5276, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1099.9496, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1101.2329, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1095.4271, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1103.4749, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1090.0654, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1088.7574, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1098.7791, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1080.9557, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1083.0181, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1082.9204, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1082.5879, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1088.6060, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1073.5435, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1087.1093, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1077.9607, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1052.0669, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1077.9713, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1072.2823, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1072.6736, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1064.1357, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1065.1116, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1072.6046, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1049.8007, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1060.1442, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-MMSE-5fold-4_sd0                                       \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetMMSE as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16', 'CTT5-2-16', 'CTT5-3-16', 'CTT5-5-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "text len: 69\n",
      "remove None, then wav data: 68, text len: 68\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 68\n",
      "total_loss tensor(46181.6289, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(37414.0352, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(28815.4219, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(20871.7148, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(13843.1807, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(8825.1172, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(5398.6113, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(3043.0251, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1923.5405, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1657.6311, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1698.8389, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1718.2856, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1870.0824, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1782.3193, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1785.6838, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1774.0016, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1787.5347, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1722.5132, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1793.0190, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1765.8231, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1762.8145, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1737.0750, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1705.8641, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1706.3995, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1752.5264, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1671.1379, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1721.0717, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1645.5673, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1676.5403, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1673.3262, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1639.2919, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1635.1765, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1619.8638, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1568.7423, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1599.1384, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1594.4802, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1554.9784, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1607.2369, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1510.2716, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1578.2275, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1571.1100, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1552.1537, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1547.9553, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1538.8667, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1529.2579, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1501.4916, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1509.5660, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1525.2754, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1511.3394, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1471.5261, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1492.1538, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1486.6466, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1471.7623, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1473.9238, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1464.7219, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1409.5040, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1451.6344, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1432.4939, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1417.2258, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1431.8342, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1400.7258, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1416.5454, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1407.5298, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1394.1047, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1388.3871, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1381.5334, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1375.2600, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1355.3625, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1380.7526, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1369.1282, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1374.9791, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1357.8203, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1343.8943, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1340.1641, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1333.0007, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1346.5905, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1335.2705, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1329.7987, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1315.8264, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1312.6232, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1317.8710, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1281.5818, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1322.1943, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1312.6133, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1310.7845, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1310.7236, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1303.7166, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1303.1016, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1283.9250, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1285.9130, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1299.8967, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1293.8098, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1281.4591, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1276.0153, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1268.4595, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1264.5547, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1263.4878, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1276.7802, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1265.5128, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1259.0649, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1258.5563, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1252.0638, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1250.0051, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1246.6482, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1246.7861, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1259.8121, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1248.0765, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1245.3774, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1243.2388, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1240.9553, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1247.3583, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1229.7281, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1240.7567, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1223.5745, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1218.5686, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1234.2698, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1214.9869, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1234.6472, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1230.1398, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1218.7841, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1207.0182, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1216.2950, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1218.1694, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1191.6315, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1214.9050, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1201.8754, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1216.0309, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1206.6813, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1201.0999, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1194.0587, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1190.2642, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1202.5226, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1202.0542, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1179.2539, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1194.8154, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1187.8925, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1158.9882, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1189.9578, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1188.4800, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1182.6996, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1179.2168, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1180.4398, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1174.7721, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1187.5856, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1181.1749, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1165.5149, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1172.9246, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1155.3928, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1171.9841, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1159.7946, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1151.8409, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1149.6694, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1140.8218, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1148.5514, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1163.7246, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1158.9709, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1155.0538, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1154.7139, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1145.3406, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1151.0120, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1151.3558, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1130.8716, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1130.0490, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1149.2678, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1137.7186, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1128.5193, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1124.3491, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1138.8005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1145.7966, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1134.1880, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1136.2764, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1132.2386, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1114.2606, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1133.0587, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1139.5435, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1130.1455, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1121.9178, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1125.5114, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1113.9677, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1126.8232, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1107.5114, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1113.7542, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1108.2638, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1114.0848, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1107.9351, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1112.4932, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1112.5807, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1102.9292, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1096.8939, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1103.6978, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1106.6440, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1082.0836, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1100.8485, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1104.8978, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1094.3110, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1102.5956, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1098.2324, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1093.8853, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1094.8796, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1080.0100, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1087.7600, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1091.0250, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1092.1543, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1092.6611, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1064.2974, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1096.7767, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1053.0667, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1083.3986, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1079.2417, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1078.9653, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1072.8970, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1074.5752, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1042.9729, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1072.2942, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1072.1226, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1068.2408, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1058.0820, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1073.2219, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1064.5043, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "total_loss tensor(1055.5195, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 68\n",
      "15001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-MMSE-5fold-5_sd0                                       \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDatasetMMSE as Dataset\n",
      "[VAGDataset] path: data_process, split: ['CTT5-5-16']\n",
      "Mozillacv11Dataset CTT5-5-16 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 16, text len: 16\n",
      "[VAGDataset] path: data_process, split: ['CTT5-1-16', 'CTT5-2-16', 'CTT5-3-16', 'CTT5-4-16']\n",
      "Mozillacv11Dataset CTT5-1-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-2-16 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-3-16 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-4-16 found wav data: 17\n",
      "text len: 69\n",
      "remove None, then wav data: 69, text len: 69\n",
      "Setup ASR model and optimizer \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 69\n",
      "total_loss tensor(46278.7617, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(37944.0508, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(29601.9785, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(22015.3672, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(15321.6016, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(9997.5957, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(6446.7373, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(3825.9343, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2374.7065, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1958.2649, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1971.3763, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2059.8577, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2091.3738, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2085.6997, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2087.7793, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2034.0483, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2053.5894, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2080.2849, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2036.3765, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1983.4426, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(2003.2874, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1971.2188, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1950.4191, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1973.4492, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1931.1659, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1949.6174, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1922.3518, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1880.6056, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1899.8062, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1866.6936, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1889.9794, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1851.0627, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1864.6245, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1844.5188, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1831.4783, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1829.7522, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1815.0248, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1813.9333, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1805.7147, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1781.2463, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1792.3389, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1765.8115, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1798.9481, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1745.1823, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1770.0044, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1739.1136, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1746.8340, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1735.9148, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1717.2618, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1711.1844, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1722.1857, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1681.6433, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1696.5287, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1683.6620, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1694.3983, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1675.2306, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1658.5209, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1664.7400, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1632.5859, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1647.8386, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1648.4392, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1641.2290, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1635.9003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1629.6101, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1619.0803, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1609.9885, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1613.4303, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1621.9364, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1598.4253, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1596.3761, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1583.9065, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1592.6731, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1592.6178, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1575.6427, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1573.9022, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1588.7836, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1570.1775, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1557.7208, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1564.8175, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1557.7572, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1531.0381, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1549.4276, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1544.1277, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1541.7571, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1541.8915, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1528.1344, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1515.5566, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1516.5668, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1530.7494, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1525.6572, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1512.9684, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1515.9521, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1518.2036, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1505.1732, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1509.1809, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1485.8997, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1502.1022, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1483.6245, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1474.7756, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1491.3328, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1481.9275, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1470.7570, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1479.6650, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1462.2417, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1474.7167, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1471.7633, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1455.0458, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1454.6550, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1457.0314, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1450.4773, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1457.1627, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1457.4651, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1445.5164, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1437.2375, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1440.4738, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1429.1847, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1422.8638, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1428.3270, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1434.5570, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1416.0212, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1417.3275, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1410.5969, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1416.1377, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1403.0184, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1398.2866, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1404.0297, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1399.7286, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1395.6649, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1398.4408, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1397.3157, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1381.3947, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1373.5254, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1386.3778, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1373.1656, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1354.7030, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1363.5402, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1358.1477, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1378.8334, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1365.6621, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1357.4091, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1363.9410, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1352.6332, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1357.8431, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1355.6510, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1336.1942, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1342.1528, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1344.8716, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1323.2640, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1348.3873, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1329.0874, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1320.7080, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1331.7887, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1323.2786, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1328.1066, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1323.5211, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1324.2405, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1301.3433, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1305.0629, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1308.3545, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1315.1362, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1312.2089, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1293.7104, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1306.6664, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1303.0972, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1283.3370, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1293.3104, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1285.9435, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1298.0566, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1269.9712, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1296.9017, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1278.6338, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1283.9519, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1278.5596, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1276.5846, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1279.6399, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1269.6519, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1272.1846, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1267.0909, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1255.7534, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1263.7914, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1262.7137, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1264.5504, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1259.5208, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1263.8116, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1250.5900, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1250.3541, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1247.5265, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1250.9070, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1249.0970, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1239.0364, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1251.2620, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1239.6039, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1233.7979, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1246.0835, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1244.2726, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1237.4778, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1233.3408, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1220.4485, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1232.0471, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1238.1272, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1220.3889, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1229.1624, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1221.9805, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1222.3801, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1215.5762, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1206.5010, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1225.1865, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1218.2772, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1212.8864, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1192.1208, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1213.4001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1206.8561, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1207.9830, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1195.2168, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1207.7710, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1202.0997, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "total_loss tensor(1186.3279, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 69\n",
      "15001\n"
     ]
    }
   ],
   "source": [
    "# res = False\n",
    "# import time\n",
    "# while (res == False):\n",
    "#     time.sleep(2)\n",
    "#     try:\n",
    "#         res = main()\n",
    "#     except:\n",
    "#         continue\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "infrared-denmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "============  Result of /home/jupyter-jason3/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv ============\r\n",
      " -----------------------------------------------------------------------\r\n",
      "| Statics\t\t|  Truth\t|  Prediction\t| Abs. Diff.\t|\r\n",
      " -----------------------------------------------------------------------\r\n",
      "| Avg. # of chars\t|  8.01\t|  8.10\t|  0.16\t\t|\r\n",
      "| Avg. # of words\t|  1.00\t|  1.00\t|  0.00\t\t|\r\n",
      " -----------------------------------------------------------------------\r\n",
      " ---------------------------------------------------------------\r\n",
      "| Error Rate (%)| Mean\t\t| Std.\t\t| Min./Max.\t|\r\n",
      " ---------------------------------------------------------------\r\n",
      "| Character\t| 7.9479\t| 21.68\t\t| 0.00/240.00\t|\r\n",
      "| Word\t\t| 18.1725\t| 38.56\t\t| 0.00/100.00\t|\r\n",
      " ---------------------------------------------------------------\r\n",
      "Note : If the text unit is phoneme, WER = PER and CER is meaningless.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval.py --file ~/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-validity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "230917",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
